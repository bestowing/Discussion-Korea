2022-04-03T11:17:26,158 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:17:26,158 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:17:26,765 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:17:26,765 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:17:26,788 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:17:26,788 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:17:26,864 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:17:26,864 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:17:37,627 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:17:37,627 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:17:37,628 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:17:37,628 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:17:37,629 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:17:37,629 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:17:37,629 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:17:37,629 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:17:37,683 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:17:37,683 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:17:37,681 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:17:37,683 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:17:37,683 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:17:37,683 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:17:37,683 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:17:37,694 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:17:37,683 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:17:37,694 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:17:37,683 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:17:37,681 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:17:37,697 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:17:37,697 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:17:37,694 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:17:37,694 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:17:37,694 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:17:37,694 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:17:38,398 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:17:38,398 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:17:38,399 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:17:38,399 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:17:38,467 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:17:38,467 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:17:38,576 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:17:38,576 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:17:38,587 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:17:38,587 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:17:39,209 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:17:39,206 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:17:39,205 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:17:39,209 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:17:39,212 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:17:39,211 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:17:39,205 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:17:39,209 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:17:39,279 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]25781
2022-04-03T11:17:39,288 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]25777
2022-04-03T11:17:39,278 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]25775
2022-04-03T11:17:39,281 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]25780
2022-04-03T11:17:39,277 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]25776
2022-04-03T11:17:39,295 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,295 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,278 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]25774
2022-04-03T11:17:39,281 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]25778
2022-04-03T11:17:39,295 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,293 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:39,294 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:39,292 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:39,278 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]25779
2022-04-03T11:17:39,299 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,297 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,299 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,299 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:39,295 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,307 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,309 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,308 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:39,295 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,295 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,308 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:39,307 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,295 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,297 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,309 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,299 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:39,301 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:39,308 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:39,292 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:39,295 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:17:39,311 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:39,313 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:39,313 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:39,315 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:39,314 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:39,314 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:39,334 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:17:39,334 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:17:39,334 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:17:39,334 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:17:39,335 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:17:39,334 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:17:39,334 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:17:39,334 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:17:39,334 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:17:39,334 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:17:39,335 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:17:39,334 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:17:39,334 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:17:39,334 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:17:39,342 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:17:39,342 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:17:39,430 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T11:17:39,430 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T11:17:39,431 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T11:17:39,432 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T11:17:39,429 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T11:17:39,429 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T11:17:39,429 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T11:17:39,430 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T11:17:39,483 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259482
2022-04-03T11:17:39,483 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259482
2022-04-03T11:17:39,483 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259483
2022-04-03T11:17:39,482 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259482
2022-04-03T11:17:39,483 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259483
2022-04-03T11:17:39,482 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259482
2022-04-03T11:17:39,483 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259483
2022-04-03T11:17:39,483 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259482
2022-04-03T11:17:39,482 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259482
2022-04-03T11:17:39,482 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259482
2022-04-03T11:17:39,483 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259482
2022-04-03T11:17:39,483 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259483
2022-04-03T11:17:39,483 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259482
2022-04-03T11:17:39,483 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259483
2022-04-03T11:17:39,483 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259482
2022-04-03T11:17:39,483 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952259483
2022-04-03T11:17:39,576 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:39,577 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:39,578 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:39,578 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:39,577 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:39,577 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:39,582 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:39,583 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:39,672 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952259
2022-04-03T11:17:39,690 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:104.3012466430664|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952259
2022-04-03T11:17:39,691 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:123.97261810302734|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952259
2022-04-03T11:17:39,691 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.3|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952259
2022-04-03T11:17:39,691 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2807.09375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952259
2022-04-03T11:17:39,692 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4038.15625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952259
2022-04-03T11:17:39,692 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:65.7|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952259
2022-04-03T11:17:39,964 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:39,965 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:39,981 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:39,981 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:39,991 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:39,998 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:40,002 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:40,002 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:45,812 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:45,812 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:45,812 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:45,813 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:45,813 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:45,814 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:45,816 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:45,816 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:45,816 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:45,816 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:45,816 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:45,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:45,817 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:45,817 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:45,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:45,817 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:45,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:45,817 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:45,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:45,817 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:45,817 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:45,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:45,830 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:45,852 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,848 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:45,863 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:45,852 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,879 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:45,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:45,880 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:45,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:45,880 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:45,881 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:45,881 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:45,881 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:45,881 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:45,881 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:45,881 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:45,881 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:45,875 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,866 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,881 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:45,882 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:45,866 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,875 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,831 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:45,884 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:45,884 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:45,884 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:45,884 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:45,885 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:45,885 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:45,885 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:45,886 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:45,887 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:45,884 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:45,885 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:45,847 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:45,911 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,894 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,936 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:45,938 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:45,938 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:45,940 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:45,941 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:45,941 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:45,942 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:45,943 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:45,946 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:45,905 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,946 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:45,989 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:45,980 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:45,980 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:45,983 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:45,973 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:45,984 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:45,993 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:45,993 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:45,993 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:45,962 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:45,993 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:45,980 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:45,994 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:45,993 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:45,994 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:45,993 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:45,977 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:46,003 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,894 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,911 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,905 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:45,994 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:45,994 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:46,035 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:46,036 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:46,035 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:45,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:46,036 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:46,035 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:46,049 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:46,035 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:45,977 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:46,048 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:45,994 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:46,003 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:46,047 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:46,045 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:46,060 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:46,063 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:46,063 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:46,063 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:46,064 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:46,064 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:46,064 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:46,064 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:46,064 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:46,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:46,065 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:46,065 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:46,065 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:46,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:46,065 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:46,066 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:46,066 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:46,065 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:46,066 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:46,066 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:46,066 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:46,066 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:46,066 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:46,066 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:46,104 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-03T11:17:46,069 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-03T11:17:46,104 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-03T11:17:46,105 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-03T11:17:46,107 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-03T11:17:46,107 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-03T11:17:46,109 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-03T11:17:46,111 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-03T11:17:46,069 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-03T11:17:46,066 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:46,104 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-03T11:17:46,104 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-03T11:17:46,113 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:46,066 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:46,143 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-03T11:17:46,105 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-03T11:17:46,111 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-03T11:17:46,143 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-03T11:17:46,204 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:46,204 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:46,207 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:46,208 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:46,207 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:46,141 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-03T11:17:46,141 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-03T11:17:46,202 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-03T11:17:46,107 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-03T11:17:46,141 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-03T11:17:46,141 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-03T11:17:46,107 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-03T11:17:46,202 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-03T11:17:46,109 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-03T11:17:46,226 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-03T11:17:46,266 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:46,232 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:46,229 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:46,226 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-03T11:17:46,286 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-03T11:17:46,286 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-03T11:17:46,286 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:46,287 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:46,296 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:46,296 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:46,303 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:46,313 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:46,317 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:46,330 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-03T11:17:46,330 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-03T11:17:46,335 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:46,341 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:46,345 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-03T11:17:46,345 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-03T11:17:45,895 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,063 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,065 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,063 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:45,881 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,064 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,060 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:45,884 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:45,884 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,060 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,064 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,386 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,386 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,385 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:45,881 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,389 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,065 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,390 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,063 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,390 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,063 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:45,895 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:46,385 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,390 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,390 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,386 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,390 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,386 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,390 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,390 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,390 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,390 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,390 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,389 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:46,391 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,392 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,392 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,391 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:46,406 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-03T11:17:46,407 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-03T11:17:46,406 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-03T11:17:46,406 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-03T11:17:46,406 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-03T11:17:46,408 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-03T11:17:46,407 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-03T11:17:46,408 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-03T11:17:46,408 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-03T11:17:46,408 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-03T11:17:46,408 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-03T11:17:46,408 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-03T11:17:46,409 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-03T11:17:46,409 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-03T11:17:46,409 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-03T11:17:46,409 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-03T11:17:46,409 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-03T11:17:46,409 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-03T11:17:46,409 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-03T11:17:46,409 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-03T11:17:46,410 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-03T11:17:46,410 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-03T11:17:46,410 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-03T11:17:46,410 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-03T11:17:46,410 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-03T11:17:46,410 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-03T11:17:46,410 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-03T11:17:46,410 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-03T11:17:46,411 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-03T11:17:46,411 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-03T11:17:46,411 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-03T11:17:46,411 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-03T11:17:46,415 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-03T11:17:46,415 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-03T11:17:47,427 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:17:47,427 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:17:47,427 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:17:47,427 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:17:47,427 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:17:47,427 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:17:47,427 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:17:47,427 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:17:47,426 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:17:47,426 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:17:47,429 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:17:47,429 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:17:47,429 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:17:47,429 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:17:47,429 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:17:47,429 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:17:48,618 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:17:48,622 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:17:48,622 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:17:48,630 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:17:48,634 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]25787
2022-04-03T11:17:48,635 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,622 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:17:48,634 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:48,635 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]25790
2022-04-03T11:17:48,635 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,634 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]25785
2022-04-03T11:17:48,635 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:48,635 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:48,634 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]25789
2022-04-03T11:17:48,635 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,635 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,634 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]25786
2022-04-03T11:17:48,635 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,636 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,636 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:17:48,635 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,636 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:48,635 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,635 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:48,635 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:48,636 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:17:48,640 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:17:48,635 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,640 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:17:48,640 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:17:48,635 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:48,636 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,635 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:17:48,640 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:17:48,640 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:17:48,640 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:17:48,642 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:17:48,642 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:17:48,663 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]25792
2022-04-03T11:17:48,657 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:48,656 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:48,657 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:48,659 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:17:48,670 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]25788
2022-04-03T11:17:48,670 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:48,670 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:48,670 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,670 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,670 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,670 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:48,670 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:48,670 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,671 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:17:48,671 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:17:48,678 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:17:48,678 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:17:48,682 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T11:17:48,685 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T11:17:48,691 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T11:17:48,695 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268695
2022-04-03T11:17:48,695 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268695
2022-04-03T11:17:48,696 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268696
2022-04-03T11:17:48,696 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T11:17:48,696 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268696
2022-04-03T11:17:48,695 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268695
2022-04-03T11:17:48,695 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268695
2022-04-03T11:17:48,696 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T11:17:48,697 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T11:17:48,697 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268694
2022-04-03T11:17:48,697 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268694
2022-04-03T11:17:48,698 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268695
2022-04-03T11:17:48,698 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268695
2022-04-03T11:17:48,699 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268699
2022-04-03T11:17:48,671 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:17:48,699 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268699
2022-04-03T11:17:48,700 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]25791
2022-04-03T11:17:48,700 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:48,701 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:48,703 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,703 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:48,704 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:17:48,704 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:17:48,726 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T11:17:48,729 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T11:17:48,777 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268776
2022-04-03T11:17:48,791 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268765
2022-04-03T11:17:48,802 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:48,802 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:48,777 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268776
2022-04-03T11:17:48,791 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952268765
2022-04-03T11:17:48,799 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:48,853 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:48,851 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:48,925 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:48,925 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:48,930 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:49,097 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:49,125 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:49,155 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:49,156 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:49,156 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:49,238 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:49,239 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:49,238 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:54,811 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:54,811 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:54,811 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:54,813 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:54,825 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:54,824 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:54,838 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:54,838 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:54,839 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:54,839 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:54,839 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:54,839 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:54,839 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:54,866 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:54,870 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:54,871 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:54,867 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:54,871 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:54,872 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:54,872 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:54,872 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:54,872 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:54,868 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:54,872 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:54,873 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:54,873 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:54,873 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:54,873 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:54,868 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:54,873 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:54,874 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:54,866 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:54,873 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:54,874 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:54,839 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,839 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,843 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,834 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,836 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,836 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,839 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,839 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,843 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,893 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,892 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,893 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,893 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,893 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,893 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,892 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,893 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,834 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,903 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,903 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,903 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:54,904 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:54,905 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:54,916 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:54,918 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:54,918 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:54,918 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:54,918 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:54,918 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:54,918 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:54,921 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:54,921 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:54,919 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:54,920 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:54,919 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:54,929 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:54,929 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:54,929 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:54,929 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:54,929 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:54,929 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:54,930 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:54,930 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:54,930 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:54,931 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:54,931 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:54,929 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:54,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:54,930 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:54,930 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:54,957 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,969 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:55,029 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-03T11:17:55,029 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-03T11:17:54,968 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:54,966 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,971 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:54,955 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:54,972 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:17:55,048 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:55,049 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:55,049 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-03T11:17:55,049 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-03T11:17:55,050 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-03T11:17:54,966 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:54,957 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:55,051 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:55,051 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:55,052 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:55,052 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:55,044 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-03T11:17:55,040 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-03T11:17:55,039 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:55,045 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:55,083 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:55,103 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:55,100 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:54,894 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,044 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-03T11:17:55,040 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-03T11:17:55,104 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:55,086 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-03T11:17:55,086 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-03T11:17:55,045 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:17:55,072 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:55,104 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:55,102 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:55,104 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:55,083 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:55,105 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:55,105 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:17:55,105 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:55,072 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:55,105 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:55,105 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:17:55,105 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:55,039 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-03T11:17:55,106 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:54,894 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,105 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:55,106 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:17:55,050 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-03T11:17:54,894 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,101 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-03T11:17:55,040 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-03T11:17:55,105 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:54,894 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,039 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-03T11:17:55,100 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-03T11:17:55,008 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-03T11:17:55,040 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-03T11:17:55,105 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:17:55,105 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:55,105 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:55,088 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-03T11:17:54,903 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,101 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-03T11:17:55,008 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-03T11:17:55,088 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-03T11:17:55,039 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-03T11:17:55,100 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-03T11:17:55,140 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:55,142 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,148 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:55,142 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,141 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:55,141 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:17:55,141 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:55,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:55,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:55,157 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,157 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,163 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:55,164 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:55,165 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:55,165 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:55,165 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:55,164 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:17:55,172 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-03T11:17:55,172 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-03T11:17:55,173 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:17:55,173 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:55,173 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:17:55,173 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:55,173 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:55,173 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:55,173 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:17:55,176 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-03T11:17:55,176 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-03T11:17:55,181 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:17:55,173 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:55,181 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:17:55,181 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:17:55,181 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:17:55,181 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:55,182 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:17:55,183 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-03T11:17:55,183 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-03T11:17:55,183 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-03T11:17:55,183 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-03T11:17:55,183 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-03T11:17:55,183 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-03T11:17:55,183 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-03T11:17:55,183 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-03T11:17:54,894 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,105 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:54,894 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,187 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-03T11:17:55,187 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-03T11:17:54,903 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,105 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:54,894 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,190 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,190 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,190 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,190 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,190 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,190 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,190 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,190 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,189 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:54,894 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,189 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,189 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,189 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,143 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,196 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-03T11:17:55,196 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-03T11:17:55,143 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,196 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,197 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-03T11:17:55,197 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-03T11:17:55,197 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-03T11:17:55,197 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-03T11:17:55,105 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:17:55,197 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,197 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,197 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-03T11:17:55,197 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-03T11:17:55,196 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,196 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,197 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-03T11:17:55,197 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-03T11:17:55,196 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:17:55,198 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-03T11:17:55,198 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-03T11:17:55,200 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,200 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,203 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,203 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,203 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,203 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,203 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,203 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,204 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-03T11:17:55,204 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-03T11:17:55,205 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-03T11:17:55,205 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-03T11:17:55,205 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-03T11:17:55,205 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-03T11:17:55,205 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,205 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:17:55,207 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-03T11:17:55,209 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-03T11:17:55,209 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-03T11:17:55,209 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-03T11:17:55,207 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-03T11:17:55,209 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-03T11:17:55,213 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-03T11:17:55,213 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-03T11:17:55,213 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-03T11:17:55,213 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-03T11:17:55,213 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-03T11:17:55,213 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-03T11:17:55,213 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-03T11:17:55,213 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-03T11:17:55,214 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-03T11:17:55,214 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-03T11:17:55,214 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-03T11:17:55,214 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-03T11:17:55,214 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-03T11:17:55,214 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-03T11:17:55,214 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-03T11:17:55,214 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-03T11:17:55,214 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-03T11:17:55,214 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-03T11:17:56,219 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:17:56,215 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:17:56,215 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:17:56,219 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:17:56,218 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:17:56,218 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:17:56,216 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:17:56,216 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:17:56,218 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:17:56,218 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:17:56,218 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:17:56,218 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:17:56,215 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:17:56,215 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:17:56,215 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:17:56,215 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:17:57,301 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:17:57,306 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]25799
2022-04-03T11:17:57,306 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:57,306 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:57,309 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,309 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,311 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:17:57,312 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]25797
2022-04-03T11:17:57,312 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:57,312 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:57,312 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,312 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,316 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:17:57,317 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:17:57,316 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:17:57,317 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:17:57,315 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:17:57,322 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]25801
2022-04-03T11:17:57,323 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:57,323 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:57,324 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,324 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,324 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:17:57,324 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:17:57,324 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:17:57,326 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]25795
2022-04-03T11:17:57,326 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:57,326 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:57,328 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,328 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,329 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:17:57,329 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:17:57,330 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:17:57,372 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]25796
2022-04-03T11:17:57,384 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T11:17:57,378 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T11:17:57,384 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:57,384 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:57,386 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,386 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,387 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:17:57,387 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:17:57,389 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T11:17:57,389 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T11:17:57,408 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277407
2022-04-03T11:17:57,408 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277407
2022-04-03T11:17:57,420 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277418
2022-04-03T11:17:57,420 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277418
2022-04-03T11:17:57,423 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277417
2022-04-03T11:17:57,423 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277417
2022-04-03T11:17:57,353 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:17:57,355 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:17:57,426 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277426
2022-04-03T11:17:57,426 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277426
2022-04-03T11:17:57,350 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:17:57,429 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]25798
2022-04-03T11:17:57,429 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277429
2022-04-03T11:17:57,429 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277429
2022-04-03T11:17:57,430 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:57,431 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:57,432 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:57,433 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T11:17:57,433 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]25794
2022-04-03T11:17:57,433 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:57,433 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:57,433 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]25800
2022-04-03T11:17:57,433 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:57,434 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:57,434 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:57,434 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,434 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,434 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,434 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,434 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:17:57,434 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:17:57,434 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:17:57,434 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:17:57,443 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:57,443 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T11:17:57,444 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,444 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:17:57,444 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:17:57,444 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:17:57,444 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:17:57,444 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:17:57,445 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277445
2022-04-03T11:17:57,445 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277445
2022-04-03T11:17:57,449 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:57,458 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T11:17:57,458 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T11:17:57,460 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277460
2022-04-03T11:17:57,460 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277460
2022-04-03T11:17:57,460 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277460
2022-04-03T11:17:57,460 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952277460
2022-04-03T11:17:57,463 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:57,463 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:17:57,765 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:57,767 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:57,778 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:57,779 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:57,782 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:57,789 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:57,793 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:17:57,796 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:18:03,410 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:03,411 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:03,411 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:03,411 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:03,411 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:03,411 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:03,411 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:03,411 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:03,411 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:03,411 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:03,411 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:03,417 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,420 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,412 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:03,420 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,419 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:03,417 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,420 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:03,422 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:03,422 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:03,422 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:03,422 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:03,422 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:03,422 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:03,422 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:03,422 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:03,422 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:03,422 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:03,423 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:18:03,423 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,422 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:03,423 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,423 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,423 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,423 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:03,423 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:03,423 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,423 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,423 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,423 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,422 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:03,424 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:03,424 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:03,424 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:03,424 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:03,424 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:18:03,425 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:03,428 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:03,428 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:03,428 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:03,428 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:03,429 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:03,425 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,424 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,425 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,431 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,431 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,431 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,423 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,431 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,435 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:03,444 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-03T11:18:03,444 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-03T11:18:03,445 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-03T11:18:03,445 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-03T11:18:03,445 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:03,446 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:03,446 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:03,446 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:18:03,453 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-03T11:18:03,453 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-03T11:18:03,453 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-04-03T11:18:03,453 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-04-03T11:18:03,490 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,493 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,493 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,494 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,493 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:03,494 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,456 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:03,493 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,494 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,490 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,496 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,494 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:03,498 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,498 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:03,498 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,498 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,498 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:03,499 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:03,494 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,495 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:03,500 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,493 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:03,500 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,496 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:03,496 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,493 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:03,501 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,424 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,499 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,499 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:03,501 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:03,502 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:03,498 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,423 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,515 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:03,501 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,500 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,500 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:03,499 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,515 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,500 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:03,515 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,515 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,515 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:03,515 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,515 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,515 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,515 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,516 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-03T11:18:03,516 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-03T11:18:03,516 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:03,515 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:03,516 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:03,516 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:03,516 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-03T11:18:03,516 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-03T11:18:03,517 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-04-03T11:18:03,517 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-04-03T11:18:03,518 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,515 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,518 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,515 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,518 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,515 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,518 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,515 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,515 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,519 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,519 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,519 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,519 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,519 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,518 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,515 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:03,445 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-03T11:18:03,519 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,519 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,519 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,519 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,519 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-03T11:18:03,519 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-03T11:18:03,519 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-03T11:18:03,519 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:03,519 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-03T11:18:03,519 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-03T11:18:03,519 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,519 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,519 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-03T11:18:03,445 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-03T11:18:03,519 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-03T11:18:03,518 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,519 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-03T11:18:03,548 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:03,548 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:03,546 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-04-03T11:18:03,518 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-03T11:18:03,542 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:03,546 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-04-03T11:18:03,547 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:03,550 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:03,550 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:03,550 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:03,550 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:03,559 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:03,547 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:03,560 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:03,561 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:03,561 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:03,561 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:03,561 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:18:03,567 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-03T11:18:03,569 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-03T11:18:03,569 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-03T11:18:03,569 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-03T11:18:03,571 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-03T11:18:03,569 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-03T11:18:03,569 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-03T11:18:03,565 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-03T11:18:03,565 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-03T11:18:03,572 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:03,567 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-03T11:18:03,573 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-03T11:18:03,573 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-03T11:18:03,568 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-03T11:18:03,566 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-03T11:18:03,566 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-03T11:18:03,575 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-03T11:18:03,580 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-04-03T11:18:03,569 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-03T11:18:03,568 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-03T11:18:03,573 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:03,571 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-03T11:18:03,591 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-03T11:18:03,589 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-03T11:18:03,557 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:03,580 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-04-03T11:18:03,575 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-03T11:18:03,591 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-03T11:18:03,594 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:03,594 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:03,589 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-03T11:18:03,594 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:03,594 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:03,575 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-03T11:18:03,594 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:03,594 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:03,566 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-03T11:18:03,595 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:03,595 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:03,518 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-03T11:18:03,566 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-03T11:18:03,597 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,599 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-03T11:18:03,606 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-04-03T11:18:03,609 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-04-03T11:18:03,575 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-03T11:18:03,597 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:03,566 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-03T11:18:03,595 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:03,566 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-03T11:18:03,599 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-03T11:18:03,595 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:03,609 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-04-03T11:18:03,606 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-04-03T11:18:03,622 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:03,623 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-04-03T11:18:03,623 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-04-03T11:18:03,623 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:03,623 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-03T11:18:03,620 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:03,624 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:03,623 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-03T11:18:03,624 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-03T11:18:03,624 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-03T11:18:03,624 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:18:03,624 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-03T11:18:03,624 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-03T11:18:03,626 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-03T11:18:03,627 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-04-03T11:18:03,626 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-03T11:18:03,627 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-04-03T11:18:03,608 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-03T11:18:03,608 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-03T11:18:05,467 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:18:05,467 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:18:05,521 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:18:05,521 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:18:05,521 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:18:05,521 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:18:05,580 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:18:05,580 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:18:05,604 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:18:05,604 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:18:05,604 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:18:05,604 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:18:05,620 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:18:05,620 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:18:05,629 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:18:05,629 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:18:06,786 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:18:06,790 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]25803
2022-04-03T11:18:06,791 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:18:06,791 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:18:06,791 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:06,791 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:06,791 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:18:06,791 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:18:06,797 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T11:18:06,798 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952286798
2022-04-03T11:18:06,798 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952286798
2022-04-03T11:18:06,799 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:18:06,900 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:18:06,901 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]25804
2022-04-03T11:18:06,902 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:18:06,903 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:06,903 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:06,903 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:18:06,903 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:18:06,904 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:18:06,906 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952286906
2022-04-03T11:18:06,906 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952286906
2022-04-03T11:18:06,909 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T11:18:06,913 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:18:06,919 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:18:06,921 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]25805
2022-04-03T11:18:06,921 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:18:06,921 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:18:06,921 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:06,921 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:06,921 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:18:06,921 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:18:06,924 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952286924
2022-04-03T11:18:06,924 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952286924
2022-04-03T11:18:06,927 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T11:18:06,927 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:18:07,052 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:18:07,054 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]25806
2022-04-03T11:18:07,054 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:18:07,054 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:18:07,055 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:07,055 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:07,055 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:18:07,055 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:18:07,059 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T11:18:07,060 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952287060
2022-04-03T11:18:07,060 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952287060
2022-04-03T11:18:07,063 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:18:07,089 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:18:07,097 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]25808
2022-04-03T11:18:07,097 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:18:07,097 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:18:07,097 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:07,097 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:07,097 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:18:07,097 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:18:07,101 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T11:18:07,103 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952287103
2022-04-03T11:18:07,103 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952287103
2022-04-03T11:18:07,108 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:18:07,115 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:18:07,116 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]25807
2022-04-03T11:18:07,116 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:18:07,117 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:07,117 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:18:07,117 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:07,117 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:18:07,117 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:18:07,123 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952287123
2022-04-03T11:18:07,122 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T11:18:07,123 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952287123
2022-04-03T11:18:07,129 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:18:07,138 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:18:07,137 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:18:07,139 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]25809
2022-04-03T11:18:07,139 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:18:07,139 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:18:07,140 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:07,140 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:07,141 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:18:07,141 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:18:07,147 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T11:18:07,149 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952287149
2022-04-03T11:18:07,149 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952287149
2022-04-03T11:18:07,164 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:18:07,180 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:18:07,182 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]25810
2022-04-03T11:18:07,182 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:07,182 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T11:18:07,182 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:18:07,182 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:18:07,182 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:18:07,182 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:18:07,188 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952287188
2022-04-03T11:18:07,188 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952287188
2022-04-03T11:18:07,201 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T11:18:07,202 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:18:07,272 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:18:07,292 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:18:07,409 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:18:07,448 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:18:07,456 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:18:07,479 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:18:07,495 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:18:12,766 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:12,767 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:12,768 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:12,768 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:12,768 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:12,768 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:12,768 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:12,768 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:12,768 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:12,768 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:12,769 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:12,769 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:12,771 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:12,771 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:12,774 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:12,774 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:12,774 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:18:12,775 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:12,775 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:12,776 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:12,776 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:12,776 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:12,776 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:12,788 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:12,788 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:12,789 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-03T11:18:12,789 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-03T11:18:12,789 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-03T11:18:12,789 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-03T11:18:12,790 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-03T11:18:12,789 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-03T11:18:12,790 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-03T11:18:12,789 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-03T11:18:12,797 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-04-03T11:18:12,797 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-04-03T11:18:12,908 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:12,912 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:12,909 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:12,912 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:12,924 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:18:12,924 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:12,924 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:12,924 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:12,924 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:12,926 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:12,926 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:12,926 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:12,926 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:12,927 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-03T11:18:12,927 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-03T11:18:12,927 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-03T11:18:12,927 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-03T11:18:12,927 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-04-03T11:18:12,927 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-04-03T11:18:12,927 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-03T11:18:12,927 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-03T11:18:12,930 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-03T11:18:12,930 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-03T11:18:12,932 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:12,933 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:12,933 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:12,933 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:12,934 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:12,933 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:12,934 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:12,943 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:12,943 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:12,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:12,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:12,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:12,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:12,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:12,943 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:12,943 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:12,944 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:12,944 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:12,944 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:12,944 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:12,945 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-03T11:18:12,945 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-03T11:18:12,945 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-03T11:18:12,945 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-03T11:18:12,945 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2022-04-03T11:18:12,945 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2022-04-03T11:18:12,945 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-03T11:18:12,945 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-03T11:18:12,946 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:12,946 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-03T11:18:12,946 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-03T11:18:13,113 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:13,114 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:13,114 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:13,114 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:13,114 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:13,114 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:13,114 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:13,114 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:13,114 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:13,114 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:13,114 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:13,114 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:13,115 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:13,115 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:13,115 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:13,115 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:13,115 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:13,115 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:13,115 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:13,115 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:13,116 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:13,118 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:13,119 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:13,119 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:13,120 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:13,120 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:13,120 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:13,120 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:13,120 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:18:13,119 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:13,124 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:13,124 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:13,124 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:13,124 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:13,127 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:13,127 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:13,131 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:13,131 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:13,131 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:13,131 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:13,132 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:13,132 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:13,132 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:13,132 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:13,132 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:13,132 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:13,132 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:13,132 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:13,135 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-03T11:18:13,135 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-03T11:18:13,136 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-03T11:18:13,136 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-03T11:18:13,136 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:13,136 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:13,135 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-03T11:18:13,135 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-03T11:18:13,136 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-03T11:18:13,136 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-03T11:18:13,144 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:13,144 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:13,144 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2022-04-03T11:18:13,144 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2022-04-03T11:18:13,145 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:13,145 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-03T11:18:13,145 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-03T11:18:13,145 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:13,145 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:13,145 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:13,155 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:13,159 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:13,160 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2022-04-03T11:18:13,160 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2022-04-03T11:18:13,160 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:13,161 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:13,160 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:13,161 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:13,161 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:13,161 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:13,161 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:13,161 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:13,161 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:13,161 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-03T11:18:13,161 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:13,162 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-03T11:18:13,162 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-03T11:18:13,161 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-03T11:18:13,162 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:13,161 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:13,162 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-03T11:18:13,162 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:13,162 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-03T11:18:13,163 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-04-03T11:18:13,163 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-04-03T11:18:13,163 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:13,163 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-03T11:18:13,163 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-03T11:18:13,163 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:13,163 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:13,135 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-03T11:18:13,163 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:13,163 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:13,163 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:13,164 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:13,164 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:13,164 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:13,164 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:13,164 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:13,148 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-03T11:18:13,165 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-03T11:18:13,165 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-03T11:18:13,165 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-03T11:18:13,165 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-03T11:18:13,135 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-03T11:18:13,164 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-03T11:18:13,165 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-04-03T11:18:13,163 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-03T11:18:13,165 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-04-03T11:18:13,148 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-03T11:18:13,163 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-03T11:18:13,164 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-03T11:18:13,169 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:13,170 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-03T11:18:13,170 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-03T11:18:13,184 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 112, in load
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     initialize_fn(service.context)
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/ceba72e98107482bbc2a69b7841aaab5/RobertaModel_handler.py", line 54, in initialize
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.model.to(self.device)
2022-04-03T11:18:13,185 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - AttributeError: 'NoneType' object has no attribute 'to'
2022-04-03T11:18:13,187 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:13,187 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-03T11:18:13,188 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:13,188 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-03T11:18:13,188 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:13,188 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T11:18:13,188 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:13,188 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-03T11:18:13,188 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:13,188 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-03T11:18:13,189 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-03T11:18:13,189 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-03T11:18:13,189 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-03T11:18:13,189 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-03T11:18:13,189 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-03T11:18:13,189 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-03T11:18:13,189 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2022-04-03T11:18:13,189 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2022-04-03T11:18:13,189 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-03T11:18:13,189 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-03T11:18:13,552 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-03T11:18:13,552 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-03T11:26:47,048 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:26:47,048 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:26:47,578 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:26:47,578 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:26:47,589 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:26:47,589 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:26:47,623 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:26:47,623 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:26:58,461 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:26:58,461 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:26:58,462 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:26:58,462 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:26:58,463 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:26:58,463 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:26:58,463 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:26:58,463 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:26:58,533 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:26:58,527 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:26:58,533 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:26:58,533 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:26:58,529 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:26:58,528 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:26:58,527 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:26:58,528 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:26:58,532 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:26:58,527 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:26:58,529 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:26:58,533 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:26:58,533 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:26:58,528 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:26:58,528 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:26:58,533 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:26:58,527 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:26:58,532 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:26:59,472 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:26:59,472 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:26:59,473 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:26:59,473 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:26:59,489 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:26:59,489 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:26:59,490 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:26:59,490 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:26:59,492 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:26:59,492 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:26:59,809 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:26:59,813 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]26431
2022-04-03T11:26:59,814 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:26:59,815 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:26:59,816 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:26:59,816 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:26:59,877 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:26:59,877 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:26:59,928 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T11:26:59,942 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952819941
2022-04-03T11:26:59,942 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952819941
2022-04-03T11:27:00,041 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:27:00,122 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:27:00,128 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:27:00,144 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]26434
2022-04-03T11:27:00,147 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]26433
2022-04-03T11:27:00,153 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,153 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,159 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:27:00,152 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,152 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,160 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:27:00,160 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:27:00,159 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:27:00,151 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:27:00,151 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:27:00,121 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:27:00,221 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:27:00,151 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:27:00,152 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:27:00,248 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:27:00,276 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820276
2022-04-03T11:27:00,250 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]26432
2022-04-03T11:27:00,276 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820276
2022-04-03T11:27:00,259 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]26435
2022-04-03T11:27:00,259 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]26438
2022-04-03T11:27:00,275 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820275
2022-04-03T11:27:00,277 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T11:27:00,275 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820275
2022-04-03T11:27:00,282 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:27:00,283 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:27:00,283 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:27:00,283 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:27:00,283 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,283 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,283 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,283 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,283 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:27:00,280 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T11:27:00,284 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:27:00,290 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,285 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:27:00,285 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:27:00,153 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:27:00,249 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:27:00,284 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:27:00,290 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,284 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:27:00,317 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:27:00,318 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:27:00,301 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:27:00,312 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]26436
2022-04-03T11:27:00,317 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]26437
2022-04-03T11:27:00,301 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:27:00,319 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,319 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:27:00,319 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,320 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,319 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:27:00,320 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:27:00,319 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:27:00,322 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:27:00,322 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:27:00,322 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:27:00,322 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:27:00,337 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T11:27:00,339 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:27:00,343 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820342
2022-04-03T11:27:00,346 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820346
2022-04-03T11:27:00,343 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820342
2022-04-03T11:27:00,346 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820346
2022-04-03T11:27:00,366 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T11:27:00,431 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820414
2022-04-03T11:27:00,365 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T11:27:00,431 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820414
2022-04-03T11:27:00,477 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820477
2022-04-03T11:27:00,477 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820477
2022-04-03T11:27:00,477 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:27:00,533 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:27:00,492 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:27:00,477 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820477
2022-04-03T11:27:00,477 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:27:00,477 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T11:27:00,477 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T11:27:00,477 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952820477
2022-04-03T11:27:00,678 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:27:00,679 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:27:00,678 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:27:00,680 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:27:00,781 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:27:00,785 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:27:00,836 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:27:00,906 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:27:00,913 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:27:00,951 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952820
2022-04-03T11:27:00,959 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:104.29602813720703|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952820
2022-04-03T11:27:00,961 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:123.97783660888672|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952820
2022-04-03T11:27:00,962 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.3|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952820
2022-04-03T11:27:00,962 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2685.5|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952820
2022-04-03T11:27:00,962 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3927.890625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952820
2022-04-03T11:27:00,962 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:67.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952820
2022-04-03T11:27:22,396 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias']
2022-04-03T11:27:22,396 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
2022-04-03T11:27:22,396 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']
2022-04-03T11:27:22,396 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']
2022-04-03T11:27:22,396 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']
2022-04-03T11:27:22,396 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
2022-04-03T11:27:22,396 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
2022-04-03T11:27:22,396 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight']
2022-04-03T11:27:24,338 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:27:24,338 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:27:24,338 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:27:24,338 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:27:24,338 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:27:24,338 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:27:24,338 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:27:24,348 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:27:24,353 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:27:24,347 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:27:24,347 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:27:24,372 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:27:24,353 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:27:27,329 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:27:24,372 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:27:24,363 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:27:27,329 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:27:24,347 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:27:24,372 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:27:27,488 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:27:27,509 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:27:27,488 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:27:27,823 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:27:27,815 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:27:27,815 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:27:27,488 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:27:27,844 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:27:27,488 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:27:28,937 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:27:28,937 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:27:28,937 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:27:28,613 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:27:38,248 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/d17d3516e153450186f5bc4405195663 loaded successfully
2022-04-03T11:27:38,297 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/d17d3516e153450186f5bc4405195663 loaded successfully
2022-04-03T11:27:38,246 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/d17d3516e153450186f5bc4405195663 loaded successfully
2022-04-03T11:27:38,256 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/d17d3516e153450186f5bc4405195663 loaded successfully
2022-04-03T11:27:38,246 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/d17d3516e153450186f5bc4405195663 loaded successfully
2022-04-03T11:27:38,246 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/d17d3516e153450186f5bc4405195663 loaded successfully
2022-04-03T11:27:38,246 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/d17d3516e153450186f5bc4405195663 loaded successfully
2022-04-03T11:27:38,249 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/d17d3516e153450186f5bc4405195663 loaded successfully
2022-04-03T11:27:38,534 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38079
2022-04-03T11:27:38,534 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 37909
2022-04-03T11:27:38,534 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38015
2022-04-03T11:27:38,534 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 37908
2022-04-03T11:27:38,535 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38222
2022-04-03T11:27:38,534 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38015
2022-04-03T11:27:38,535 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38222
2022-04-03T11:27:38,539 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38218
2022-04-03T11:27:38,534 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 37908
2022-04-03T11:27:38,534 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 37909
2022-04-03T11:27:38,539 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38218
2022-04-03T11:27:38,534 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38079
2022-04-03T11:27:38,538 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38079
2022-04-03T11:27:38,539 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38494
2022-04-03T11:27:38,542 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,538 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38079
2022-04-03T11:27:38,542 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,542 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,542 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,542 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,542 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,539 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 38494
2022-04-03T11:27:38,542 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,542 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,543 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,542 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,544 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,542 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,542 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,542 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,543 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,545 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:40048|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952858
2022-04-03T11:27:38,545 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:40044|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952858
2022-04-03T11:27:38,572 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:40071|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952858
2022-04-03T11:27:38,584 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:87|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:27:38,573 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:40078|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952858
2022-04-03T11:27:38,573 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:40079|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952858
2022-04-03T11:27:38,585 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:164|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:27:38,573 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:40085|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952858
2022-04-03T11:27:38,586 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:161|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:27:38,586 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:201|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:27:38,586 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:92|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:27:38,545 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:40044|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952858
2022-04-03T11:27:38,544 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:27:38,587 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:158|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:27:38,584 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:198|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:27:38,587 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:40096|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952858
2022-04-03T11:27:38,588 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:153|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:28:01,599 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952881
2022-04-03T11:28:01,601 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:101.29653549194336|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952881
2022-04-03T11:28:01,601 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:126.97732925415039|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952881
2022-04-03T11:28:01,601 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.6|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952881
2022-04-03T11:28:01,601 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1953.03125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952881
2022-04-03T11:28:01,601 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2151.546875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952881
2022-04-03T11:28:01,601 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:76.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952881
2022-04-03T11:28:14,487 [INFO ] pool-2-thread-9 ACCESS_LOG - /127.0.0.1:54419 "POST /ping HTTP/1.1" 200 34
2022-04-03T11:28:14,527 [INFO ] pool-2-thread-9 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:28:43,691 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952923691
2022-04-03T11:28:43,691 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952923691
2022-04-03T11:28:43,696 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648952923
2022-04-03T11:28:43,706 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12
2022-04-03T11:28:43,706 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:28:43,706 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 12
2022-04-03T11:28:43,707 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:28:43,707 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:28:43,707 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:28:43,707 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:28:43,708 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:28:43,708 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/d17d3516e153450186f5bc4405195663/RobertaModel_handler.py", line 98, in preprocess
2022-04-03T11:28:43,708 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:28:43,711 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54421 "POST /predictions/my_tc HTTP/1.1" 503 30
2022-04-03T11:28:43,713 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:28:43,714 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:28:43,714 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:28:43,714 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:28:43,714 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:28:43,715 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:28:43,715 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 249250, Inference time ns: 24053458
2022-04-03T11:28:43,715 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 249250, Inference time ns: 24053458
2022-04-03T11:28:43,715 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:28:43,731 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:28:43,730 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:27|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:28:43,732 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:28:43,732 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:29:00,955 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952940
2022-04-03T11:29:00,956 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29696273803711|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952940
2022-04-03T11:29:00,956 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.97690200805664|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952940
2022-04-03T11:29:00,956 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952940
2022-04-03T11:29:00,957 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1321.5625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952940
2022-04-03T11:29:00,957 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2463.546875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952940
2022-04-03T11:29:00,957 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.9|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648952940
2022-04-03T11:29:01,472 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952941472
2022-04-03T11:29:01,472 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648952941472
2022-04-03T11:29:01,475 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648952941
2022-04-03T11:29:01,479 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:29:01,479 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2022-04-03T11:29:01,479 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 6
2022-04-03T11:29:01,479 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:29:01,479 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:29:01,479 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:29:01,479 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:29:01,480 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:29:01,481 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/d17d3516e153450186f5bc4405195663/RobertaModel_handler.py", line 98, in preprocess
2022-04-03T11:29:01,479 [INFO ] W-9007-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54423 "POST /predictions/my_tc HTTP/1.1" 503 8
2022-04-03T11:29:01,481 [INFO ] W-9007-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:29:01,481 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:29:01,481 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 169834, Inference time ns: 9666709
2022-04-03T11:29:01,481 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 169834, Inference time ns: 9666709
2022-04-03T11:29:01,481 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:29:01,481 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:3|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:29:01,482 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:29:01,482 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:29:01,482 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:29:01,482 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:29:01,482 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:29:01,486 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:29:01,486 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:29:01,486 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:29:07,943 [INFO ] pool-2-thread-9 ACCESS_LOG - /127.0.0.1:54425 "POST /ping HTTP/1.1" 200 1
2022-04-03T11:29:07,944 [INFO ] pool-2-thread-9 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:30:00,939 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953000
2022-04-03T11:30:00,941 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29654312133789|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953000
2022-04-03T11:30:00,942 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.97732162475586|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953000
2022-04-03T11:30:00,943 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953000
2022-04-03T11:30:00,948 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1303.21875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953000
2022-04-03T11:30:00,951 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2582.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953000
2022-04-03T11:30:00,953 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:84.1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953000
2022-04-03T11:31:01,508 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953061
2022-04-03T11:31:01,510 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29324722290039|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953061
2022-04-03T11:31:01,511 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.98061752319336|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953061
2022-04-03T11:31:01,512 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953061
2022-04-03T11:31:01,512 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1341.40625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953061
2022-04-03T11:31:01,512 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2523.015625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953061
2022-04-03T11:31:01,512 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.6|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953061
2022-04-03T11:32:00,956 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953120
2022-04-03T11:32:00,957 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.28641510009766|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953120
2022-04-03T11:32:00,957 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.9874496459961|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953120
2022-04-03T11:32:00,958 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953120
2022-04-03T11:32:00,958 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1371.578125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953120
2022-04-03T11:32:00,958 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2546.90625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953120
2022-04-03T11:32:00,958 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.3|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953120
2022-04-03T11:32:11,374 [INFO ] pool-2-thread-10 ACCESS_LOG - /127.0.0.1:54470 "POST /ping HTTP/1.1" 200 2
2022-04-03T11:32:11,384 [INFO ] pool-2-thread-10 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:35:32,823 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:35:32,823 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:35:33,411 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:35:33,411 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:35:33,422 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:35:33,422 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:35:33,455 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:35:33,455 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:35:44,248 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:35:44,248 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:35:44,250 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:35:44,250 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:35:44,250 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:35:44,250 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:35:44,251 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:35:44,251 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:35:44,309 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:35:44,310 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:35:44,309 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:35:44,309 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:35:44,308 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:35:44,310 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:35:44,308 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:35:44,309 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:35:44,313 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:35:44,308 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:35:44,310 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:35:44,309 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:35:44,309 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:35:44,310 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:35:44,310 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:35:44,313 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:35:44,310 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:35:44,308 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:35:45,249 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:35:45,249 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:35:45,250 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:35:45,250 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:35:45,254 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:35:45,254 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:35:45,255 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:35:45,255 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:35:45,257 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:35:45,257 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:35:45,796 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:35:45,796 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:35:45,803 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:35:45,816 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]27778
2022-04-03T11:35:45,821 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]27779
2022-04-03T11:35:45,830 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-03T11:35:45,834 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,835 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,814 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]27784
2022-04-03T11:35:45,812 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:35:45,821 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:35:45,834 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,830 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-03T11:35:45,829 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:35:45,835 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,844 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]27781
2022-04-03T11:35:45,827 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:35:45,850 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:35:45,850 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,850 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:35:45,850 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,848 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]27780
2022-04-03T11:35:45,850 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:35:45,848 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:35:45,850 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:35:45,851 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:35:45,850 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,851 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,851 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,850 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,851 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:35:45,851 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:35:45,852 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:35:45,849 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:35:45,939 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:35:45,940 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:35:45,940 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:35:45,940 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:35:45,939 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]27782
2022-04-03T11:35:45,939 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:35:45,948 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:35:45,939 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:35:45,948 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:35:45,948 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:35:45,927 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]27783
2022-04-03T11:35:45,940 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:35:45,948 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:35:45,939 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:35:45,951 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,951 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,951 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:35:45,951 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,951 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,898 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:35:45,960 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:35:45,969 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]27785
2022-04-03T11:35:45,960 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:35:45,975 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,961 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:35:45,974 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:35:45,949 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953345
2022-04-03T11:35:45,975 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:35:45,961 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:35:45,959 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:35:45,995 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:35:45,995 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.29696655273438|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953345
2022-04-03T11:35:45,995 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:124.97689819335938|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953345
2022-04-03T11:35:45,996 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:35:45,996 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:35:45,997 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.7|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953345
2022-04-03T11:35:46,010 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2932.578125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953345
2022-04-03T11:35:46,029 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4158.5625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953345
2022-04-03T11:35:46,029 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:64.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953345
2022-04-03T11:35:46,101 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T11:35:46,101 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T11:35:46,098 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T11:35:46,098 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T11:35:46,098 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T11:35:46,099 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T11:35:46,101 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T11:35:46,100 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T11:35:46,143 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346143
2022-04-03T11:35:46,145 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346144
2022-04-03T11:35:46,144 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346144
2022-04-03T11:35:46,144 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346143
2022-04-03T11:35:46,144 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346144
2022-04-03T11:35:46,144 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346144
2022-04-03T11:35:46,144 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346143
2022-04-03T11:35:46,143 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346143
2022-04-03T11:35:46,143 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346143
2022-04-03T11:35:46,144 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346144
2022-04-03T11:35:46,143 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346143
2022-04-03T11:35:46,144 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346143
2022-04-03T11:35:46,144 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346143
2022-04-03T11:35:46,144 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346144
2022-04-03T11:35:46,144 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346144
2022-04-03T11:35:46,145 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953346144
2022-04-03T11:35:46,207 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:35:46,208 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:35:46,208 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:35:46,210 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:35:46,210 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:35:46,208 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:35:46,213 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:35:46,212 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:35:46,471 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:35:46,476 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:35:46,487 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:35:46,491 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:35:46,493 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:35:46,494 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:35:46,498 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:35:46,501 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:36:04,973 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias']
2022-04-03T11:36:04,970 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight']
2022-04-03T11:36:05,011 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:36:04,970 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']
2022-04-03T11:36:05,045 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']
2022-04-03T11:36:04,970 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
2022-04-03T11:36:05,011 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:36:05,068 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:36:05,068 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:36:04,970 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias']
2022-04-03T11:36:04,970 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']
2022-04-03T11:36:04,970 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']
2022-04-03T11:36:05,066 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:36:05,066 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:36:05,904 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:36:05,890 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:36:05,904 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:36:05,890 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:36:05,904 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:36:05,890 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:36:18,797 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32587
2022-04-03T11:36:18,797 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32583
2022-04-03T11:36:18,797 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32588
2022-04-03T11:36:18,797 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32586
2022-04-03T11:36:18,797 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32584
2022-04-03T11:36:18,797 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32584
2022-04-03T11:36:18,797 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32589
2022-04-03T11:36:18,797 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32583
2022-04-03T11:36:18,797 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32584
2022-04-03T11:36:18,797 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32586
2022-04-03T11:36:11,803 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:36:18,681 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d loaded successfully
2022-04-03T11:36:18,797 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32588
2022-04-03T11:36:18,797 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32584
2022-04-03T11:36:18,797 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32583
2022-04-03T11:36:18,797 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32589
2022-04-03T11:36:18,797 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32583
2022-04-03T11:36:19,106 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:18,523 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d loaded successfully
2022-04-03T11:36:18,543 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d loaded successfully
2022-04-03T11:36:18,502 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d loaded successfully
2022-04-03T11:36:18,502 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d loaded successfully
2022-04-03T11:36:18,574 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d loaded successfully
2022-04-03T11:36:18,511 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d loaded successfully
2022-04-03T11:36:18,559 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d loaded successfully
2022-04-03T11:36:19,106 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,106 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:11,803 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:36:18,797 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32587
2022-04-03T11:36:19,105 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:36:19,177 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,177 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:36:19,178 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:36:11,803 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:36:11,803 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:36:11,803 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:36:11,803 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:36:11,803 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:36:11,803 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:36:19,109 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:34838|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953379
2022-04-03T11:36:19,182 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:454|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:19,184 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:36:19,177 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:34903|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953379
2022-04-03T11:36:19,184 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:36:19,177 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:34903|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953379
2022-04-03T11:36:19,177 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:34903|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953379
2022-04-03T11:36:19,177 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:34905|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953379
2022-04-03T11:36:19,177 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:34903|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953379
2022-04-03T11:36:19,177 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:34904|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953379
2022-04-03T11:36:19,189 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:458|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:19,177 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:34904|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953379
2022-04-03T11:36:19,190 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:36:19,190 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:36:19,190 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:36:19,199 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:36:19,200 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:471|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:19,199 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:36:19,200 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:473|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:19,194 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:36:19,224 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:36:19,222 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:36:19,216 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:489|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:19,221 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:490|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:19,216 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:488|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:19,216 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:482|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:36,339 [INFO ] KQueueEventLoopGroup-3-1 ACCESS_LOG - /127.0.0.1:54586 "POST /prediction HTTP/1.1" 404 21
2022-04-03T11:36:36,345 [INFO ] KQueueEventLoopGroup-3-1 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:46,500 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953406
2022-04-03T11:36:46,504 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29510116577148|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953406
2022-04-03T11:36:46,508 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.97876358032227|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953406
2022-04-03T11:36:46,509 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953406
2022-04-03T11:36:46,509 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1333.28125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953406
2022-04-03T11:36:46,509 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2589.453125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953406
2022-04-03T11:36:46,510 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.7|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953406
2022-04-03T11:36:57,365 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953417365
2022-04-03T11:36:57,365 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953417365
2022-04-03T11:36:57,370 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648953417
2022-04-03T11:36:57,380 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:36:57,380 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [{'body': bytearray(b'\xec\xa0\x80\xeb\x8a\x94 \xea\xb3\xb5\xeb\xb6\x80\xea\xb0\x80 \xeb\x84\x88\xeb\xac\xb4 \xed\x95\x98\xea\xb8\xb0 \xec\x8b\xab\xec\x96\xb4\xec\x9a\x94')}]
2022-04-03T11:36:57,380 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - <class 'list'>
2022-04-03T11:36:57,380 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:36:57,381 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:36:57,381 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:36:57,381 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14
2022-04-03T11:36:57,381 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 14
2022-04-03T11:36:57,381 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:36:57,381 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:36:57,382 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:36:57,382 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:36:57,382 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d/RobertaModel_handler.py", line 101, in preprocess
2022-04-03T11:36:57,382 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54588 "POST /predictions/my_tc HTTP/1.1" 503 27
2022-04-03T11:36:57,384 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:36:57,397 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:57,397 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:36:57,402 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:36:57,402 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:36:57,402 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:36:57,402 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 218083, Inference time ns: 37587542
2022-04-03T11:36:57,402 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 218083, Inference time ns: 37587542
2022-04-03T11:36:57,402 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:36:57,402 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:23|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:36:57,402 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:36:57,403 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:36:57,407 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:36:57,407 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:37:30,963 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953450962
2022-04-03T11:37:30,963 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953450962
2022-04-03T11:37:30,992 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648953450
2022-04-03T11:37:30,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:37:30,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [{'body': bytearray(b'\xec\xa0\x80\xeb\x8a\x94 \xea\xb3\xb5\xeb\xb6\x80\xea\xb0\x80 \xeb\x84\x88\xeb\xac\xb4 \xed\x95\x98\xea\xb8\xb0 \xec\x8b\xab\xec\x96\xb4\xec\x9a\x94')}]
2022-04-03T11:37:30,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - <class 'list'>
2022-04-03T11:37:30,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:37:30,999 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18
2022-04-03T11:37:30,999 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 18
2022-04-03T11:37:31,000 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:37:31,001 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:37:31,002 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:37:31,002 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:37:31,002 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:37:31,002 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:37:31,003 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d/RobertaModel_handler.py", line 101, in preprocess
2022-04-03T11:37:31,008 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:37:31,008 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:37:31,009 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:37:31,009 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:37:31,009 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:37:31,012 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:37:31,012 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:37:31,012 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:37:31,012 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:37:31,013 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:37:31,008 [INFO ] W-9007-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54590 "POST /predictions/my_tc HTTP/1.1" 503 51
2022-04-03T11:37:31,013 [INFO ] W-9007-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:37:31,014 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 684125, Inference time ns: 52111458
2022-04-03T11:37:31,014 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 684125, Inference time ns: 52111458
2022-04-03T11:37:31,014 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:34|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:37:42,983 [INFO ] KQueueEventLoopGroup-3-4 ACCESS_LOG - /127.0.0.1:54593 "POST /prediction HTTP/1.1" 404 1
2022-04-03T11:37:42,986 [INFO ] KQueueEventLoopGroup-3-4 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:37:45,896 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953465
2022-04-03T11:37:45,900 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29240417480469|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953465
2022-04-03T11:37:45,901 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.98146057128906|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953465
2022-04-03T11:37:45,906 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953465
2022-04-03T11:37:45,907 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1341.1875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953465
2022-04-03T11:37:45,907 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2534.359375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953465
2022-04-03T11:37:45,907 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.6|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953465
2022-04-03T11:37:54,326 [INFO ] KQueueEventLoopGroup-3-5 ACCESS_LOG - /127.0.0.1:54595 "POST /prediction HTTP/1.1" 404 0
2022-04-03T11:37:54,328 [INFO ] KQueueEventLoopGroup-3-5 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:38:06,860 [INFO ] KQueueEventLoopGroup-3-6 ACCESS_LOG - /127.0.0.1:54597 "POST /predictions HTTP/1.1" 404 0
2022-04-03T11:38:06,861 [INFO ] KQueueEventLoopGroup-3-6 TS_METRICS - Requests4XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:38:14,931 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953494931
2022-04-03T11:38:14,931 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953494931
2022-04-03T11:38:14,939 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648953494
2022-04-03T11:38:14,942 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8
2022-04-03T11:38:14,942 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 8
2022-04-03T11:38:14,942 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:38:14,942 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [{'body': {'text': 'Bloomberg has decided to publish a new report on the global economy.', 'target': 1}}]
2022-04-03T11:38:14,942 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - <class 'list'>
2022-04-03T11:38:14,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:38:14,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:38:14,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:38:14,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:38:14,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:38:14,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:38:14,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:38:14,945 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d/RobertaModel_handler.py", line 101, in preprocess
2022-04-03T11:38:14,946 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:38:14,946 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:38:14,946 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:38:14,946 [INFO ] W-9005-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54599 "POST /predictions/my_tc HTTP/1.1" 503 17
2022-04-03T11:38:14,946 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:38:14,946 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:38:14,946 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:38:14,946 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:38:14,946 [INFO ] W-9005-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:38:14,946 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:38:14,947 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 122709, Inference time ns: 15934750
2022-04-03T11:38:14,947 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:38:14,947 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 122709, Inference time ns: 15934750
2022-04-03T11:38:14,947 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:38:14,947 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:38:45,902 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953525
2022-04-03T11:38:45,912 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29231643676758|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953525
2022-04-03T11:38:45,913 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.98154830932617|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953525
2022-04-03T11:38:45,913 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953525
2022-04-03T11:38:45,913 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1331.21875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953525
2022-04-03T11:38:45,913 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2531.59375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953525
2022-04-03T11:38:45,913 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.7|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953525
2022-04-03T11:38:58,213 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953538212
2022-04-03T11:38:58,213 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953538212
2022-04-03T11:38:58,227 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648953538
2022-04-03T11:38:58,232 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:38:58,232 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [{'body': bytearray(b'i hate englist')}]
2022-04-03T11:38:58,233 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - <class 'list'>
2022-04-03T11:38:58,233 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:38:58,233 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:38:58,233 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:38:58,233 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:38:58,235 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13
2022-04-03T11:38:58,235 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 13
2022-04-03T11:38:58,235 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:38:58,236 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:38:58,236 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:38:58,236 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d/RobertaModel_handler.py", line 101, in preprocess
2022-04-03T11:38:58,236 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:38:58,236 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:38:58,236 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:38:58,236 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:38:58,236 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:38:58,237 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:38:58,237 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:38:58,238 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:38:58,238 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:38:58,239 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:38:58,237 [INFO ] W-9006-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54602 "POST /predictions/my_tc HTTP/1.1" 503 28
2022-04-03T11:38:58,244 [INFO ] W-9006-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:38:58,244 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1286833, Inference time ns: 33619875
2022-04-03T11:38:58,244 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1286833, Inference time ns: 33619875
2022-04-03T11:38:58,244 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:19|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:39:45,872 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953585
2022-04-03T11:39:45,874 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29232025146484|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953585
2022-04-03T11:39:45,875 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.9815444946289|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953585
2022-04-03T11:39:45,875 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953585
2022-04-03T11:39:45,875 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1299.46875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953585
2022-04-03T11:39:45,875 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2570.390625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953585
2022-04-03T11:39:45,875 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:84.1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953585
2022-04-03T11:39:48,729 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953588728
2022-04-03T11:39:48,729 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953588728
2022-04-03T11:39:48,734 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648953588
2022-04-03T11:39:48,743 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11
2022-04-03T11:39:48,742 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:39:48,743 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11
2022-04-03T11:39:48,745 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [{'body': {'text': '  '}}]
2022-04-03T11:39:48,746 [INFO ] W-9003-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54604 "POST /predictions/my_tc HTTP/1.1" 503 19
2022-04-03T11:39:48,748 [INFO ] W-9003-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:39:48,749 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - <class 'list'>
2022-04-03T11:39:48,749 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 758250, Inference time ns: 21198500
2022-04-03T11:39:48,749 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 758250, Inference time ns: 21198500
2022-04-03T11:39:48,749 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:10|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:39:48,749 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:39:48,749 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:39:48,749 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:39:48,755 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:39:48,755 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:39:48,756 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:39:48,756 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:39:48,756 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d/RobertaModel_handler.py", line 101, in preprocess
2022-04-03T11:39:48,756 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:39:48,756 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:39:48,756 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:39:48,756 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:39:48,757 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:39:48,758 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:39:48,759 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:39:48,760 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:39:48,760 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:39:48,760 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:40:43,723 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953643723
2022-04-03T11:40:43,723 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953643723
2022-04-03T11:40:43,731 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648953643
2022-04-03T11:40:43,739 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [{'body': bytearray(b'{"text":"\xeb\x82\x98\xeb\x8a\x94 \xea\xb3\xb5\xeb\xb6\x80\xed\x95\x98\xea\xb8\xb0\xea\xb0\x80 \xec\x8b\x9c\xeb\x9f\xac\xec\x9a\x94"}')}]
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - <class 'list'>
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d/RobertaModel_handler.py", line 101, in preprocess
2022-04-03T11:40:43,740 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 15
2022-04-03T11:40:43,741 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:40:43,741 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:40:43,742 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:40:43,741 [INFO ] W-9002-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54608 "POST /predictions/my_tc HTTP/1.1" 503 18
2022-04-03T11:40:43,742 [INFO ] W-9002-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:40:43,742 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:40:43,742 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 413167, Inference time ns: 19621708
2022-04-03T11:40:43,742 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 413167, Inference time ns: 19621708
2022-04-03T11:40:43,743 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:40:43,744 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:40:43,745 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:40:43,746 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:40:43,747 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:40:43,747 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:40:43,748 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:40:46,429 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953646
2022-04-03T11:40:46,430 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29124450683594|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953646
2022-04-03T11:40:46,431 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.98262023925781|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953646
2022-04-03T11:40:46,431 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953646
2022-04-03T11:40:46,431 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1353.09375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953646
2022-04-03T11:40:46,431 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2522.984375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953646
2022-04-03T11:40:46,431 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.5|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953646
2022-04-03T11:40:53,839 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953653837
2022-04-03T11:40:53,839 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953653837
2022-04-03T11:40:53,849 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648953653
2022-04-03T11:40:53,854 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11
2022-04-03T11:40:53,854 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:40:53,854 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 11
2022-04-03T11:40:53,854 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [{'body': bytearray(b'{"text":"\xeb\x82\x98\xeb\x8a\x94 \xea\xb3\xb5\xeb\xb6\x80\xed\x95\x98\xea\xb8\xb0\xea\xb0\x80 \xec\x8b\x9c\xeb\x9f\xac\xec\x9a\x94"}')}]
2022-04-03T11:40:53,854 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - <class 'list'>
2022-04-03T11:40:53,854 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:40:53,854 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:40:53,854 [INFO ] W-9001-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54611 "POST /predictions/my_tc HTTP/1.1" 503 17
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d/RobertaModel_handler.py", line 101, in preprocess
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:40:53,855 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:40:53,855 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 190375, Inference time ns: 18614000
2022-04-03T11:40:53,856 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:40:53,855 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 190375, Inference time ns: 18614000
2022-04-03T11:40:53,856 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:40:53,857 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:40:53,857 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:41:26,798 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953686798
2022-04-03T11:41:26,798 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953686798
2022-04-03T11:41:26,805 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648953686
2022-04-03T11:41:26,810 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10
2022-04-03T11:41:26,810 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 10
2022-04-03T11:41:26,810 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:41:26,810 [INFO ] W-9004-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54615 "POST /predictions/my_tc HTTP/1.1" 503 12
2022-04-03T11:41:26,811 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [{'body': {'name': '', 'text': '  '}}]
2022-04-03T11:41:26,811 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - <class 'list'>
2022-04-03T11:41:26,811 [INFO ] W-9004-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:41:26,811 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:41:26,811 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:41:26,812 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 92541, Inference time ns: 13568666
2022-04-03T11:41:26,812 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 92541, Inference time ns: 13568666
2022-04-03T11:41:26,812 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:41:26,812 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:41:26,812 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:41:26,813 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:41:26,815 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:41:26,816 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:41:26,816 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d/RobertaModel_handler.py", line 101, in preprocess
2022-04-03T11:41:26,816 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:41:26,816 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:41:26,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:41:26,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:41:26,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:41:26,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:41:26,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:41:26,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:41:26,821 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:41:26,821 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:41:41,364 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953701364
2022-04-03T11:41:41,364 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648953701364
2022-04-03T11:41:41,369 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648953701
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [{'body': {'name': '', 'text': '  '}}]
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - <class 'list'>
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 4
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T11:41:41,371 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54617 "POST /predictions/my_tc HTTP/1.1" 503 7
2022-04-03T11:41:41,373 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/8e5bd6881d72465b879446bbb4b4142d/RobertaModel_handler.py", line 101, in preprocess
2022-04-03T11:41:41,374 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     input = torch.tensor(self.tokenizer.encode(requests), device=self.device)
2022-04-03T11:41:41,374 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2226, in encode
2022-04-03T11:41:41,374 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     encoded_inputs = self.encode_plus(
2022-04-03T11:41:41,373 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:41:41,374 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_base.py", line 2556, in encode_plus
2022-04-03T11:41:41,374 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return self._encode_plus(
2022-04-03T11:41:41,374 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 499, in _encode_plus
2022-04-03T11:41:41,374 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     batched_output = self._batch_encode_plus(
2022-04-03T11:41:41,374 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py", line 426, in _batch_encode_plus
2022-04-03T11:41:41,374 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     encodings = self._tokenizer.encode_batch(
2022-04-03T11:41:41,375 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - TypeError: TextEncodeInput must be Union[TextInputSequence, Tuple[InputSequence, InputSequence]]
2022-04-03T11:41:41,375 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 181250, Inference time ns: 11129291
2022-04-03T11:41:41,375 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 181250, Inference time ns: 11129291
2022-04-03T11:41:41,375 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:7|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:41:45,880 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953705
2022-04-03T11:41:45,884 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:102.29490661621094|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953705
2022-04-03T11:41:45,885 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:125.97895812988281|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953705
2022-04-03T11:41:45,888 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953705
2022-04-03T11:41:45,889 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:1422.8125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953705
2022-04-03T11:41:45,889 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:2500.359375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953705
2022-04-03T11:41:45,889 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:82.6|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648953705
2022-04-03T11:48:55,393 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:48:55,393 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:48:55,956 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:48:55,956 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:48:55,968 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:48:55,968 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:48:56,053 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:48:56,053 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:49:06,961 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:49:06,961 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:49:06,962 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:49:06,962 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:49:06,962 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:49:06,962 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:49:06,963 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:49:06,963 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:49:07,013 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:49:07,013 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:49:07,013 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:49:07,016 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:49:07,017 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:49:07,012 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:49:07,013 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:49:07,013 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:49:07,016 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:49:07,020 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:49:07,012 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:49:07,013 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:49:07,013 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:49:07,012 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:49:07,012 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:49:07,013 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:49:07,017 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:49:07,020 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:49:07,906 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:49:07,906 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:49:07,907 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:49:07,907 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:49:07,913 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:49:07,913 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:49:07,914 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:49:07,914 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:49:07,918 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:49:07,918 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:49:08,357 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:49:08,365 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]29307
2022-04-03T11:49:08,367 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:49:08,367 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:49:08,369 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,369 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,462 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:49:08,462 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:49:08,528 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T11:49:08,522 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:49:08,553 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]29302
2022-04-03T11:49:08,555 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,555 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:49:08,555 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,556 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:49:08,556 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:49:08,556 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:49:08,557 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:49:08,564 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:49:08,566 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:49:08,571 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]29305
2022-04-03T11:49:08,570 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]29303
2022-04-03T11:49:08,572 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,572 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,572 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:49:08,572 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:49:08,572 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,572 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,572 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:49:08,572 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:49:08,572 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:49:08,572 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:49:08,572 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:49:08,572 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:49:08,604 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T11:49:08,571 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]29301
2022-04-03T11:49:08,614 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T11:49:08,648 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,648 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,648 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T11:49:08,647 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:49:08,663 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148663
2022-04-03T11:49:08,663 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148663
2022-04-03T11:49:08,663 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148663
2022-04-03T11:49:08,663 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148663
2022-04-03T11:49:08,660 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:49:08,663 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148663
2022-04-03T11:49:08,663 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148663
2022-04-03T11:49:08,663 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148663
2022-04-03T11:49:08,663 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148663
2022-04-03T11:49:08,671 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:49:08,616 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:49:08,675 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]29308
2022-04-03T11:49:08,676 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:49:08,676 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:49:08,671 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:49:08,677 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,677 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,571 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:49:08,605 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:49:08,681 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:49:08,681 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:49:08,684 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]29306
2022-04-03T11:49:08,697 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T11:49:08,698 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:49:08,698 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,685 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]29304
2022-04-03T11:49:08,704 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148697
2022-04-03T11:49:08,708 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:49:08,698 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,711 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:49:08,711 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,711 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:49:08,712 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:49:08,712 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:49:08,704 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:49:08,712 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:49:08,704 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148697
2022-04-03T11:49:08,712 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:49:08,744 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148740
2022-04-03T11:49:08,744 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148740
2022-04-03T11:49:08,744 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148740
2022-04-03T11:49:08,744 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148740
2022-04-03T11:49:08,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T11:49:08,748 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148738
2022-04-03T11:49:08,740 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T11:49:08,740 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T11:49:08,748 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954148738
2022-04-03T11:49:08,841 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:49:08,840 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:49:08,839 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:49:08,840 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:49:08,841 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:49:08,841 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:49:08,842 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:49:08,842 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:49:09,026 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954149
2022-04-03T11:49:09,032 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.29389190673828|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954149
2022-04-03T11:49:09,033 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:124.97997283935547|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954149
2022-04-03T11:49:09,033 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954149
2022-04-03T11:49:09,034 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2952.1875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954149
2022-04-03T11:49:09,035 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4191.734375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954149
2022-04-03T11:49:09,036 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:64.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954149
2022-04-03T11:49:09,248 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:49:09,248 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:49:09,248 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:49:09,247 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:49:09,247 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:49:09,247 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:49:09,248 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:49:09,247 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:49:29,208 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']
2022-04-03T11:49:29,316 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:49:29,209 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']
2022-04-03T11:49:29,209 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']
2022-04-03T11:49:29,208 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias']
2022-04-03T11:49:29,336 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:49:29,336 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:49:29,336 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:49:29,336 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:49:29,251 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias']
2022-04-03T11:49:29,208 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']
2022-04-03T11:49:29,346 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:49:29,209 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
2022-04-03T11:49:29,349 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:49:29,346 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:49:29,208 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']
2022-04-03T11:49:48,355 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,355 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,355 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,355 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,355 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,356 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39512
2022-04-03T11:49:48,356 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39512
2022-04-03T11:49:48,357 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:29,349 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:49:48,357 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,355 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,229 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/6136fcf01c5044cdac08b5d5742620b8 loaded successfully
2022-04-03T11:49:48,355 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,355 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,355 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,107 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/6136fcf01c5044cdac08b5d5742620b8 loaded successfully
2022-04-03T11:49:48,355 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39510
2022-04-03T11:49:48,356 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39512
2022-04-03T11:49:48,059 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/6136fcf01c5044cdac08b5d5742620b8 loaded successfully
2022-04-03T11:49:48,154 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/6136fcf01c5044cdac08b5d5742620b8 loaded successfully
2022-04-03T11:49:48,175 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/6136fcf01c5044cdac08b5d5742620b8 loaded successfully
2022-04-03T11:49:48,184 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/6136fcf01c5044cdac08b5d5742620b8 loaded successfully
2022-04-03T11:49:48,676 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,676 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,676 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,676 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,676 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,676 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,676 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,676 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,676 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:29,352 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:49:48,676 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:29,352 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:49:29,353 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:49:29,351 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:49:48,066 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/6136fcf01c5044cdac08b5d5742620b8 loaded successfully
2022-04-03T11:49:29,350 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:49:29,349 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:49:29,356 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:49:48,675 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:49:48,676 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,674 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:49:48,676 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,356 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 39512
2022-04-03T11:49:48,675 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:49:48,676 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,676 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,059 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/6136fcf01c5044cdac08b5d5742620b8 loaded successfully
2022-04-03T11:49:48,675 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:49:48,675 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:49:48,675 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:49:48,675 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:49:48,723 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,687 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:41698|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954188
2022-04-03T11:49:48,688 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:49:48,687 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:41707|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954188
2022-04-03T11:49:48,700 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:49:48,688 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:49:48,687 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:41700|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954188
2022-04-03T11:49:48,700 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:49:48,700 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:49:48,687 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:49:48,687 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:49:48,755 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:582|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:49:48,724 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:41734|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954188
2022-04-03T11:49:48,754 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:504|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:49:48,723 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:41740|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954188
2022-04-03T11:49:48,756 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:49:48,756 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:583|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:49:48,756 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:583|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:49:48,750 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:543|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:49:48,724 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:41741|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954188
2022-04-03T11:49:48,757 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:507|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:49:48,724 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:49:48,723 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:49:48,757 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:49:48,723 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:49:48,755 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:49:48,757 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:49:48,723 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:41735|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954188
2022-04-03T11:49:48,759 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:509|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:49:48,757 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:41772|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954188
2022-04-03T11:49:48,760 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:585|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:49:48,763 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:49:48,762 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:49:48,762 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:49:48,763 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:50:09,539 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954209
2022-04-03T11:50:09,542 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29310607910156|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954209
2022-04-03T11:50:09,549 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.98075866699219|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954209
2022-04-03T11:50:09,549 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954209
2022-04-03T11:50:09,549 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1381.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954209
2022-04-03T11:50:09,549 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2659.3125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954209
2022-04-03T11:50:09,549 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954209
2022-04-03T11:50:17,160 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954217160
2022-04-03T11:50:17,160 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954217160
2022-04-03T11:50:17,167 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648954217
2022-04-03T11:50:17,433 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model: my_tc, Invalid return type: <class 'str'>.
2022-04-03T11:50:17,435 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 271
2022-04-03T11:50:17,435 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 271
2022-04-03T11:50:17,434 [INFO ] W-9004-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:265.58|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:3ab7c01b-a28f-48be-b8b5-c32118a3cc61,timestamp:1648954217
2022-04-03T11:50:17,455 [INFO ] W-9004-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54733 "POST /predictions/my_tc HTTP/1.1" 503 307
2022-04-03T11:50:17,455 [INFO ] W-9004-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:50:17,456 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 196000, Inference time ns: 296429333
2022-04-03T11:50:17,456 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 196000, Inference time ns: 296429333
2022-04-03T11:50:17,458 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:27|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:51:34,945 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:51:34,945 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:51:35,328 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:51:35,328 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:51:35,339 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:51:35,339 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:51:35,372 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:51:35,372 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:51:46,367 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:51:46,367 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:51:46,368 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:51:46,368 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:51:46,368 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:51:46,368 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:51:46,369 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:51:46,369 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:51:46,435 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:51:46,435 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:51:46,432 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:51:46,432 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:51:46,431 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:51:46,435 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:51:46,436 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:51:46,439 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:51:46,432 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:51:46,431 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:51:46,440 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:51:46,440 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:51:46,435 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:51:46,436 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:51:46,432 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:51:46,439 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:51:46,440 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:51:46,440 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:51:47,146 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:51:47,146 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:51:47,147 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:51:47,147 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:51:47,152 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:51:47,152 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:51:47,153 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:51:47,153 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:51:47,155 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:51:47,155 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:51:47,557 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:51:47,569 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]29807
2022-04-03T11:51:47,570 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:51:47,571 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:51:47,588 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:47,588 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:47,658 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:51:47,658 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:51:47,732 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T11:51:47,761 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-03T11:51:47,761 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-03T11:51:47,787 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954307787
2022-04-03T11:51:47,787 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954307787
2022-04-03T11:51:47,853 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:51:47,870 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954307
2022-04-03T11:51:47,872 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.29850387573242|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954307
2022-04-03T11:51:47,875 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:124.97536087036133|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954307
2022-04-03T11:51:47,877 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.7|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954307
2022-04-03T11:51:47,877 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2939.90625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954307
2022-04-03T11:51:47,878 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4218.40625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954307
2022-04-03T11:51:47,879 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:64.1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954307
2022-04-03T11:51:48,010 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:51:48,010 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:51:48,015 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:51:48,024 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]29806
2022-04-03T11:51:48,025 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]29803
2022-04-03T11:51:48,025 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]29809
2022-04-03T11:51:48,015 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:51:48,025 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:51:48,025 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:51:48,026 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]29808
2022-04-03T11:51:48,017 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:51:48,026 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:51:48,026 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:51:48,026 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:51:48,026 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]29810
2022-04-03T11:51:48,027 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:51:48,027 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:51:48,027 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:51:48,027 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:51:48,027 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:51:48,027 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:51:48,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]29805
2022-04-03T11:51:48,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:51:48,033 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:51:48,033 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,033 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,033 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,033 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,033 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,033 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,033 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,033 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,034 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:51:48,034 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:51:48,034 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:51:48,034 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:51:48,034 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:51:48,034 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:51:48,034 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:51:48,034 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:51:48,034 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,034 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,034 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,069 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308069
2022-04-03T11:51:48,070 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:51:48,070 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308067
2022-04-03T11:51:48,069 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308069
2022-04-03T11:51:48,034 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,070 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308067
2022-04-03T11:51:48,069 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308069
2022-04-03T11:51:48,055 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T11:51:48,062 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T11:51:48,079 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:51:48,070 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308067
2022-04-03T11:51:48,079 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:51:48,063 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T11:51:48,070 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:51:48,069 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T11:51:48,070 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308067
2022-04-03T11:51:48,069 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308069
2022-04-03T11:51:48,056 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:51:48,138 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308138
2022-04-03T11:51:48,138 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308138
2022-04-03T11:51:48,124 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:51:48,123 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]29804
2022-04-03T11:51:48,138 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T11:51:48,138 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T11:51:48,192 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:51:48,208 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:51:48,197 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,197 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:51:48,199 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:51:48,211 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:51:48,138 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:51:48,211 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:51:48,138 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308138
2022-04-03T11:51:48,138 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308138
2022-04-03T11:51:48,186 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:51:48,297 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:51:48,297 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:51:48,310 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:51:48,313 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308312
2022-04-03T11:51:48,313 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954308312
2022-04-03T11:51:48,310 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T11:51:48,396 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:51:48,445 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:51:48,461 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:51:48,476 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:51:48,516 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:51:48,588 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:51:48,612 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:51:48,664 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:52:06,026 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']
2022-04-03T11:52:05,967 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']
2022-04-03T11:52:05,966 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
2022-04-03T11:52:05,968 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']
2022-04-03T11:52:05,965 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']
2022-04-03T11:52:05,967 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']
2022-04-03T11:52:05,966 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']
2022-04-03T11:52:06,003 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.bias']
2022-04-03T11:52:06,861 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:52:06,860 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:52:06,860 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:52:06,858 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:52:06,874 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:52:06,874 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:52:06,874 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:52:06,877 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:52:06,878 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:52:06,878 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:52:06,877 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:52:06,877 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:52:06,878 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:52:06,878 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:52:10,289 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:52:10,289 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:52:10,289 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:52:10,289 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:52:10,632 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:52:10,705 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:52:10,693 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:52:10,289 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:52:10,604 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:52:13,387 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:52:13,380 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:52:10,604 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:52:13,379 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:52:13,380 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:52:13,379 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:52:13,945 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:52:19,025 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:52:19,491 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:52:20,381 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/5bcfab0e2aa145beb94fd48a821bccd3 loaded successfully
2022-04-03T11:52:20,385 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/5bcfab0e2aa145beb94fd48a821bccd3 loaded successfully
2022-04-03T11:52:20,419 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/5bcfab0e2aa145beb94fd48a821bccd3 loaded successfully
2022-04-03T11:52:20,455 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:52:20,459 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/5bcfab0e2aa145beb94fd48a821bccd3 loaded successfully
2022-04-03T11:52:20,473 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/5bcfab0e2aa145beb94fd48a821bccd3 loaded successfully
2022-04-03T11:52:20,456 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:52:20,457 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:52:20,556 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:52:20,556 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:52:20,574 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/5bcfab0e2aa145beb94fd48a821bccd3 loaded successfully
2022-04-03T11:52:20,577 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:52:20,643 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/5bcfab0e2aa145beb94fd48a821bccd3 loaded successfully
2022-04-03T11:52:20,644 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:52:20,666 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/5bcfab0e2aa145beb94fd48a821bccd3 loaded successfully
2022-04-03T11:52:20,669 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T11:52:20,782 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32925
2022-04-03T11:52:20,782 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32660
2022-04-03T11:52:20,782 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32613
2022-04-03T11:52:20,782 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32644
2022-04-03T11:52:20,782 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32472
2022-04-03T11:52:20,782 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32583
2022-04-03T11:52:20,782 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32505
2022-04-03T11:52:20,782 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32394
2022-04-03T11:52:20,782 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32660
2022-04-03T11:52:20,782 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32925
2022-04-03T11:52:20,782 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32394
2022-04-03T11:52:20,782 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32472
2022-04-03T11:52:20,936 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:20,936 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:20,936 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:20,936 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:20,782 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32644
2022-04-03T11:52:20,782 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32505
2022-04-03T11:52:20,936 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:20,782 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32583
2022-04-03T11:52:20,936 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:20,936 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:20,936 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:20,782 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32613
2022-04-03T11:52:21,011 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:21,011 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:21,011 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:21,011 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:21,011 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:21,011 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:21,012 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:21,012 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T11:52:21,012 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:34617|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954341
2022-04-03T11:52:21,014 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:34617|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954341
2022-04-03T11:52:21,013 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:34622|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954341
2022-04-03T11:52:21,013 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:34619|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954341
2022-04-03T11:52:21,017 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:34623|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954341
2022-04-03T11:52:21,022 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:379|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:21,014 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:34617|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954341
2022-04-03T11:52:21,012 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:34617|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954341
2022-04-03T11:52:21,022 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:311|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:21,013 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:34617|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954341
2022-04-03T11:52:21,071 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:359|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:21,071 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:365|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:21,071 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:419|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:21,071 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:461|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:21,071 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:391|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:21,071 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:342|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:30,828 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954350828
2022-04-03T11:52:30,828 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954350828
2022-04-03T11:52:30,838 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648954350
2022-04-03T11:52:31,087 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model: my_tc, number of batch response mismatched, expect: 1, got: 5.
2022-04-03T11:52:31,088 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 255
2022-04-03T11:52:31,088 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 255
2022-04-03T11:52:31,090 [INFO ] W-9007-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:247.25|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:62490a41-415f-4c05-bdaa-3d50d0d2548e,timestamp:1648954351
2022-04-03T11:52:31,119 [INFO ] W-9007-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54852 "POST /predictions/my_tc HTTP/1.1" 503 304
2022-04-03T11:52:31,119 [INFO ] W-9007-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:31,120 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 314750, Inference time ns: 292200959
2022-04-03T11:52:31,120 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 314750, Inference time ns: 292200959
2022-04-03T11:52:31,120 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:37|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:37,663 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954357663
2022-04-03T11:52:37,663 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954357663
2022-04-03T11:52:37,668 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648954357
2022-04-03T11:52:37,878 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model: my_tc, number of batch response mismatched, expect: 1, got: 5.
2022-04-03T11:52:37,880 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 215
2022-04-03T11:52:37,880 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 215
2022-04-03T11:52:37,879 [INFO ] W-9003-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:208.49|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:2e8772e3-465b-48e8-ab3e-eddde0dec093,timestamp:1648954357
2022-04-03T11:52:37,881 [INFO ] W-9003-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54854 "POST /predictions/my_tc HTTP/1.1" 503 219
2022-04-03T11:52:37,882 [INFO ] W-9003-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:37,883 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 243500, Inference time ns: 219933584
2022-04-03T11:52:37,883 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 243500, Inference time ns: 219933584
2022-04-03T11:52:37,895 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:17|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T11:52:48,431 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954368
2022-04-03T11:52:48,434 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29536437988281|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954368
2022-04-03T11:52:48,434 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.97850036621094|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954368
2022-04-03T11:52:48,434 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954368
2022-04-03T11:52:48,434 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1655.34375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954368
2022-04-03T11:52:48,435 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2893.9375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954368
2022-04-03T11:52:48,435 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:79.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954368
2022-04-03T11:53:47,843 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954427
2022-04-03T11:53:47,845 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29298400878906|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954427
2022-04-03T11:53:47,845 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.98088073730469|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954427
2022-04-03T11:53:47,845 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954427
2022-04-03T11:53:47,845 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1354.046875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954427
2022-04-03T11:53:47,846 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2485.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954427
2022-04-03T11:53:47,846 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.5|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954427
2022-04-03T11:54:47,816 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954487
2022-04-03T11:54:47,818 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.29309844970703|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954487
2022-04-03T11:54:47,818 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.98076629638672|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954487
2022-04-03T11:54:47,818 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954487
2022-04-03T11:54:47,818 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1304.65625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954487
2022-04-03T11:54:47,818 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2538.375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954487
2022-04-03T11:54:47,818 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:84.1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954487
2022-04-03T11:55:47,803 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954547
2022-04-03T11:55:47,814 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:102.28893280029297|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954547
2022-04-03T11:55:47,814 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:125.98493194580078|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954547
2022-04-03T11:55:47,814 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954547
2022-04-03T11:55:47,814 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:1337.796875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954547
2022-04-03T11:55:47,814 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:2514.765625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954547
2022-04-03T11:55:47,814 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:83.7|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954547
2022-04-03T11:56:47,780 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954607
2022-04-03T11:56:47,783 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:102.28192520141602|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954607
2022-04-03T11:56:47,783 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:125.99193954467773|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954607
2022-04-03T11:56:47,783 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954607
2022-04-03T11:56:47,784 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:1302.71875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954607
2022-04-03T11:56:47,784 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:2573.890625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954607
2022-04-03T11:56:47,784 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:84.1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954607
2022-04-03T11:57:47,795 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954667
2022-04-03T11:57:47,799 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:102.2822494506836|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954667
2022-04-03T11:57:47,799 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:125.99161529541016|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954667
2022-04-03T11:57:47,799 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954667
2022-04-03T11:57:47,799 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:1394.90625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954667
2022-04-03T11:57:47,799 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:2547.09375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954667
2022-04-03T11:57:47,799 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:83.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954667
2022-04-03T11:59:22,745 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:59:22,745 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T11:59:23,327 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:59:23,327 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T11:59:23,338 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:59:23,338 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T11:59:23,371 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:59:23,371 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T11:59:34,120 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:59:34,120 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T11:59:34,121 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:59:34,121 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T11:59:34,122 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:59:34,122 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T11:59:34,122 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:59:34,122 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T11:59:34,198 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:59:34,188 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:59:34,190 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:59:34,190 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:59:34,188 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:59:34,198 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T11:59:34,189 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:59:34,190 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:59:34,199 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:59:34,189 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T11:59:34,188 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T11:59:34,190 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T11:59:34,203 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:59:34,190 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T11:59:34,199 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T11:59:34,190 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T11:59:34,188 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T11:59:34,203 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T11:59:35,090 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:59:35,090 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T11:59:35,092 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:59:35,092 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T11:59:35,096 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:59:35,096 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T11:59:35,097 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:59:35,097 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T11:59:35,098 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:59:35,098 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T11:59:35,272 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:59:35,329 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]30543
2022-04-03T11:59:35,330 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:59:35,331 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:59:35,333 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,333 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,363 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:59:35,363 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T11:59:35,450 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T11:59:35,457 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775457
2022-04-03T11:59:35,457 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775457
2022-04-03T11:59:35,529 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:59:35,767 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:59:35,768 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:59:35,768 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:59:35,787 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:59:35,768 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:59:35,768 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:59:35,792 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]30542
2022-04-03T11:59:35,794 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]30540
2022-04-03T11:59:35,797 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]30544
2022-04-03T11:59:35,801 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]30545
2022-04-03T11:59:35,802 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]30539
2022-04-03T11:59:35,806 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:59:35,810 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,806 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:59:35,809 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,804 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]30541
2022-04-03T11:59:35,812 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:59:35,823 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:59:35,823 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,809 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,823 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:59:35,810 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:59:35,810 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,805 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:59:35,823 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,809 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,809 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:59:35,823 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:59:35,805 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:59:35,825 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:59:35,810 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,825 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:59:35,809 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,826 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:59:35,826 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:59:35,827 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:59:35,826 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T11:59:35,826 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T11:59:35,826 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:59:35,825 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T11:59:35,827 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T11:59:35,809 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,810 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,834 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:59:35,835 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:59:35,835 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T11:59:35,834 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T11:59:35,796 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:59:35,844 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]30546
2022-04-03T11:59:35,848 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,848 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T11:59:35,848 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T11:59:35,848 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:59:35,848 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T11:59:35,849 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T11:59:35,916 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T11:59:35,912 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T11:59:35,917 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775917
2022-04-03T11:59:35,917 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775917
2022-04-03T11:59:35,916 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T11:59:35,918 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775918
2022-04-03T11:59:35,918 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775918
2022-04-03T11:59:35,918 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775918
2022-04-03T11:59:35,916 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T11:59:35,918 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775918
2022-04-03T11:59:35,918 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775918
2022-04-03T11:59:35,919 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T11:59:35,919 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775919
2022-04-03T11:59:35,915 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T11:59:35,918 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775918
2022-04-03T11:59:35,940 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775920
2022-04-03T11:59:35,919 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775919
2022-04-03T11:59:35,940 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775920
2022-04-03T11:59:35,943 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:59:35,944 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775943
2022-04-03T11:59:35,944 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954775943
2022-04-03T11:59:36,011 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:59:35,968 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T11:59:35,990 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:59:35,991 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:59:35,991 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:59:35,981 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:59:36,064 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:59:36,079 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T11:59:36,294 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:59:36,309 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:59:36,313 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:59:36,314 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:59:36,344 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:59:36,352 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:59:36,403 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T11:59:36,463 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954776
2022-04-03T11:59:36,466 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.2817268371582|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954776
2022-04-03T11:59:36,466 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:124.99213790893555|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954776
2022-04-03T11:59:36,467 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954776
2022-04-03T11:59:36,467 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2999.859375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954776
2022-04-03T11:59:36,467 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3824.328125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954776
2022-04-03T11:59:36,468 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:63.4|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954776
2022-04-03T11:59:55,924 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']
2022-04-03T11:59:55,925 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']
2022-04-03T11:59:55,945 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:59:55,923 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
2022-04-03T11:59:55,923 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']
2022-04-03T11:59:55,945 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:59:55,965 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:59:55,964 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:59:55,965 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:59:55,924 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']
2022-04-03T11:59:55,923 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.bias']
2022-04-03T11:59:55,925 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
2022-04-03T11:59:55,924 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']
2022-04-03T11:59:56,386 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:59:56,386 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:59:56,386 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:59:56,386 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:59:56,386 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:59:56,386 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T11:59:59,239 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:59:59,240 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:59:59,240 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:59:59,240 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:59:59,240 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:59:59,348 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:59:56,386 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:59:56,386 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:59:59,349 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:59:59,367 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T11:59:59,348 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T11:59:59,513 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:59:59,513 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:59:59,589 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:59:59,513 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:59:59,240 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T11:59:59,589 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:59:59,589 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T11:59:59,589 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:00:00,370 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:00:00,376 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:00:07,281 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/76905d25aa124253a56b34085bc02aec loaded successfully
2022-04-03T12:00:07,279 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/76905d25aa124253a56b34085bc02aec loaded successfully
2022-04-03T12:00:07,281 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/76905d25aa124253a56b34085bc02aec loaded successfully
2022-04-03T12:00:07,280 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/76905d25aa124253a56b34085bc02aec loaded successfully
2022-04-03T12:00:07,309 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/76905d25aa124253a56b34085bc02aec loaded successfully
2022-04-03T12:00:07,281 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/76905d25aa124253a56b34085bc02aec loaded successfully
2022-04-03T12:00:07,280 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/76905d25aa124253a56b34085bc02aec loaded successfully
2022-04-03T12:00:07,280 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/76905d25aa124253a56b34085bc02aec loaded successfully
2022-04-03T12:00:07,318 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:00:07,319 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:00:07,318 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:00:07,318 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:00:07,318 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:00:07,319 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:00:07,320 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:00:07,318 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:00:07,852 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31864
2022-04-03T12:00:07,852 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31775
2022-04-03T12:00:07,852 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31878
2022-04-03T12:00:07,854 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31843
2022-04-03T12:00:07,852 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31832
2022-04-03T12:00:07,852 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31864
2022-04-03T12:00:07,852 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31775
2022-04-03T12:00:07,854 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31843
2022-04-03T12:00:07,852 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32320
2022-04-03T12:00:07,852 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31832
2022-04-03T12:00:07,852 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31865
2022-04-03T12:00:07,852 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32320
2022-04-03T12:00:07,852 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31878
2022-04-03T12:00:07,852 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31864
2022-04-03T12:00:07,852 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31865
2022-04-03T12:00:07,852 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 31864
2022-04-03T12:00:07,864 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,865 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,865 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,864 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:00:07,879 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:33729|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954807
2022-04-03T12:00:07,879 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:33725|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954807
2022-04-03T12:00:07,879 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:33726|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954807
2022-04-03T12:00:07,880 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:33728|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954807
2022-04-03T12:00:07,879 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:33724|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954807
2022-04-03T12:00:07,879 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:33723|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954807
2022-04-03T12:00:07,892 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:110|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:00:07,892 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:130|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:00:07,892 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:108|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:00:07,892 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:116|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:00:07,879 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:33724|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954807
2022-04-03T12:00:07,892 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:95|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:00:07,879 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:33727|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954807
2022-04-03T12:00:07,892 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:115|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:00:07,892 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:110|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:00:07,892 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:196|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:00:13,872 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954813871
2022-04-03T12:00:13,872 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648954813871
2022-04-03T12:00:13,889 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648954813
2022-04-03T12:00:13,928 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:00:13,930 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 52
2022-04-03T12:00:13,930 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 52
2022-04-03T12:00:13,932 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-03T12:00:13,937 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   
2022-04-03T12:00:13,939 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:00:13,939 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T12:00:13,939 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T12:00:13,939 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T12:00:13,939 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T12:00:13,942 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 219, in handle
2022-04-03T12:00:13,946 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     data_preprocess = self.preprocess(data)
2022-04-03T12:00:13,947 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/76905d25aa124253a56b34085bc02aec/RobertaModel_handler.py", line 106, in preprocess
2022-04-03T12:00:13,947 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     print(list(input.unsqueeze(0), input_name))
2022-04-03T12:00:13,947 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - TypeError: list expected at most 1 argument, got 2
2022-04-03T12:00:13,967 [INFO ] W-9006-my_tc_1.0 ACCESS_LOG - /127.0.0.1:54999 "POST /predictions/my_tc HTTP/1.1" 503 105
2022-04-03T12:00:13,967 [INFO ] W-9006-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:00:13,970 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 277875, Inference time ns: 99056667
2022-04-03T12:00:13,970 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 277875, Inference time ns: 99056667
2022-04-03T12:00:13,982 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:58|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:00:37,097 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954837
2022-04-03T12:00:37,100 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.2834358215332|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954837
2022-04-03T12:00:37,100 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.99042892456055|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954837
2022-04-03T12:00:37,100 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954837
2022-04-03T12:00:37,100 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1334.328125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954837
2022-04-03T12:00:37,100 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2590.640625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954837
2022-04-03T12:00:37,101 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.7|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954837
2022-04-03T12:01:36,500 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954896
2022-04-03T12:01:36,506 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.28832626342773|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954896
2022-04-03T12:01:36,506 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.98553848266602|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954896
2022-04-03T12:01:36,507 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954896
2022-04-03T12:01:36,508 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1305.59375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954896
2022-04-03T12:01:36,508 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2560.203125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954896
2022-04-03T12:01:36,508 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:84.1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954896
2022-04-03T12:02:36,482 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954956
2022-04-03T12:02:36,483 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.28443908691406|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954956
2022-04-03T12:02:36,483 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.98942565917969|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954956
2022-04-03T12:02:36,483 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954956
2022-04-03T12:02:36,483 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1347.921875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954956
2022-04-03T12:02:36,483 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2498.90625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954956
2022-04-03T12:02:36,483 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.5|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648954956
2022-04-03T12:03:32,118 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-03T12:03:32,118 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-03T12:04:29,635 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:04:29,635 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:04:30,089 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:04:30,089 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:04:30,100 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:04:30,100 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:04:30,133 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:04:30,133 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:04:40,867 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:04:40,867 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:04:40,869 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:04:40,869 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:04:40,869 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:04:40,869 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:04:40,869 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:04:40,869 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:04:40,924 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:04:40,921 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:04:40,923 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:04:40,923 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:04:40,922 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:04:40,923 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:04:40,924 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:04:40,929 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:04:40,923 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:04:40,922 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:04:40,923 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:04:40,923 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:04:40,935 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:04:40,932 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:04:40,935 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:04:40,921 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:04:40,932 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:04:40,929 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:04:41,990 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:04:41,990 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:04:41,990 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:04:41,990 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:04:41,994 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:04:41,994 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:04:41,995 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:04:41,995 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:04:41,998 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:04:41,998 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:04:42,075 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:04:42,082 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]31197
2022-04-03T12:04:42,085 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:04:42,085 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:04:42,087 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,087 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,121 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:04:42,121 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:04:42,168 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082167
2022-04-03T12:04:42,168 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T12:04:42,168 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082167
2022-04-03T12:04:42,226 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:04:42,600 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:04:42,621 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]31194
2022-04-03T12:04:42,631 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:04:42,632 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,632 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,633 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:04:42,633 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:04:42,633 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:04:42,593 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:04:42,602 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:04:42,617 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:04:42,593 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:04:42,618 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:04:42,630 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:04:42,653 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]31195
2022-04-03T12:04:42,666 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]31191
2022-04-03T12:04:42,654 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]31196
2022-04-03T12:04:42,654 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]31192
2022-04-03T12:04:42,663 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]31193
2022-04-03T12:04:42,660 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]31198
2022-04-03T12:04:42,668 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:04:42,670 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:04:42,668 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:04:42,671 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:04:42,672 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,672 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,672 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,672 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,673 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:04:42,673 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,673 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:04:42,673 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,673 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T12:04:42,673 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:04:42,673 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:04:42,673 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:04:42,674 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:04:42,677 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:04:42,689 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,683 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082682
2022-04-03T12:04:42,690 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T12:04:42,688 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,680 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:04:42,681 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:04:42,688 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,689 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,689 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,688 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:04:42,688 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:04:42,689 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:04:42,691 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:04:42,691 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:04:42,691 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:04:42,691 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:04:42,692 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:04:42,691 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:04:42,692 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:04:42,683 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082682
2022-04-03T12:04:42,689 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:04:42,700 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082699
2022-04-03T12:04:42,692 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082691
2022-04-03T12:04:42,704 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082704
2022-04-03T12:04:42,700 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082699
2022-04-03T12:04:42,700 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T12:04:42,689 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:04:42,706 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T12:04:42,729 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082725
2022-04-03T12:04:42,729 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T12:04:42,692 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082691
2022-04-03T12:04:42,704 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082704
2022-04-03T12:04:42,732 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082731
2022-04-03T12:04:42,729 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082725
2022-04-03T12:04:42,731 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T12:04:42,746 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T12:04:42,731 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:04:42,732 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082731
2022-04-03T12:04:42,746 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:04:42,747 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082747
2022-04-03T12:04:42,747 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955082747
2022-04-03T12:04:42,762 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:04:42,838 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:04:42,838 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:04:42,838 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:04:42,839 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:04:42,851 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:04:43,048 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:04:43,084 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:04:43,170 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:04:43,183 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955083
2022-04-03T12:04:43,190 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.27820587158203|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955083
2022-04-03T12:04:43,191 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:124.99565887451172|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955083
2022-04-03T12:04:43,191 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955083
2022-04-03T12:04:43,191 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2894.015625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955083
2022-04-03T12:04:43,192 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4219.53125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955083
2022-04-03T12:04:43,192 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:64.7|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955083
2022-04-03T12:04:43,209 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:04:43,208 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:04:43,205 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:04:43,209 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:05:01,523 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias']
2022-04-03T12:05:01,523 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']
2022-04-03T12:05:01,523 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias']
2022-04-03T12:05:01,524 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']
2022-04-03T12:05:01,523 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']
2022-04-03T12:05:01,524 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']
2022-04-03T12:05:01,524 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']
2022-04-03T12:05:02,825 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:05:02,825 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:05:02,825 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:05:02,827 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:05:02,825 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:05:03,197 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:05:01,523 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
2022-04-03T12:05:02,984 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:05:02,826 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:05:02,999 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:05:05,402 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:05:02,984 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:05:05,397 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:05:05,397 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:05:05,399 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:05:06,167 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:05:06,167 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:05:06,167 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:05:06,167 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:05:06,212 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:05:06,167 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:05:06,167 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:05:06,673 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:05:06,674 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:05:06,211 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:05:06,167 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:05:06,674 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:05:06,674 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:05:07,570 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:05:07,570 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:05:07,575 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:05:07,574 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:05:07,608 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:05:15,458 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/72b47fcfce304c14a72244dd939986fc loaded successfully
2022-04-03T12:05:15,459 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/72b47fcfce304c14a72244dd939986fc loaded successfully
2022-04-03T12:05:15,459 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/72b47fcfce304c14a72244dd939986fc loaded successfully
2022-04-03T12:05:15,514 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:05:15,458 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/72b47fcfce304c14a72244dd939986fc loaded successfully
2022-04-03T12:05:15,514 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:05:15,463 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/72b47fcfce304c14a72244dd939986fc loaded successfully
2022-04-03T12:05:15,514 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:05:15,521 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:05:15,458 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/72b47fcfce304c14a72244dd939986fc loaded successfully
2022-04-03T12:05:15,458 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/72b47fcfce304c14a72244dd939986fc loaded successfully
2022-04-03T12:05:15,526 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:05:15,526 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:05:15,514 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:05:15,458 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/72b47fcfce304c14a72244dd939986fc loaded successfully
2022-04-03T12:05:15,725 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:05:16,072 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33846
2022-04-03T12:05:16,072 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33250
2022-04-03T12:05:16,072 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33241
2022-04-03T12:05:16,072 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33234
2022-04-03T12:05:16,072 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33234
2022-04-03T12:05:16,072 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33308
2022-04-03T12:05:16,072 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33225
2022-04-03T12:05:16,072 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33325
2022-04-03T12:05:16,072 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33846
2022-04-03T12:05:16,072 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33241
2022-04-03T12:05:16,072 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33325
2022-04-03T12:05:16,072 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33308
2022-04-03T12:05:16,072 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33234
2022-04-03T12:05:16,072 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33225
2022-04-03T12:05:16,072 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33250
2022-04-03T12:05:16,079 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,079 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,079 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,079 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,079 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,079 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,072 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33234
2022-04-03T12:05:16,079 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,080 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,079 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,080 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,079 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,079 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,079 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,082 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:35193|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955116
2022-04-03T12:05:16,079 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,082 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:35195|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955116
2022-04-03T12:05:16,079 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,082 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:35193|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955116
2022-04-03T12:05:16,079 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:05:16,082 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:35195|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955116
2022-04-03T12:05:16,347 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:405|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:05:16,347 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:340|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:05:16,347 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:334|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:05:16,347 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:365|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:05:16,346 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:35457|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955116
2022-04-03T12:05:16,346 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:35462|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955116
2022-04-03T12:05:16,350 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:385|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:05:16,347 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:35457|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955116
2022-04-03T12:05:16,347 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:35460|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955116
2022-04-03T12:05:16,350 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:343|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:05:16,350 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:421|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:05:16,351 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:385|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:05:24,813 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955124813
2022-04-03T12:05:24,813 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955124813
2022-04-03T12:05:24,822 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648955124
2022-04-03T12:05:24,861 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 43
2022-04-03T12:05:24,861 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 43
2022-04-03T12:05:24,863 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:05:24,865 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-03T12:05:24,872 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   
2022-04-03T12:05:24,873 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:05:24,874 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - tensor([    0,   717,  2259,  4244, 31302,  2116,  1325,  2030,  2182,     2])
2022-04-03T12:05:24,875 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T12:05:24,875 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T12:05:24,875 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T12:05:24,876 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T12:05:24,877 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 222, in handle
2022-04-03T12:05:24,877 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     output = self.inference(data_preprocess)
2022-04-03T12:05:24,883 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/72b47fcfce304c14a72244dd939986fc/RobertaModel_handler.py", line 118, in inference
2022-04-03T12:05:24,883 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     input_name = input[1]
2022-04-03T12:05:24,883 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - IndexError: index 1 is out of bounds for dimension 0 with size 1
2022-04-03T12:05:24,894 [INFO ] W-9004-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55135 "POST /predictions/my_tc HTTP/1.1" 503 95
2022-04-03T12:05:24,901 [INFO ] W-9004-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:05:24,903 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 219833, Inference time ns: 90743333
2022-04-03T12:05:24,903 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 219833, Inference time ns: 90743333
2022-04-03T12:05:24,903 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:47|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:05:43,691 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:25.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955143
2022-04-03T12:05:43,693 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.27763748168945|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955143
2022-04-03T12:05:43,694 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.9962272644043|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955143
2022-04-03T12:05:43,694 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955143
2022-04-03T12:05:43,694 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1411.328125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955143
2022-04-03T12:05:43,695 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2537.609375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955143
2022-04-03T12:05:43,695 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955143
2022-04-03T12:06:43,194 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955203
2022-04-03T12:06:43,201 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.27632141113281|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955203
2022-04-03T12:06:43,202 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.99754333496094|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955203
2022-04-03T12:06:43,210 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955203
2022-04-03T12:06:43,210 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1375.6875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955203
2022-04-03T12:06:43,210 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2508.59375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955203
2022-04-03T12:06:43,211 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955203
2022-04-03T12:08:16,821 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:08:16,821 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:08:17,257 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:08:17,257 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:08:17,268 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:08:17,268 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:08:17,353 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:08:17,353 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:08:28,153 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:08:28,153 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:08:28,154 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:08:28,154 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:08:28,155 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:08:28,155 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:08:28,155 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:08:28,155 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:08:28,205 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:08:28,205 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:08:28,205 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:08:28,206 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:08:28,207 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:08:28,206 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:08:28,206 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:08:28,206 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:08:28,205 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:08:28,215 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:08:28,206 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:08:28,206 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:08:28,206 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:08:28,207 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:08:28,216 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:08:28,206 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:08:28,215 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:08:28,216 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:08:29,154 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:08:29,154 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:08:29,156 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:08:29,156 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:08:29,163 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:08:29,163 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:08:29,165 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:08:29,165 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:08:29,168 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:08:29,168 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:08:29,343 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:08:29,370 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]31911
2022-04-03T12:08:29,372 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:08:29,372 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:08:29,376 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,376 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,434 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:08:29,434 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:08:29,466 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T12:08:29,478 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955309477
2022-04-03T12:08:29,478 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955309477
2022-04-03T12:08:29,532 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:08:29,787 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:08:29,792 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:08:29,797 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]31913
2022-04-03T12:08:29,799 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]31912
2022-04-03T12:08:29,802 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:08:29,803 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,803 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,803 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:08:29,803 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,803 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,804 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:08:29,804 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:08:29,804 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:08:29,804 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:08:29,804 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:08:29,796 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:08:29,804 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:08:29,800 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:08:29,807 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]31910
2022-04-03T12:08:29,866 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]31914
2022-04-03T12:08:29,881 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,872 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:08:29,885 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,881 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,885 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,898 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:08:29,898 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:08:29,898 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:08:29,898 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:08:29,915 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955309915
2022-04-03T12:08:29,915 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955309915
2022-04-03T12:08:29,872 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:08:29,917 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:08:29,915 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955309915
2022-04-03T12:08:29,918 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T12:08:29,871 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:08:29,914 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:08:29,916 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T12:08:29,870 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:08:29,915 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955309915
2022-04-03T12:08:29,809 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:08:29,923 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]31909
2022-04-03T12:08:29,923 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]31907
2022-04-03T12:08:29,958 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,958 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,959 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955309957
2022-04-03T12:08:29,959 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955309957
2022-04-03T12:08:29,959 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:08:29,925 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:08:29,959 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:08:29,924 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:08:29,924 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]31908
2022-04-03T12:08:29,960 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:08:29,960 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,957 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,960 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:08:29,961 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:08:29,957 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,961 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:08:29,960 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:08:29,961 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955309957
2022-04-03T12:08:29,961 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955309957
2022-04-03T12:08:29,963 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:08:29,961 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:08:29,963 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:08:29,961 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:08:29,973 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:08:29,991 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:08:29,991 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T12:08:29,973 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:08:29,973 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T12:08:30,006 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955310006
2022-04-03T12:08:30,006 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955310006
2022-04-03T12:08:30,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:08:30,005 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T12:08:30,006 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T12:08:30,005 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:08:30,007 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955310007
2022-04-03T12:08:30,007 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955310007
2022-04-03T12:08:30,126 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T12:08:30,127 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:08:30,188 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955310184
2022-04-03T12:08:30,188 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955310184
2022-04-03T12:08:30,223 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:08:30,246 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:08:30,280 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:08:30,280 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:08:30,320 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:08:30,324 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:08:30,424 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:08:30,474 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:08:30,521 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:08:30,613 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955310
2022-04-03T12:08:30,619 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.27165603637695|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955310
2022-04-03T12:08:30,620 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.0022087097168|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955310
2022-04-03T12:08:30,622 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955310
2022-04-03T12:08:30,623 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2950.625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955310
2022-04-03T12:08:30,623 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4208.0625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955310
2022-04-03T12:08:30,624 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:64.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955310
2022-04-03T12:08:49,035 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias']
2022-04-03T12:08:49,035 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
2022-04-03T12:08:49,035 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
2022-04-03T12:08:49,035 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']
2022-04-03T12:08:49,035 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']
2022-04-03T12:08:49,991 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:08:49,991 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:08:49,991 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:08:49,992 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:08:49,991 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:08:49,035 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias']
2022-04-03T12:08:49,035 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']
2022-04-03T12:08:49,035 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']
2022-04-03T12:08:50,267 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:08:50,310 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:08:50,305 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:08:50,304 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:08:50,318 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:08:50,318 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:08:50,310 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:08:50,318 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:08:50,339 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:08:50,318 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:08:50,314 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:08:52,595 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:08:52,648 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:08:52,649 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:08:52,593 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:08:52,594 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:08:52,572 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:08:52,568 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:08:52,569 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:08:52,656 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:08:52,656 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:08:52,656 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:08:52,648 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:08:52,652 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:08:52,774 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:08:52,774 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:08:53,100 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:09:00,199 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/768dbf173caa4cbf9e05772354d4562f loaded successfully
2022-04-03T12:09:00,199 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/768dbf173caa4cbf9e05772354d4562f loaded successfully
2022-04-03T12:09:00,212 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/768dbf173caa4cbf9e05772354d4562f loaded successfully
2022-04-03T12:09:00,229 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/768dbf173caa4cbf9e05772354d4562f loaded successfully
2022-04-03T12:09:00,244 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/768dbf173caa4cbf9e05772354d4562f loaded successfully
2022-04-03T12:09:00,244 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/768dbf173caa4cbf9e05772354d4562f loaded successfully
2022-04-03T12:09:00,254 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/768dbf173caa4cbf9e05772354d4562f loaded successfully
2022-04-03T12:09:00,323 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/768dbf173caa4cbf9e05772354d4562f loaded successfully
2022-04-03T12:09:00,520 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30986
2022-04-03T12:09:00,520 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30560
2022-04-03T12:09:00,520 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30515
2022-04-03T12:09:00,520 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30515
2022-04-03T12:09:00,520 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30255
2022-04-03T12:09:00,520 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30561
2022-04-03T12:09:00,520 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30515
2022-04-03T12:09:00,520 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30986
2022-04-03T12:09:00,520 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30334
2022-04-03T12:09:00,523 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30404
2022-04-03T12:09:00,520 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30561
2022-04-03T12:09:00,520 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30255
2022-04-03T12:09:00,520 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30515
2022-04-03T12:09:00,520 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30560
2022-04-03T12:09:00,523 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30404
2022-04-03T12:09:00,520 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 30334
2022-04-03T12:09:00,530 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,530 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,536 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:32364|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955340
2022-04-03T12:09:00,530 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:09:00,533 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:32355|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955340
2022-04-03T12:09:00,530 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:32356|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955340
2022-04-03T12:09:00,530 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:32354|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955340
2022-04-03T12:09:00,575 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:99|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:09:00,573 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:232|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:09:00,577 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:138|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:09:00,572 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:32398|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955340
2022-04-03T12:09:00,575 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:165|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:09:00,571 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:32395|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955340
2022-04-03T12:09:00,572 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:32396|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955340
2022-04-03T12:09:00,587 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:114|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:09:00,586 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:123|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:09:00,586 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:114|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:09:00,574 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:32398|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955340
2022-04-03T12:09:00,588 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:112|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:09:03,563 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955343562
2022-04-03T12:09:03,563 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955343562
2022-04-03T12:09:03,573 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648955343
2022-04-03T12:09:03,854 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 284
2022-04-03T12:09:03,854 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:09:03,854 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 284
2022-04-03T12:09:03,856 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-03T12:09:03,864 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   
2022-04-03T12:09:03,869 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:09:03,871 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - tensor([    0,   717,  2259,  4244, 31302,  2116,  1325,  2030,  2182,     2])
2022-04-03T12:09:03,871 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:09:03,872 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - (tensor([[ 0.4208, -1.2351]], grad_fn=<AddmmBackward0>), None)
2022-04-03T12:09:03,872 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 0
2022-04-03T12:09:03,873 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:09:03,878 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model: my_tc, Invalid return type: <class 'int'>.
2022-04-03T12:09:03,879 [INFO ] W-9001-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:278.51|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:78d0ed40-db93-4b9f-9b22-f8b05d7ff2aa,timestamp:1648955343
2022-04-03T12:09:03,889 [INFO ] W-9001-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55252 "POST /predictions/my_tc HTTP/1.1" 503 336
2022-04-03T12:09:03,889 [INFO ] W-9001-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:09:03,890 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 231042, Inference time ns: 327411833
2022-04-03T12:09:03,890 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 231042, Inference time ns: 327411833
2022-04-03T12:09:03,890 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:44|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:09:31,279 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955371
2022-04-03T12:09:31,281 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.27045822143555|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955371
2022-04-03T12:09:31,282 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:126.0034065246582|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955371
2022-04-03T12:09:31,282 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955371
2022-04-03T12:09:31,282 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1272.40625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955371
2022-04-03T12:09:31,282 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2641.8125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955371
2022-04-03T12:09:31,282 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:84.5|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955371
2022-04-03T12:10:30,640 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955430
2022-04-03T12:10:30,645 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.26991653442383|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955430
2022-04-03T12:10:30,646 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:126.00394821166992|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955430
2022-04-03T12:10:30,646 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955430
2022-04-03T12:10:30,646 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1292.890625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955430
2022-04-03T12:10:30,649 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2594.515625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955430
2022-04-03T12:10:30,650 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:84.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955430
2022-04-03T12:10:38,968 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-04-03T12:10:38,965 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-03T12:10:38,968 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-04-03T12:10:38,965 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-03T12:10:38,985 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-04-03T12:10:38,985 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-04-03T12:11:24,772 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:11:24,772 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:11:25,414 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:11:25,414 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:11:25,425 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:11:25,425 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:11:25,458 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:11:25,458 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:11:36,190 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:11:36,190 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:11:36,191 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:11:36,191 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:11:36,191 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:11:36,191 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:11:36,192 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:11:36,192 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:11:36,243 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:11:36,242 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:11:36,247 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:11:36,241 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:11:36,243 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:11:36,241 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:11:36,247 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:11:36,242 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:11:36,243 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:11:36,252 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:11:36,243 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:11:36,241 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:11:36,241 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:11:36,258 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:11:36,252 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:11:36,252 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:11:36,258 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:11:36,252 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:11:37,112 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:11:37,112 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:11:37,112 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:11:37,112 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:11:37,117 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:11:37,117 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:11:37,118 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:11:37,118 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:11:37,119 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:11:37,119 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:11:37,354 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:11:37,487 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]32467
2022-04-03T12:11:37,488 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:11:37,489 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:11:37,527 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,527 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,570 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:11:37,570 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:11:37,608 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T12:11:37,643 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955497642
2022-04-03T12:11:37,643 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955497642
2022-04-03T12:11:37,791 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:11:37,818 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:11:37,842 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]32465
2022-04-03T12:11:37,848 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,846 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:11:37,819 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:11:37,862 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:11:37,848 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,841 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:11:37,810 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:11:37,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]32464
2022-04-03T12:11:37,844 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:11:37,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]32468
2022-04-03T12:11:37,864 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-03T12:11:37,843 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:11:37,864 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-03T12:11:37,865 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]32466
2022-04-03T12:11:37,865 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:11:37,865 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:11:37,864 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:11:37,866 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:11:37,842 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:11:37,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:11:37,866 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:11:37,866 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]32462
2022-04-03T12:11:37,868 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]32463
2022-04-03T12:11:37,869 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:11:37,869 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:11:37,870 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:11:37,870 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:11:37,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]32461
2022-04-03T12:11:37,872 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,874 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,876 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:11:37,872 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,876 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:11:37,874 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,879 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:11:37,882 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,884 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:11:37,885 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:11:37,884 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,881 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,882 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,879 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,915 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:11:37,915 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:11:37,915 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:11:37,915 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:11:37,881 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,888 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:11:37,884 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:11:37,885 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:11:37,918 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:11:37,884 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:11:37,918 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T12:11:37,924 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955497923
2022-04-03T12:11:37,924 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955497923
2022-04-03T12:11:37,918 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:11:37,926 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:11:37,943 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955497943
2022-04-03T12:11:37,943 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955497943
2022-04-03T12:11:37,945 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T12:11:37,945 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T12:11:37,943 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955497943
2022-04-03T12:11:37,945 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T12:11:37,945 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955497945
2022-04-03T12:11:37,943 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955497943
2022-04-03T12:11:37,945 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955497945
2022-04-03T12:11:37,926 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:11:38,037 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:11:38,039 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:11:38,041 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:11:38,139 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955498139
2022-04-03T12:11:38,129 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955498124
2022-04-03T12:11:38,139 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955498139
2022-04-03T12:11:38,138 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T12:11:38,129 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955498124
2022-04-03T12:11:38,139 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955498138
2022-04-03T12:11:38,133 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:11:38,179 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:11:38,070 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T12:11:38,066 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955497
2022-04-03T12:11:38,139 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955498138
2022-04-03T12:11:38,138 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T12:11:38,197 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.27344512939453|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955497
2022-04-03T12:11:38,288 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.00041961669922|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955497
2022-04-03T12:11:38,292 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955497
2022-04-03T12:11:38,292 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:11:38,292 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:11:38,293 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:11:38,293 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:11:38,296 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:3266.34375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955497
2022-04-03T12:11:38,298 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3898.421875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955497
2022-04-03T12:11:38,303 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:60.1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955497
2022-04-03T12:11:38,301 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:11:38,324 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:11:38,383 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:11:38,498 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:11:38,500 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:11:38,507 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:11:55,212 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight']
2022-04-03T12:11:55,212 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']
2022-04-03T12:11:55,212 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias']
2022-04-03T12:11:55,212 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias']
2022-04-03T12:11:55,212 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias']
2022-04-03T12:11:55,212 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.decoder.bias']
2022-04-03T12:11:55,212 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
2022-04-03T12:11:55,212 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight']
2022-04-03T12:11:57,120 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:11:57,120 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:11:57,120 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:11:57,120 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:11:57,120 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:11:57,153 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:11:57,151 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:11:57,151 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:11:57,150 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:11:57,143 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:11:57,120 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:11:57,150 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:11:57,151 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:12:08,991 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:12:08,991 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:12:08,991 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:12:08,991 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:12:08,991 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:12:09,016 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:12:09,019 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:12:08,991 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:12:10,142 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:12:10,143 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:12:09,999 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:12:10,653 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:12:10,653 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:12:10,671 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:12:10,671 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:12:08,991 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:12:10,701 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:12:11,818 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:12:11,846 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:12:11,924 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/2bb1f1295c0d4425a052336ac49ebdef loaded successfully
2022-04-03T12:12:11,924 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/2bb1f1295c0d4425a052336ac49ebdef loaded successfully
2022-04-03T12:12:11,934 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/2bb1f1295c0d4425a052336ac49ebdef loaded successfully
2022-04-03T12:12:11,924 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/2bb1f1295c0d4425a052336ac49ebdef loaded successfully
2022-04-03T12:12:11,955 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/2bb1f1295c0d4425a052336ac49ebdef loaded successfully
2022-04-03T12:12:11,962 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/2bb1f1295c0d4425a052336ac49ebdef loaded successfully
2022-04-03T12:12:12,010 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/2bb1f1295c0d4425a052336ac49ebdef loaded successfully
2022-04-03T12:12:11,991 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/2bb1f1295c0d4425a052336ac49ebdef loaded successfully
2022-04-03T12:12:12,249 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34214
2022-04-03T12:12:12,249 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34131
2022-04-03T12:12:12,249 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34217
2022-04-03T12:12:12,249 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34000
2022-04-03T12:12:12,249 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34001
2022-04-03T12:12:12,249 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34131
2022-04-03T12:12:12,249 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34417
2022-04-03T12:12:12,249 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34417
2022-04-03T12:12:12,249 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34001
2022-04-03T12:12:12,249 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33983
2022-04-03T12:12:12,249 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34000
2022-04-03T12:12:12,249 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34214
2022-04-03T12:12:12,249 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34217
2022-04-03T12:12:12,249 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34207
2022-04-03T12:12:12,249 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33983
2022-04-03T12:12:12,254 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,249 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34207
2022-04-03T12:12:12,254 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,258 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,258 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,254 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:12:12,259 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:36044|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955532
2022-04-03T12:12:12,259 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:36042|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955532
2022-04-03T12:12:12,285 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:128|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:12:12,285 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:134|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:12:12,283 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:36068|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955532
2022-04-03T12:12:12,283 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:36067|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955532
2022-04-03T12:12:12,292 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:216|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:12:12,280 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:36066|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955532
2022-04-03T12:12:12,280 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:36068|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955532
2022-04-03T12:12:12,283 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:36067|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955532
2022-04-03T12:12:12,292 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:168|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:12:12,292 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:152|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:12:12,292 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:233|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:12:12,283 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:36075|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955532
2022-04-03T12:12:12,292 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:171|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:12:12,293 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:153|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:12:18,298 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955538298
2022-04-03T12:12:18,298 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955538298
2022-04-03T12:12:18,306 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648955538
2022-04-03T12:12:18,574 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:12:18,578 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 275
2022-04-03T12:12:18,578 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 275
2022-04-03T12:12:18,581 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-03T12:12:18,585 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   
2022-04-03T12:12:18,586 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:12:18,587 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - tensor([    0,   717,  2259,  4244, 31302,  2116,  1325,  2030,  2182,     2])
2022-04-03T12:12:18,588 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:12:18,588 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - (tensor([[ 0.4208, -1.2351]], grad_fn=<AddmmBackward0>), None)
2022-04-03T12:12:18,591 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 0
2022-04-03T12:12:18,599 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:12:18,599 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Invoking custom service failed.
2022-04-03T12:12:18,599 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T12:12:18,600 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/service.py", line 102, in predict
2022-04-03T12:12:18,601 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     ret = self._entry_point(input_batch, self.context)
2022-04-03T12:12:18,603 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/torch_handler/base_handler.py", line 222, in handle
2022-04-03T12:12:18,603 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     output = self.inference(data_preprocess)
2022-04-03T12:12:18,603 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/2bb1f1295c0d4425a052336ac49ebdef/RobertaModel_handler.py", line 131, in inference
2022-04-03T12:12:18,604 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return list(0)
2022-04-03T12:12:18,606 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - TypeError: 'int' object is not iterable
2022-04-03T12:12:18,620 [INFO ] W-9007-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55351 "POST /predictions/my_tc HTTP/1.1" 503 336
2022-04-03T12:12:18,621 [INFO ] W-9007-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:12:18,622 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 613167, Inference time ns: 324910708
2022-04-03T12:12:18,622 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 613167, Inference time ns: 324910708
2022-04-03T12:12:18,622 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:49|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:12:38,523 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955558
2022-04-03T12:12:38,532 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.26789093017578|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955558
2022-04-03T12:12:38,533 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:126.00597381591797|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955558
2022-04-03T12:12:38,533 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955558
2022-04-03T12:12:38,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1548.234375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955558
2022-04-03T12:12:38,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2862.0625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955558
2022-04-03T12:12:38,533 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:81.1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955558
2022-04-03T12:13:15,982 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-03T12:13:15,983 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-04-03T12:13:15,983 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-04-03T12:13:15,982 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-03T12:13:16,003 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-04-03T12:13:16,003 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-04-03T12:14:00,777 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:14:00,777 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:14:01,168 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:14:01,168 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:14:01,178 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:14:01,178 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:14:01,211 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:14:01,211 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:14:12,339 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:14:12,339 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:14:12,340 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:14:12,340 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:14:12,340 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:14:12,340 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:14:12,341 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:14:12,341 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:14:12,390 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:14:12,392 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:14:12,391 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:14:12,391 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:14:12,392 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:14:12,392 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:14:12,396 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:14:12,392 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:14:12,394 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:14:12,396 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:14:12,390 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:14:12,392 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:14:12,392 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:14:12,391 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:14:12,392 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:14:12,394 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:14:12,392 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:14:12,391 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:14:13,208 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:14:13,208 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:14:13,209 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:14:13,209 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:14:13,214 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:14:13,214 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:14:13,216 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:14:13,216 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:14:13,218 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:14:13,218 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:14:13,463 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:14:13,511 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]33121
2022-04-03T12:14:13,513 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:14:13,513 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:14:13,516 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:13,516 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:13,532 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:14:13,532 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:14:13,569 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955653568
2022-04-03T12:14:13,569 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955653568
2022-04-03T12:14:13,618 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T12:14:13,633 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:14:13,885 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:14:13,891 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]33118
2022-04-03T12:14:13,877 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:14:13,885 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:14:13,897 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]33119
2022-04-03T12:14:13,898 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:14:13,898 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:14:13,898 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:14:13,898 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:14:13,899 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:13,899 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:13,903 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:14:13,903 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:14:13,900 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:13,900 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]33125
2022-04-03T12:14:13,900 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:13,909 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:14:13,913 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:13,909 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:14:13,913 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:13,916 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955653915
2022-04-03T12:14:13,912 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:14:13,916 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955653915
2022-04-03T12:14:13,916 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:14:13,916 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:14:13,916 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:14:13,913 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T12:14:13,966 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T12:14:13,966 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955653966
2022-04-03T12:14:13,966 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955653966
2022-04-03T12:14:13,965 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955653965
2022-04-03T12:14:13,965 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955653965
2022-04-03T12:14:13,957 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:14:13,967 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T12:14:13,931 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:14:13,981 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]33122
2022-04-03T12:14:13,957 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:14:13,958 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:14:13,932 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:14:14,045 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:14:14,042 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]33123
2022-04-03T12:14:14,044 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:14:14,079 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:14,042 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]33120
2022-04-03T12:14:14,090 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:14,079 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:14,090 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:14,077 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:14,077 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:14,067 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:14:14,089 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:14:14,099 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:14:14,100 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:14:14,084 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:14:14,100 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:14:14,078 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:14:14,100 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:14:14,100 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:14:14,043 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]33124
2022-04-03T12:14:14,100 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:14:14,100 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:14:14,101 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:14:14,101 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:14,100 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:14:14,100 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:14:14,101 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:14:14,101 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:14:14,126 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:14:14,126 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:14:14,159 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955654157
2022-04-03T12:14:14,159 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955654157
2022-04-03T12:14:14,162 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T12:14:14,157 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T12:14:14,163 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T12:14:14,166 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T12:14:14,169 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955654158
2022-04-03T12:14:14,169 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955654165
2022-04-03T12:14:14,169 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955654165
2022-04-03T12:14:14,169 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955654158
2022-04-03T12:14:14,169 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955654165
2022-04-03T12:14:14,222 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:14:14,169 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955654165
2022-04-03T12:14:14,230 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:14:14,297 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:14:14,297 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:14:14,314 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:14:14,314 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:14:14,298 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:14:14,485 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:14:14,499 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:14:14,568 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:14:14,570 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:14:14,574 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955654
2022-04-03T12:14:14,587 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.27561950683594|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955654
2022-04-03T12:14:14,589 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:124.99824523925781|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955654
2022-04-03T12:14:14,589 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955654
2022-04-03T12:14:14,590 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2928.953125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955654
2022-04-03T12:14:14,590 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4206.1875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955654
2022-04-03T12:14:14,591 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:64.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955654
2022-04-03T12:14:34,023 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']
2022-04-03T12:14:34,023 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias']
2022-04-03T12:14:34,023 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias']
2022-04-03T12:14:34,023 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']
2022-04-03T12:14:34,491 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:14:34,097 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']
2022-04-03T12:14:34,097 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']
2022-04-03T12:14:34,097 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias']
2022-04-03T12:14:34,022 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.layer_norm.bias']
2022-04-03T12:14:34,517 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:14:34,517 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:14:34,517 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:14:34,517 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:14:34,539 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:14:34,541 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:14:34,517 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:14:34,519 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:14:34,517 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:14:34,518 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:14:39,634 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:14:39,634 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:14:48,622 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/4e653e7fd1d040758800f899c3628cdd loaded successfully
2022-04-03T12:14:48,651 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/4e653e7fd1d040758800f899c3628cdd loaded successfully
2022-04-03T12:14:48,779 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/4e653e7fd1d040758800f899c3628cdd loaded successfully
2022-04-03T12:14:39,634 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:14:48,700 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/4e653e7fd1d040758800f899c3628cdd loaded successfully
2022-04-03T12:14:48,924 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34609
2022-04-03T12:14:48,924 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34688
2022-04-03T12:14:48,924 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34969
2022-04-03T12:14:48,926 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 35296
2022-04-03T12:14:48,926 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34689
2022-04-03T12:14:48,926 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34611
2022-04-03T12:14:48,942 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34883
2022-04-03T12:14:48,942 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34883
2022-04-03T12:14:39,669 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:14:39,669 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:14:39,669 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:14:48,601 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/4e653e7fd1d040758800f899c3628cdd loaded successfully
2022-04-03T12:14:39,669 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:14:34,519 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:14:48,549 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/4e653e7fd1d040758800f899c3628cdd loaded successfully
2022-04-03T12:14:48,942 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34883
2022-04-03T12:14:48,926 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34689
2022-04-03T12:14:48,620 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/4e653e7fd1d040758800f899c3628cdd loaded successfully
2022-04-03T12:14:48,942 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34883
2022-04-03T12:14:48,592 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/4e653e7fd1d040758800f899c3628cdd loaded successfully
2022-04-03T12:14:48,926 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34611
2022-04-03T12:14:49,229 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,229 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,229 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,229 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:48,926 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 35296
2022-04-03T12:14:48,924 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34609
2022-04-03T12:14:48,924 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34969
2022-04-03T12:14:49,246 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:48,904 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:14:48,924 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 34688
2022-04-03T12:14:48,902 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:14:49,246 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,246 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,229 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:48,904 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:14:49,247 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,225 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:14:49,224 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:14:49,229 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,222 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:14:49,222 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:14:49,229 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,229 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,223 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:14:49,246 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,270 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:14:49,250 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:14:49,247 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:36882|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955689
2022-04-03T12:14:49,271 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:36909|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955689
2022-04-03T12:14:49,247 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,246 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,271 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:14:49,270 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:36912|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955689
2022-04-03T12:14:49,246 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:14:49,270 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:14:49,269 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:36908|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955689
2022-04-03T12:14:49,342 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:494|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:49,343 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:496|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:49,344 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:36979|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955689
2022-04-03T12:14:49,344 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:36984|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955689
2022-04-03T12:14:49,356 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:471|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:49,344 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:36982|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955689
2022-04-03T12:14:49,356 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:492|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:49,342 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:566|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:49,344 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:14:49,356 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:510|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:49,343 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:36981|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955689
2022-04-03T12:14:49,349 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:500|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:49,359 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:585|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:53,743 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955693742
2022-04-03T12:14:53,743 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955693742
2022-04-03T12:14:53,750 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648955693
2022-04-03T12:14:54,009 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 262
2022-04-03T12:14:54,009 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 262
2022-04-03T12:14:54,010 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:14:54,012 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-03T12:14:54,015 [INFO ] W-9005-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55468 "POST /predictions/my_tc HTTP/1.1" 200 283
2022-04-03T12:14:54,019 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   
2022-04-03T12:14:54,018 [INFO ] W-9005-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:54,020 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 248000, Backend time ns: 277868208
2022-04-03T12:14:54,020 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 248000, Backend time ns: 277868208
2022-04-03T12:14:54,020 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:14:54,021 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - tensor([    0,   717,  2259,  4244, 31302,  2116,  1325,  2030,  2182,     2])
2022-04-03T12:14:54,020 [INFO ] W-9005-my_tc_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:54,021 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:14:54,021 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:17|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:14:54,021 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - (tensor([[ 0.4208, -1.2351]], grad_fn=<AddmmBackward0>), None)
2022-04-03T12:14:54,021 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 0
2022-04-03T12:14:54,022 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:14:54,027 [INFO ] W-9005-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:257.75|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:ac0529fb-aa1f-4ddc-b7ed-d8659f6f8abf,timestamp:1648955694
2022-04-03T12:14:54,029 [INFO ] W-9005-my_tc_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:257.83|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:ac0529fb-aa1f-4ddc-b7ed-d8659f6f8abf,timestamp:1648955694
2022-04-03T12:15:01,632 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955701631
2022-04-03T12:15:01,632 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648955701631
2022-04-03T12:15:01,636 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648955701
2022-04-03T12:15:01,825 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:15:01,825 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-03T12:15:01,827 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 193
2022-04-03T12:15:01,826 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   
2022-04-03T12:15:01,827 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 193
2022-04-03T12:15:01,832 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:15:01,841 [INFO ] W-9004-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55470 "POST /predictions/my_tc HTTP/1.1" 200 211
2022-04-03T12:15:01,852 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - tensor([    0,   717,  2259,  4244, 31302,  2116,  1325,  2030,  2182,     2])
2022-04-03T12:15:01,853 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:15:01,853 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - (tensor([[ 0.4208, -1.2351]], grad_fn=<AddmmBackward0>), None)
2022-04-03T12:15:01,853 [INFO ] W-9004-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:15:01,853 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 0
2022-04-03T12:15:01,853 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ****************************************************************************************************
2022-04-03T12:15:01,855 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 144583, Backend time ns: 223435500
2022-04-03T12:15:01,855 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 144583, Backend time ns: 223435500
2022-04-03T12:15:01,855 [INFO ] W-9004-my_tc_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:15:01,856 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:32|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:15:01,856 [INFO ] W-9004-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:186.53|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:ad416e77-258c-4f1a-b46e-c853fb251ba6,timestamp:1648955701
2022-04-03T12:15:01,867 [INFO ] W-9004-my_tc_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:186.63|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:ad416e77-258c-4f1a-b46e-c853fb251ba6,timestamp:1648955701
2022-04-03T12:15:15,161 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955715
2022-04-03T12:15:15,162 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.2759017944336|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955715
2022-04-03T12:15:15,162 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.99796295166016|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955715
2022-04-03T12:15:15,163 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955715
2022-04-03T12:15:15,163 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1325.0625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955715
2022-04-03T12:15:15,163 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2710.75|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955715
2022-04-03T12:15:15,164 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955715
2022-04-03T12:16:15,206 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955775
2022-04-03T12:16:15,207 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.27196502685547|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955775
2022-04-03T12:16:15,208 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.00189971923828|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955775
2022-04-03T12:16:15,208 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955775
2022-04-03T12:16:15,208 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1298.578125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955775
2022-04-03T12:16:15,208 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2547.203125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955775
2022-04-03T12:16:15,208 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:84.1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955775
2022-04-03T12:17:15,127 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:33.3|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955835
2022-04-03T12:17:15,128 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.26813507080078|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955835
2022-04-03T12:17:15,128 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.00572967529297|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955835
2022-04-03T12:17:15,128 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955835
2022-04-03T12:17:15,128 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1350.59375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955835
2022-04-03T12:17:15,129 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2670.015625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955835
2022-04-03T12:17:15,129 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:83.5|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955835
2022-04-03T12:18:14,564 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955894
2022-04-03T12:18:14,565 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.26812362670898|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955894
2022-04-03T12:18:14,565 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.00574111938477|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955894
2022-04-03T12:18:14,566 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955894
2022-04-03T12:18:14,566 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1424.0625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955894
2022-04-03T12:18:14,566 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2673.390625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955894
2022-04-03T12:18:14,566 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.6|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648955894
2022-04-03T12:21:02,597 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:21:02,597 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:21:03,240 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:21:03,240 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:21:03,251 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:21:03,251 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:21:03,285 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:21:03,285 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:21:14,111 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:21:14,111 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:21:14,112 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:21:14,112 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:21:14,112 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:21:14,112 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:21:14,113 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:21:14,113 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:21:14,169 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:21:14,166 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:21:14,167 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:21:14,167 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:21:14,167 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:21:14,164 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:21:14,164 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:21:14,171 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:21:14,167 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:21:14,171 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:21:14,171 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:21:14,169 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:21:14,167 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:21:14,167 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:21:14,167 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:21:14,167 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:21:14,166 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:21:14,171 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:21:14,839 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:21:14,839 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:21:14,840 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:21:14,840 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:21:14,843 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:21:14,843 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:21:14,844 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:21:14,844 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:21:14,845 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:21:14,845 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:21:15,415 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-03T12:21:15,415 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-03T12:21:15,465 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:21:15,471 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]33857
2022-04-03T12:21:15,472 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:21:15,473 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:21:15,475 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,475 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,486 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:21:15,486 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:21:15,505 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956075
2022-04-03T12:21:15,529 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.26656341552734|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956075
2022-04-03T12:21:15,530 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.0073013305664|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956075
2022-04-03T12:21:15,534 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956075
2022-04-03T12:21:15,534 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:3110.984375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956075
2022-04-03T12:21:15,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3958.859375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956075
2022-04-03T12:21:15,535 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:62.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956075
2022-04-03T12:21:15,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T12:21:15,576 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956075576
2022-04-03T12:21:15,576 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956075576
2022-04-03T12:21:15,632 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:21:15,725 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:21:15,724 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:21:15,737 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]33855
2022-04-03T12:21:15,738 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]33854
2022-04-03T12:21:15,740 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,739 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:21:15,739 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:21:15,740 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:21:15,740 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:21:15,740 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,740 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,741 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:21:15,741 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:21:15,740 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,742 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:21:15,742 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:21:15,761 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956075760
2022-04-03T12:21:15,761 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956075760
2022-04-03T12:21:15,761 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956075760
2022-04-03T12:21:15,731 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:21:15,761 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956075760
2022-04-03T12:21:15,764 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T12:21:15,763 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]33856
2022-04-03T12:21:15,765 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:21:15,766 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T12:21:15,767 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:21:15,765 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,765 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,769 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:21:15,769 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:21:15,769 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:21:15,770 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]33853
2022-04-03T12:21:15,770 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,770 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:21:15,770 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,770 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:21:15,770 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:21:15,770 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:21:15,811 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956075810
2022-04-03T12:21:15,811 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956075810
2022-04-03T12:21:15,811 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T12:21:15,768 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:21:15,811 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:21:15,821 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T12:21:15,823 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]33852
2022-04-03T12:21:15,869 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956075866
2022-04-03T12:21:15,869 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956075866
2022-04-03T12:21:15,894 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:21:15,818 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:21:15,896 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,894 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:21:15,842 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:21:15,919 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]33858
2022-04-03T12:21:15,920 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:21:15,921 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,921 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,942 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]33859
2022-04-03T12:21:15,942 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:21:15,942 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:21:15,896 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,959 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,958 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:21:15,958 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:21:15,937 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:21:15,958 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:21:15,958 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:21:15,959 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:21:15,958 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:21:15,963 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:21:15,959 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:21:15,974 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:21:15,974 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:21:16,002 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956076002
2022-04-03T12:21:16,001 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956076001
2022-04-03T12:21:16,001 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956076001
2022-04-03T12:21:16,001 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956076001
2022-04-03T12:21:16,002 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956076002
2022-04-03T12:21:16,000 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T12:21:16,002 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T12:21:16,001 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956076001
2022-04-03T12:21:16,000 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T12:21:16,076 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:21:16,075 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:21:16,078 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:21:16,081 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:21:16,120 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:21:16,217 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:21:16,233 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:21:16,267 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:21:16,327 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:21:16,349 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:21:16,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:21:35,624 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias']
2022-04-03T12:21:35,624 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']
2022-04-03T12:21:35,632 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']
2022-04-03T12:21:35,624 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']
2022-04-03T12:21:35,634 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
2022-04-03T12:21:35,634 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.bias']
2022-04-03T12:21:35,634 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.bias']
2022-04-03T12:21:36,844 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:21:36,844 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:21:36,844 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:21:36,845 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:21:36,862 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:21:36,862 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:21:36,844 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:21:35,634 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']
2022-04-03T12:21:36,844 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:21:41,516 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:21:36,844 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:21:41,516 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:21:41,516 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:21:41,516 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:21:41,515 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:21:41,603 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:21:41,603 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:21:41,597 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:21:36,862 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:21:41,597 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:21:41,597 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:21:41,868 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:21:41,874 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:21:42,441 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:21:42,441 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:21:42,442 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:21:42,442 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:21:42,442 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:21:42,442 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:21:42,442 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:21:43,055 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:21:43,055 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:21:43,063 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:21:48,937 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:21:48,936 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:21:48,937 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:21:48,937 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:21:49,025 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:21:49,051 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:21:49,099 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:21:49,134 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:21:49,390 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33580
2022-04-03T12:21:49,390 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33344
2022-04-03T12:21:49,390 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33490
2022-04-03T12:21:49,390 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33327
2022-04-03T12:21:49,390 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33757
2022-04-03T12:21:49,390 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33435
2022-04-03T12:21:49,390 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33514
2022-04-03T12:21:49,390 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33580
2022-04-03T12:21:49,390 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33757
2022-04-03T12:21:49,390 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33514
2022-04-03T12:21:49,390 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33435
2022-04-03T12:21:49,390 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33327
2022-04-03T12:21:49,390 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33490
2022-04-03T12:21:49,390 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33344
2022-04-03T12:21:49,390 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33326
2022-04-03T12:21:49,390 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33326
2022-04-03T12:21:49,403 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,403 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,403 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,402 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,402 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,405 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,403 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,403 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,402 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,403 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,405 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,403 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,403 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,403 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,403 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:49,402 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:21:50,314 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:36175|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956110
2022-04-03T12:21:50,314 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:36172|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956110
2022-04-03T12:21:50,307 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:36167|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956110
2022-04-03T12:21:50,314 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:36175|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956110
2022-04-03T12:21:50,315 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:36177|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956110
2022-04-03T12:21:50,307 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:36176|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956110
2022-04-03T12:21:50,307 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:36168|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956110
2022-04-03T12:21:50,314 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:36179|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956110
2022-04-03T12:21:50,330 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:997|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:21:50,330 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:1056|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:21:50,330 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:1002|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:21:50,330 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:990|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:21:50,331 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:1029|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:21:50,330 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:1030|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:21:50,331 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:1003|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:21:50,331 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:984|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:21:56,069 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956116069
2022-04-03T12:21:56,069 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956116069
2022-04-03T12:21:56,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648956116
2022-04-03T12:21:56,324 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 251
2022-04-03T12:21:56,323 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - tensor([    0,   717,  2259,  4244, 31302,  2116,  1325,  2030,  2182,     2])
2022-04-03T12:21:56,324 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 251
2022-04-03T12:21:56,331 [INFO ] W-9000-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:246.59|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:52bf43eb-16c1-4c6e-bd75-0c8353aced28,timestamp:1648956116
2022-04-03T12:21:56,334 [INFO ] W-9000-my_tc_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:247.0|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:52bf43eb-16c1-4c6e-bd75-0c8353aced28,timestamp:1648956116
2022-04-03T12:21:56,338 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55602 "POST /predictions/my_tc HTTP/1.1" 200 286
2022-04-03T12:21:56,342 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:21:56,343 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 711333, Backend time ns: 274020792
2022-04-03T12:21:56,343 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 711333, Backend time ns: 274020792
2022-04-03T12:21:56,343 [INFO ] W-9000-my_tc_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:21:56,343 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:23|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:22:16,013 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956136
2022-04-03T12:22:16,014 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.27025985717773|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956136
2022-04-03T12:22:16,015 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:126.00360488891602|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956136
2022-04-03T12:22:16,015 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956136
2022-04-03T12:22:16,015 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1561.28125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956136
2022-04-03T12:22:16,015 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2802.890625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956136
2022-04-03T12:22:16,015 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:80.9|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956136
2022-04-03T12:22:32,403 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956152403
2022-04-03T12:22:32,403 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956152403
2022-04-03T12:22:32,408 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T12:22:32,408 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T12:22:32,409 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T12:22:32,409 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T12:22:32,409 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T12:22:32,409 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T12:22:32,409 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 116, in handle_connection
2022-04-03T12:22:32,409 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     cmd, msg = retrieve_msg(cl_socket)
2022-04-03T12:22:32,411 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 36, in retrieve_msg
2022-04-03T12:22:32,412 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     msg = _retrieve_inference_msg(conn)
2022-04-03T12:22:32,412 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 226, in _retrieve_inference_msg
2022-04-03T12:22:32,412 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     request = _retrieve_request(conn)
2022-04-03T12:22:32,412 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 261, in _retrieve_request
2022-04-03T12:22:32,415 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     input_data = _retrieve_input_data(conn)
2022-04-03T12:22:32,418 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 314, in _retrieve_input_data
2022-04-03T12:22:32,418 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     model_input["value"] = json.loads(value.decode("utf-8"))
2022-04-03T12:22:32,418 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py", line 346, in loads
2022-04-03T12:22:32,419 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _default_decoder.decode(s)
2022-04-03T12:22:32,419 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 337, in decode
2022-04-03T12:22:32,419 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
2022-04-03T12:22:32,419 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 355, in raw_decode
2022-04-03T12:22:32,420 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     raise JSONDecodeError("Expecting value", s, err.value) from None
2022-04-03T12:22:32,420 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - json.decoder.JSONDecodeError: Expecting value: line 1 column 9 (char 8)
2022-04-03T12:22:32,484 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:22:32,484 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:22:32,486 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:22:32,486 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:22:32,486 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:22:32,486 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:22:32,569 [INFO ] W-9005-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55604 "POST /predictions/my_tc HTTP/1.1" 500 168
2022-04-03T12:22:32,572 [INFO ] W-9005-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:22:32,572 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 217750, Inference time ns: 169824333
2022-04-03T12:22:32,572 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 217750, Inference time ns: 169824333
2022-04-03T12:22:32,572 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:22:32,572 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:22:32,574 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-03T12:22:32,574 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-03T12:22:32,574 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-03T12:22:32,574 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-03T12:22:32,574 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-03T12:22:32,574 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-03T12:22:32,575 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-03T12:22:32,575 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-03T12:22:32,587 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-03T12:22:32,587 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-03T12:22:33,593 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:22:33,593 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:22:34,192 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:22:34,193 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]34052
2022-04-03T12:22:34,193 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:22:34,193 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:22:34,194 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:22:34,194 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:22:34,194 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:22:34,194 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:22:34,197 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T12:22:34,198 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956154198
2022-04-03T12:22:34,198 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956154198
2022-04-03T12:22:34,245 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:22:34,425 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:22:43,507 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']
2022-04-03T12:22:43,522 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:22:43,525 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:22:43,534 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:22:43,538 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:22:43,833 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:22:43,835 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9597
2022-04-03T12:22:43,835 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9597
2022-04-03T12:22:43,837 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:22:43,837 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:22:43,837 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:89698|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956163
2022-04-03T12:22:43,838 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:43|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:23:15,503 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956195
2022-04-03T12:23:15,506 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:102.26641082763672|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956195
2022-04-03T12:23:15,512 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:126.00745391845703|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956195
2022-04-03T12:23:15,513 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956195
2022-04-03T12:23:15,513 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:1452.09375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956195
2022-04-03T12:23:15,513 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:2729.015625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956195
2022-04-03T12:23:15,513 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:82.3|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956195
2022-04-03T12:23:22,903 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956202902
2022-04-03T12:23:22,903 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956202902
2022-04-03T12:23:22,914 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T12:23:22,914 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T12:23:22,914 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T12:23:22,914 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T12:23:22,914 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T12:23:22,914 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T12:23:22,915 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 116, in handle_connection
2022-04-03T12:23:22,915 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     cmd, msg = retrieve_msg(cl_socket)
2022-04-03T12:23:22,915 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 36, in retrieve_msg
2022-04-03T12:23:22,915 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     msg = _retrieve_inference_msg(conn)
2022-04-03T12:23:22,915 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 226, in _retrieve_inference_msg
2022-04-03T12:23:22,915 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     request = _retrieve_request(conn)
2022-04-03T12:23:22,916 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 261, in _retrieve_request
2022-04-03T12:23:22,916 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     input_data = _retrieve_input_data(conn)
2022-04-03T12:23:22,916 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 314, in _retrieve_input_data
2022-04-03T12:23:22,916 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     model_input["value"] = json.loads(value.decode("utf-8"))
2022-04-03T12:23:22,916 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py", line 346, in loads
2022-04-03T12:23:22,916 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _default_decoder.decode(s)
2022-04-03T12:23:22,916 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 337, in decode
2022-04-03T12:23:22,916 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
2022-04-03T12:23:22,917 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 355, in raw_decode
2022-04-03T12:23:22,917 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     raise JSONDecodeError("Expecting value", s, err.value) from None
2022-04-03T12:23:22,917 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - json.decoder.JSONDecodeError: Expecting value: line 1 column 9 (char 8)
2022-04-03T12:23:22,996 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:23:22,996 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:23:23,003 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:23:23,003 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:23:23,004 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:23:23,004 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:23:23,014 [INFO ] W-9003-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55616 "POST /predictions/my_tc HTTP/1.1" 500 112
2022-04-03T12:23:23,015 [INFO ] W-9003-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:23:23,015 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 869000, Inference time ns: 113594958
2022-04-03T12:23:23,015 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 869000, Inference time ns: 113594958
2022-04-03T12:23:23,015 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:23:23,015 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:23:23,018 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-03T12:23:23,018 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-03T12:23:23,018 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-03T12:23:23,018 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-03T12:23:23,018 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-03T12:23:23,018 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-03T12:23:23,019 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-03T12:23:23,019 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-03T12:23:23,020 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-03T12:23:23,020 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-03T12:23:24,026 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:23:24,026 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:23:24,646 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:23:24,647 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]34175
2022-04-03T12:23:24,647 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:23:24,647 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:23:24,648 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:23:24,648 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:23:24,648 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:23:24,648 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:23:24,653 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T12:23:24,654 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956204654
2022-04-03T12:23:24,654 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956204654
2022-04-03T12:23:24,700 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:23:24,886 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:23:33,786 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.bias']
2022-04-03T12:23:33,796 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:23:33,797 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:23:33,798 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:23:33,799 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:23:34,154 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:23:34,160 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9465
2022-04-03T12:23:34,160 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9465
2022-04-03T12:23:34,161 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:23:34,161 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:23:34,161 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:140023|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956214
2022-04-03T12:23:34,162 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:42|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:23:36,394 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956216394
2022-04-03T12:23:36,394 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956216394
2022-04-03T12:23:36,402 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648956216
2022-04-03T12:23:36,773 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - tensor([    0,   717,  2259,  4244, 31302,  2116,  1325,  2030,  2182,     2])
2022-04-03T12:23:36,774 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 378
2022-04-03T12:23:36,774 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 378
2022-04-03T12:23:36,775 [INFO ] W-9001-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:370.31|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:70bde5ca-4a78-4f86-8aa5-1ecf030dfb73,timestamp:1648956216
2022-04-03T12:23:36,775 [INFO ] W-9001-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55630 "POST /predictions/my_tc HTTP/1.1" 200 383
2022-04-03T12:23:36,783 [INFO ] W-9001-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:23:36,783 [INFO ] W-9001-my_tc_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:370.86|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:70bde5ca-4a78-4f86-8aa5-1ecf030dfb73,timestamp:1648956216
2022-04-03T12:23:36,783 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 673709, Backend time ns: 389224375
2022-04-03T12:23:36,783 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 673709, Backend time ns: 389224375
2022-04-03T12:23:36,783 [INFO ] W-9001-my_tc_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:23:36,783 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:11|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:05,852 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956245852
2022-04-03T12:24:05,852 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956245852
2022-04-03T12:24:05,860 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T12:24:05,860 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T12:24:05,860 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T12:24:05,860 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T12:24:05,860 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T12:24:05,861 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T12:24:05,861 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 116, in handle_connection
2022-04-03T12:24:05,861 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     cmd, msg = retrieve_msg(cl_socket)
2022-04-03T12:24:05,861 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 36, in retrieve_msg
2022-04-03T12:24:05,861 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     msg = _retrieve_inference_msg(conn)
2022-04-03T12:24:05,861 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 226, in _retrieve_inference_msg
2022-04-03T12:24:05,861 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     request = _retrieve_request(conn)
2022-04-03T12:24:05,861 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 261, in _retrieve_request
2022-04-03T12:24:05,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     input_data = _retrieve_input_data(conn)
2022-04-03T12:24:05,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 314, in _retrieve_input_data
2022-04-03T12:24:05,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     model_input["value"] = json.loads(value.decode("utf-8"))
2022-04-03T12:24:05,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py", line 346, in loads
2022-04-03T12:24:05,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _default_decoder.decode(s)
2022-04-03T12:24:05,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 337, in decode
2022-04-03T12:24:05,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
2022-04-03T12:24:05,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 355, in raw_decode
2022-04-03T12:24:05,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     raise JSONDecodeError("Expecting value", s, err.value) from None
2022-04-03T12:24:05,863 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - json.decoder.JSONDecodeError: Expecting value: line 1 column 9 (char 8)
2022-04-03T12:24:05,937 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:24:05,937 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:24:05,938 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:24:05,938 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:24:05,938 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:24:05,938 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:24:05,943 [INFO ] W-9002-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55637 "POST /predictions/my_tc HTTP/1.1" 500 92
2022-04-03T12:24:05,947 [INFO ] W-9002-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:05,948 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 534250, Inference time ns: 95626958
2022-04-03T12:24:05,948 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 534250, Inference time ns: 95626958
2022-04-03T12:24:05,948 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:24:05,948 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:24:05,951 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-03T12:24:05,951 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-03T12:24:05,952 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-03T12:24:05,952 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-03T12:24:05,958 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-03T12:24:05,958 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-03T12:24:05,959 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-03T12:24:05,959 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-03T12:24:05,959 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-03T12:24:05,959 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-03T12:24:06,848 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956246848
2022-04-03T12:24:06,848 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956246848
2022-04-03T12:24:06,860 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T12:24:06,860 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T12:24:06,860 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T12:24:06,860 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 116, in handle_connection
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     cmd, msg = retrieve_msg(cl_socket)
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 36, in retrieve_msg
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     msg = _retrieve_inference_msg(conn)
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 226, in _retrieve_inference_msg
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     request = _retrieve_request(conn)
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 261, in _retrieve_request
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     input_data = _retrieve_input_data(conn)
2022-04-03T12:24:06,861 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 314, in _retrieve_input_data
2022-04-03T12:24:06,862 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     model_input["value"] = json.loads(value.decode("utf-8"))
2022-04-03T12:24:06,862 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py", line 346, in loads
2022-04-03T12:24:06,862 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _default_decoder.decode(s)
2022-04-03T12:24:06,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 337, in decode
2022-04-03T12:24:06,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
2022-04-03T12:24:06,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 355, in raw_decode
2022-04-03T12:24:06,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     raise JSONDecodeError("Expecting value", s, err.value) from None
2022-04-03T12:24:06,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - json.decoder.JSONDecodeError: Expecting value: line 1 column 9 (char 8)
2022-04-03T12:24:06,915 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:24:06,915 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:24:06,918 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:24:06,918 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:24:06,919 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:24:06,919 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:24:06,921 [INFO ] W-9007-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55639 "POST /predictions/my_tc HTTP/1.1" 500 73
2022-04-03T12:24:06,923 [INFO ] W-9007-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:06,924 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 365291, Inference time ns: 76164333
2022-04-03T12:24:06,924 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 365291, Inference time ns: 76164333
2022-04-03T12:24:06,924 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:24:06,924 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:24:06,927 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-03T12:24:06,927 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-03T12:24:06,928 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-03T12:24:06,928 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-03T12:24:06,928 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-03T12:24:06,928 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-03T12:24:06,928 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-03T12:24:06,928 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-03T12:24:06,927 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-03T12:24:06,927 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-03T12:24:06,966 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:24:06,966 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:24:07,761 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:24:07,772 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]34374
2022-04-03T12:24:07,774 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:24:07,774 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:24:07,774 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:24:07,774 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:24:07,775 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:24:07,775 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:24:07,783 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956247782
2022-04-03T12:24:07,783 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956247782
2022-04-03T12:24:07,783 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T12:24:07,790 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:24:07,934 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:24:07,934 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:24:07,980 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:24:08,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:24:08,360 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]34391
2022-04-03T12:24:08,360 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:24:08,360 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:24:08,360 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:24:08,361 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:24:08,361 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:24:08,361 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:24:08,366 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956248366
2022-04-03T12:24:08,366 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956248366
2022-04-03T12:24:08,370 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T12:24:08,371 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:24:08,522 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:24:08,777 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956248777
2022-04-03T12:24:08,777 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956248777
2022-04-03T12:24:08,783 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 116, in handle_connection
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     cmd, msg = retrieve_msg(cl_socket)
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 36, in retrieve_msg
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     msg = _retrieve_inference_msg(conn)
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 226, in _retrieve_inference_msg
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     request = _retrieve_request(conn)
2022-04-03T12:24:08,784 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 261, in _retrieve_request
2022-04-03T12:24:08,785 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     input_data = _retrieve_input_data(conn)
2022-04-03T12:24:08,785 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 314, in _retrieve_input_data
2022-04-03T12:24:08,785 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     model_input["value"] = json.loads(value.decode("utf-8"))
2022-04-03T12:24:08,785 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py", line 346, in loads
2022-04-03T12:24:08,785 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _default_decoder.decode(s)
2022-04-03T12:24:08,785 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 337, in decode
2022-04-03T12:24:08,785 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
2022-04-03T12:24:08,785 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 355, in raw_decode
2022-04-03T12:24:08,785 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     raise JSONDecodeError("Expecting value", s, err.value) from None
2022-04-03T12:24:08,785 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - json.decoder.JSONDecodeError: Expecting value: line 1 column 9 (char 8)
2022-04-03T12:24:08,849 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:24:08,849 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:24:08,851 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:24:08,851 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:24:08,851 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:24:08,851 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:24:08,852 [INFO ] W-9004-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55648 "POST /predictions/my_tc HTTP/1.1" 500 76
2022-04-03T12:24:08,853 [INFO ] W-9004-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:08,853 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 621333, Inference time ns: 76803000
2022-04-03T12:24:08,853 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 621333, Inference time ns: 76803000
2022-04-03T12:24:08,853 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:24:08,853 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:24:08,853 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-03T12:24:08,853 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-03T12:24:08,860 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-03T12:24:08,860 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-03T12:24:08,868 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-03T12:24:08,860 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-03T12:24:08,860 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-03T12:24:08,868 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-03T12:24:08,872 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-03T12:24:08,872 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-03T12:24:09,878 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:24:09,878 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:24:10,313 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:24:10,315 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]34455
2022-04-03T12:24:10,315 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:24:10,315 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:24:10,315 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:24:10,315 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:24:10,315 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:24:10,315 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:24:10,318 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T12:24:10,318 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956250318
2022-04-03T12:24:10,318 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956250318
2022-04-03T12:24:10,321 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:24:10,473 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:24:15,529 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956255
2022-04-03T12:24:15,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.26704025268555|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956255
2022-04-03T12:24:15,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.0068244934082|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956255
2022-04-03T12:24:15,531 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956255
2022-04-03T12:24:15,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1819.453125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956255
2022-04-03T12:24:15,531 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2931.703125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956255
2022-04-03T12:24:15,532 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:77.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956255
2022-04-03T12:24:16,947 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']
2022-04-03T12:24:16,966 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:24:16,966 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:24:16,966 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:24:16,967 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:24:17,460 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9671
2022-04-03T12:24:17,452 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:24:17,460 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9671
2022-04-03T12:24:17,460 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']
2022-04-03T12:24:17,463 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:24:17,463 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:24:17,463 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:24:17,464 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:24:17,464 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:24:17,464 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:24:17,465 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:183327|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956257
2022-04-03T12:24:17,465 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:12|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:17,625 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:24:17,627 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9258
2022-04-03T12:24:17,627 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9258
2022-04-03T12:24:17,627 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:24:17,627 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:24:17,628 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:183486|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956257
2022-04-03T12:24:17,628 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:19,409 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']
2022-04-03T12:24:19,411 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:24:19,411 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:24:19,411 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:24:19,411 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:24:19,753 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9431
2022-04-03T12:24:19,750 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:24:19,753 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9431
2022-04-03T12:24:19,761 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:24:19,761 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:24:19,763 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:185623|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956259
2022-04-03T12:24:19,763 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:14|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:21,398 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956261395
2022-04-03T12:24:21,398 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956261395
2022-04-03T12:24:21,415 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T12:24:21,415 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T12:24:21,415 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T12:24:21,415 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T12:24:21,415 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T12:24:21,415 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T12:24:21,415 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 116, in handle_connection
2022-04-03T12:24:21,415 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     cmd, msg = retrieve_msg(cl_socket)
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 36, in retrieve_msg
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     msg = _retrieve_inference_msg(conn)
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 226, in _retrieve_inference_msg
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     request = _retrieve_request(conn)
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 261, in _retrieve_request
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     input_data = _retrieve_input_data(conn)
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 314, in _retrieve_input_data
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     model_input["value"] = json.loads(value.decode("utf-8"))
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py", line 346, in loads
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _default_decoder.decode(s)
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 337, in decode
2022-04-03T12:24:21,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
2022-04-03T12:24:21,417 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 355, in raw_decode
2022-04-03T12:24:21,417 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     raise JSONDecodeError("Expecting value", s, err.value) from None
2022-04-03T12:24:21,417 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - json.decoder.JSONDecodeError: Expecting value: line 1 column 9 (char 8)
2022-04-03T12:24:21,452 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:24:21,452 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:24:21,454 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:24:21,454 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:24:21,454 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:24:21,454 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:24:21,456 [INFO ] W-9006-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55684 "POST /predictions/my_tc HTTP/1.1" 500 64
2022-04-03T12:24:21,457 [INFO ] W-9006-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:21,457 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 295709, Inference time ns: 62084625
2022-04-03T12:24:21,457 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 295709, Inference time ns: 62084625
2022-04-03T12:24:21,457 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:24:21,457 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:24:21,459 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-03T12:24:21,459 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-03T12:24:21,459 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-03T12:24:21,459 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-03T12:24:21,460 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-03T12:24:21,460 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-03T12:24:21,471 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-03T12:24:21,471 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-03T12:24:21,471 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-03T12:24:21,471 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-03T12:24:22,475 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:24:22,475 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:24:23,527 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:24:23,529 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]34527
2022-04-03T12:24:23,529 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:24:23,529 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:24:23,529 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:24:23,529 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:24:23,530 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:24:23,530 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:24:23,537 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956263537
2022-04-03T12:24:23,537 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956263537
2022-04-03T12:24:23,537 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T12:24:23,541 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:24:23,735 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:24:23,811 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956263811
2022-04-03T12:24:23,811 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956263811
2022-04-03T12:24:23,820 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-03T12:24:23,820 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-03T12:24:23,822 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-03T12:24:23,822 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-03T12:24:23,822 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-03T12:24:23,822 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-03T12:24:23,822 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 116, in handle_connection
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     cmd, msg = retrieve_msg(cl_socket)
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 36, in retrieve_msg
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     msg = _retrieve_inference_msg(conn)
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 226, in _retrieve_inference_msg
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     request = _retrieve_request(conn)
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 261, in _retrieve_request
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     input_data = _retrieve_input_data(conn)
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/protocol/otf_message_handler.py", line 314, in _retrieve_input_data
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     model_input["value"] = json.loads(value.decode("utf-8"))
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/__init__.py", line 346, in loads
2022-04-03T12:24:23,823 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _default_decoder.decode(s)
2022-04-03T12:24:23,824 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 337, in decode
2022-04-03T12:24:23,824 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     obj, end = self.raw_decode(s, idx=_w(s, 0).end())
2022-04-03T12:24:23,824 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/json/decoder.py", line 355, in raw_decode
2022-04-03T12:24:23,824 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     raise JSONDecodeError("Expecting value", s, err.value) from None
2022-04-03T12:24:23,824 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - json.decoder.JSONDecodeError: Expecting value: line 1 column 9 (char 8)
2022-04-03T12:24:23,857 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:24:23,857 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_MODEL_LOADED
2022-04-03T12:24:23,858 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:24:23,858 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2022-04-03T12:24:23,859 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:24:23,859 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-03T12:24:23,861 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55688 "POST /predictions/my_tc HTTP/1.1" 500 51
2022-04-03T12:24:23,861 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests5XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:23,862 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 105209, Inference time ns: 51254459
2022-04-03T12:24:23,862 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 105209, Inference time ns: 51254459
2022-04-03T12:24:23,862 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:24:23,862 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_MODEL_LOADED -> WORKER_STOPPED
2022-04-03T12:24:23,862 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-03T12:24:23,862 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-03T12:24:23,862 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-03T12:24:23,862 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-03T12:24:23,862 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-03T12:24:23,862 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-03T12:24:23,864 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-03T12:24:23,864 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-03T12:24:23,864 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-03T12:24:23,864 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-03T12:24:24,871 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:24:24,871 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:24:25,256 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:24:25,258 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]34593
2022-04-03T12:24:25,259 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:24:25,259 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:24:25,262 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:24:25,262 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-03T12:24:25,263 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:24:25,263 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:24:25,268 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T12:24:25,268 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956265268
2022-04-03T12:24:25,268 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956265268
2022-04-03T12:24:25,292 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:24:25,444 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:24:25,741 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956265741
2022-04-03T12:24:25,741 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956265741
2022-04-03T12:24:25,746 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648956265
2022-04-03T12:24:25,886 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 143
2022-04-03T12:24:25,885 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - tensor([    0,   717,  2259,  4244, 31302,  2116,  1325,  2030,  2182,     2])
2022-04-03T12:24:25,886 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 143
2022-04-03T12:24:25,889 [INFO ] W-9005-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55694 "POST /predictions/my_tc HTTP/1.1" 200 148
2022-04-03T12:24:25,889 [INFO ] W-9005-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:25,889 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 135500, Backend time ns: 148202292
2022-04-03T12:24:25,889 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 135500, Backend time ns: 148202292
2022-04-03T12:24:25,891 [INFO ] W-9005-my_tc_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:25,893 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:25,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:138.21|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:cfc1ea02-695f-4e35-9a02-61bc5911c346,timestamp:1648956265
2022-04-03T12:24:25,894 [INFO ] W-9005-my_tc_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:138.28|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:cfc1ea02-695f-4e35-9a02-61bc5911c346,timestamp:1648956265
2022-04-03T12:24:32,658 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']
2022-04-03T12:24:32,680 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:24:32,680 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:24:32,680 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:24:32,680 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:24:33,282 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:24:33,287 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9746
2022-04-03T12:24:33,287 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9746
2022-04-03T12:24:33,287 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:24:33,287 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:24:33,288 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:199148|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956273
2022-04-03T12:24:33,288 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:5|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:34,453 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.bias']
2022-04-03T12:24:34,460 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:24:34,460 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:24:34,460 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:24:34,462 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:24:34,831 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/af1aec4171434dd0844459985fbbab75 loaded successfully
2022-04-03T12:24:34,833 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9542
2022-04-03T12:24:34,833 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 9542
2022-04-03T12:24:34,833 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:24:34,833 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:24:34,834 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:200703|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956274
2022-04-03T12:24:34,834 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:24|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:51,293 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956291293
2022-04-03T12:24:51,293 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956291293
2022-04-03T12:24:51,299 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648956291
2022-04-03T12:24:51,546 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - tensor([   0, 1396, 1504, 6614, 2246, 2073,  770, 2227,    2])
2022-04-03T12:24:51,547 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 251
2022-04-03T12:24:51,547 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 251
2022-04-03T12:24:51,549 [INFO ] W-9003-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:246.88|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:52d3718e-44f7-40c6-b13f-b663bd635e95,timestamp:1648956291
2022-04-03T12:24:51,550 [INFO ] W-9003-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55714 "POST /predictions/my_tc HTTP/1.1" 200 259
2022-04-03T12:24:51,550 [INFO ] W-9003-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:51,550 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1690209, Backend time ns: 257076833
2022-04-03T12:24:51,550 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 1690209, Backend time ns: 257076833
2022-04-03T12:24:51,550 [INFO ] W-9003-my_tc_1.0 TS_METRICS - QueueTime.ms:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:24:51,550 [INFO ] W-9003-my_tc_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:247.01|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:52d3718e-44f7-40c6-b13f-b663bd635e95,timestamp:1648956291
2022-04-03T12:24:51,550 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:6|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:25:16,006 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956316
2022-04-03T12:25:16,007 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:103.26204681396484|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956316
2022-04-03T12:25:16,008 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:125.0118179321289|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956316
2022-04-03T12:25:16,008 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956316
2022-04-03T12:25:16,008 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:1417.171875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956316
2022-04-03T12:25:16,008 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:2655.140625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956316
2022-04-03T12:25:16,008 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:82.7|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956316
2022-04-03T12:25:37,210 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956337210
2022-04-03T12:25:37,210 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956337210
2022-04-03T12:25:37,215 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648956337
2022-04-03T12:25:37,351 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 140
2022-04-03T12:25:37,351 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 140
2022-04-03T12:25:37,352 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - tensor([   0, 4224,  743, 4229, 1085, 2065, 2484, 2062,    2])
2022-04-03T12:25:37,352 [INFO ] W-9001-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:136.56|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:8ef42216-81b2-47c4-beb9-89886c7f5b47,timestamp:1648956337
2022-04-03T12:25:37,353 [INFO ] W-9001-my_tc_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:136.65|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:8ef42216-81b2-47c4-beb9-89886c7f5b47,timestamp:1648956337
2022-04-03T12:25:37,353 [INFO ] W-9001-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55715 "POST /predictions/my_tc HTTP/1.1" 200 144
2022-04-03T12:25:37,353 [INFO ] W-9001-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:25:37,353 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 188750, Backend time ns: 143720125
2022-04-03T12:25:37,353 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 188750, Backend time ns: 143720125
2022-04-03T12:25:37,354 [INFO ] W-9001-my_tc_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:25:37,354 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:4|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:28:32,724 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:28:32,724 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-03T12:28:33,330 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:28:33,330 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-03T12:28:33,341 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:28:33,341 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-03T12:28:33,374 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:28:33,374 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-03T12:28:44,322 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:28:44,322 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-03T12:28:44,323 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:28:44,323 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-03T12:28:44,324 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:28:44,324 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-03T12:28:44,324 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:28:44,324 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-03T12:28:44,376 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:28:44,381 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:28:44,386 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:28:44,379 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:28:44,386 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:28:44,380 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:28:44,384 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:28:44,376 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-03T12:28:44,381 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-03T12:28:44,383 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:28:44,386 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-03T12:28:44,380 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-03T12:28:44,384 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-03T12:28:44,389 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:28:44,383 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-03T12:28:44,379 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-03T12:28:44,389 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-03T12:28:44,386 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-03T12:28:45,258 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:28:45,258 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-03T12:28:45,261 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:28:45,261 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-03T12:28:45,266 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:28:45,266 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-03T12:28:45,274 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:28:45,274 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-03T12:28:45,292 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:28:45,292 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-03T12:28:45,628 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:28:45,633 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]35407
2022-04-03T12:28:45,635 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:28:45,635 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:28:45,637 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:45,637 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:45,654 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:28:45,654 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-03T12:28:45,687 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-03T12:28:45,700 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956525698
2022-04-03T12:28:45,700 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956525698
2022-04-03T12:28:45,849 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:28:45,931 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:28:45,941 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:28:45,950 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]35405
2022-04-03T12:28:45,948 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]35411
2022-04-03T12:28:45,960 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:45,960 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:45,961 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:45,961 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:45,961 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:28:45,961 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:28:45,961 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-03T12:28:45,961 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-03T12:28:45,959 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:28:45,960 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:28:45,949 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:28:45,949 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:28:45,986 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:28:45,989 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]35408
2022-04-03T12:28:45,981 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:28:45,959 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:28:45,959 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:28:45,992 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-03T12:28:45,992 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956525992
2022-04-03T12:28:45,992 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956525992
2022-04-03T12:28:45,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:28:45,998 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]35406
2022-04-03T12:28:45,999 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:45,999 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:45,998 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]35409
2022-04-03T12:28:45,992 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956525992
2022-04-03T12:28:45,992 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956525992
2022-04-03T12:28:46,000 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:28:46,000 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-03T12:28:46,001 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-03T12:28:46,002 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:46,002 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:46,017 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:28:46,019 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:28:46,001 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:28:46,020 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:28:46,022 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:46,017 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-03T12:28:46,022 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:46,032 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:28:46,017 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]35410
2022-04-03T12:28:46,033 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956526033
2022-04-03T12:28:46,032 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-03T12:28:46,033 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:28:46,033 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956526033
2022-04-03T12:28:46,032 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:28:46,033 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:46,033 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:46,033 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:28:46,033 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-03T12:28:45,983 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:28:46,057 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:28:46,046 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:28:46,059 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:28:46,046 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-03T12:28:46,047 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:28:46,070 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]35412
2022-04-03T12:28:46,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:28:46,088 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-03T12:28:46,089 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:46,089 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-03T12:28:46,089 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-03T12:28:46,142 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:28:46,142 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-03T12:28:46,162 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-03T12:28:46,163 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-03T12:28:46,162 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-03T12:28:46,174 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956526171
2022-04-03T12:28:46,174 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956526171
2022-04-03T12:28:46,174 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956526171
2022-04-03T12:28:46,181 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956526172
2022-04-03T12:28:46,174 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956526171
2022-04-03T12:28:46,174 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956526171
2022-04-03T12:28:46,174 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956526171
2022-04-03T12:28:46,174 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-03T12:28:46,181 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956526172
2022-04-03T12:28:46,304 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:28:46,315 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:28:46,326 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:28:46,327 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:28:46,328 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-03T12:28:46,450 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:28:46,461 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:28:46,517 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:28:46,532 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956526
2022-04-03T12:28:46,538 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:103.26285934448242|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956526
2022-04-03T12:28:46,538 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:125.01100540161133|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956526
2022-04-03T12:28:46,539 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:54.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956526
2022-04-03T12:28:46,540 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:2968.671875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956526
2022-04-03T12:28:46,540 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:4268.984375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956526
2022-04-03T12:28:46,541 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:63.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956526
2022-04-03T12:28:46,674 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:28:46,675 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:28:46,677 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:28:46,677 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformers version 4.17.0
2022-04-03T12:29:05,134 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight', 'lm_head.bias']
2022-04-03T12:29:05,134 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']
2022-04-03T12:29:05,682 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:29:05,134 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias']
2022-04-03T12:29:05,135 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']
2022-04-03T12:29:05,924 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:29:05,924 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:29:05,924 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:29:05,135 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias']
2022-04-03T12:29:05,682 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:29:05,134 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']
2022-04-03T12:29:05,134 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']
2022-04-03T12:29:06,272 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:29:06,272 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:29:06,272 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:29:06,272 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:29:06,291 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.bias']
2022-04-03T12:29:06,272 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:29:06,288 [WARN ] W-9001-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:29:06,291 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:29:06,290 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:29:13,457 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:29:06,272 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:29:06,272 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
2022-04-03T12:29:19,186 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33139
2022-04-03T12:29:19,187 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33130
2022-04-03T12:29:19,186 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33101
2022-04-03T12:29:19,186 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32863
2022-04-03T12:29:19,187 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32860
2022-04-03T12:29:19,187 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32871
2022-04-03T12:29:19,187 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33339
2022-04-03T12:29:19,186 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32868
2022-04-03T12:29:19,186 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32868
2022-04-03T12:29:19,186 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33139
2022-04-03T12:29:19,187 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33339
2022-04-03T12:29:19,187 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32871
2022-04-03T12:29:19,187 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32860
2022-04-03T12:29:19,186 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33101
2022-04-03T12:29:19,187 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 33130
2022-04-03T12:29:19,186 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 32863
2022-04-03T12:29:13,454 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:29:19,161 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/39dbce7218fb4a1883e15421440a5ab4 loaded successfully
2022-04-03T12:29:19,911 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,035 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/39dbce7218fb4a1883e15421440a5ab4 loaded successfully
2022-04-03T12:29:18,988 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/39dbce7218fb4a1883e15421440a5ab4 loaded successfully
2022-04-03T12:29:19,020 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/39dbce7218fb4a1883e15421440a5ab4 loaded successfully
2022-04-03T12:29:18,882 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/39dbce7218fb4a1883e15421440a5ab4 loaded successfully
2022-04-03T12:29:18,877 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/39dbce7218fb4a1883e15421440a5ab4 loaded successfully
2022-04-03T12:29:18,882 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/39dbce7218fb4a1883e15421440a5ab4 loaded successfully
2022-04-03T12:29:18,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Transformer model from path /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/39dbce7218fb4a1883e15421440a5ab4 loaded successfully
2022-04-03T12:29:19,923 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:29:13,510 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:29:19,923 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:29:19,923 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:29:13,504 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:29:19,923 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:29:13,505 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:29:13,510 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - - This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
2022-04-03T12:29:19,922 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:29:19,916 [WARN ] W-9003-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:29:19,922 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:29:13,521 [WARN ] W-9006-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:29:19,911 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,923 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:29:19,911 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:13,505 [WARN ] W-9007-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:29:19,916 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Missing the index_to_name.json file.
2022-04-03T12:29:19,911 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,911 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2022-04-03T12:29:19,935 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:29:19,926 [INFO ] W-9004-my_tc_1.0 TS_METRICS - W-9004-my_tc_1.0.ms:35574|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956559
2022-04-03T12:29:19,940 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
2022-04-03T12:29:19,930 [INFO ] W-9006-my_tc_1.0 TS_METRICS - W-9006-my_tc_1.0.ms:35572|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956559
2022-04-03T12:29:19,932 [INFO ] W-9002-my_tc_1.0 TS_METRICS - W-9002-my_tc_1.0.ms:35589|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956559
2022-04-03T12:29:19,940 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:29:19,939 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']
2022-04-03T12:29:19,932 [INFO ] W-9007-my_tc_1.0 TS_METRICS - W-9007-my_tc_1.0.ms:35576|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956559
2022-04-03T12:29:19,932 [INFO ] W-9003-my_tc_1.0 TS_METRICS - W-9003-my_tc_1.0.ms:35581|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956559
2022-04-03T12:29:19,975 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:931|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:29:19,975 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:944|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:29:19,975 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:938|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:29:19,926 [INFO ] W-9001-my_tc_1.0 TS_METRICS - W-9001-my_tc_1.0.ms:35582|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956559
2022-04-03T12:29:19,931 [INFO ] W-9005-my_tc_1.0 TS_METRICS - W-9005-my_tc_1.0.ms:35572|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956559
2022-04-03T12:29:19,976 [INFO ] W-9001-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:842|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:29:19,977 [INFO ] W-9005-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:943|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:29:19,975 [INFO ] W-9002-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:936|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:29:19,931 [INFO ] W-9000-my_tc_1.0 TS_METRICS - W-9000-my_tc_1.0.ms:35590|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956559
2022-04-03T12:29:19,977 [INFO ] W-9000-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:846|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:29:19,976 [INFO ] W-9003-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:853|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:29:19,980 [WARN ] W-9004-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:29:19,980 [WARN ] W-9002-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:29:19,980 [WARN ] W-9005-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:29:19,980 [WARN ] W-9000-my_tc_1.0-stderr MODEL_LOG - You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2022-04-03T12:29:47,948 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:50.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956587
2022-04-03T12:29:47,956 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.26834106445312|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956587
2022-04-03T12:29:47,956 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:126.00552368164062|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956587
2022-04-03T12:29:47,957 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956587
2022-04-03T12:29:47,957 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1309.234375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956587
2022-04-03T12:29:47,957 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2514.59375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956587
2022-04-03T12:29:47,958 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:84.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956587
2022-04-03T12:29:54,123 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956594123
2022-04-03T12:29:54,123 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956594123
2022-04-03T12:29:54,135 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648956594
2022-04-03T12:29:54,432 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - tensor([   0, 4224,  743, 4229, 1085, 2065, 2484, 2062,    2])
2022-04-03T12:29:54,439 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 306
2022-04-03T12:29:54,439 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 306
2022-04-03T12:29:54,432 [INFO ] W-9004-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:295.07|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:d7928fa8-423b-4ea0-930e-cd05f580a039,timestamp:1648956594
2022-04-03T12:29:54,442 [INFO ] W-9004-my_tc_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:295.6|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:d7928fa8-423b-4ea0-930e-cd05f580a039,timestamp:1648956594
2022-04-03T12:29:54,444 [INFO ] W-9004-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55829 "POST /predictions/my_tc HTTP/1.1" 200 335
2022-04-03T12:29:54,445 [INFO ] W-9004-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:29:54,445 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 275667, Backend time ns: 322380375
2022-04-03T12:29:54,445 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 275667, Backend time ns: 322380375
2022-04-03T12:29:54,445 [INFO ] W-9004-my_tc_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:29:54,445 [INFO ] W-9004-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:16|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:30:07,235 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956607235
2022-04-03T12:30:07,235 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956607235
2022-04-03T12:30:07,248 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648956607
2022-04-03T12:30:07,457 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - tensor([    0,  1396,  1504,  1085, 16999,   770,     2])
2022-04-03T12:30:07,458 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 216
2022-04-03T12:30:07,458 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 216
2022-04-03T12:30:07,458 [INFO ] W-9006-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:207.03|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:ea8ce07d-3fa1-48a4-b157-4d467a33529f,timestamp:1648956607
2022-04-03T12:30:07,460 [INFO ] W-9006-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55831 "POST /predictions/my_tc HTTP/1.1" 200 227
2022-04-03T12:30:07,465 [INFO ] W-9006-my_tc_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:207.12|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:ea8ce07d-3fa1-48a4-b157-4d467a33529f,timestamp:1648956607
2022-04-03T12:30:07,465 [INFO ] W-9006-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:30:07,466 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 165625, Backend time ns: 231054583
2022-04-03T12:30:07,466 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 165625, Backend time ns: 231054583
2022-04-03T12:30:07,466 [INFO ] W-9006-my_tc_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:30:07,466 [INFO ] W-9006-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:15|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:30:22,760 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956622759
2022-04-03T12:30:22,760 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648956622759
2022-04-03T12:30:22,764 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend received inference at: 1648956622
2022-04-03T12:30:22,943 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 181
2022-04-03T12:30:22,943 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - tensor([    0,  4244, 31302,  3760,  1325,  2030,  2182,    97,    97,    97,
2022-04-03T12:30:22,943 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 181
2022-04-03T12:30:22,945 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -            97,     2])
2022-04-03T12:30:22,945 [INFO ] W-9007-my_tc_1.0 ACCESS_LOG - /127.0.0.1:55834 "POST /predictions/my_tc HTTP/1.1" 200 186
2022-04-03T12:30:22,945 [INFO ] W-9007-my_tc_1.0-stdout MODEL_METRICS - HandlerTime.Milliseconds:178.91|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:b2f46e07-a85c-472a-8405-ceaa277dcc65,timestamp:1648956622
2022-04-03T12:30:22,947 [INFO ] W-9007-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:30:22,947 [INFO ] W-9007-my_tc_1.0-stdout MODEL_METRICS - PredictionTime.Milliseconds:179.01|#ModelName:my_tc,Level:Model|#hostname:MacBook-Air-2.local,requestID:b2f46e07-a85c-472a-8405-ceaa277dcc65,timestamp:1648956622
2022-04-03T12:30:22,948 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 340916, Backend time ns: 188394834
2022-04-03T12:30:22,948 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.job.Job - Waiting time ns: 340916, Backend time ns: 188394834
2022-04-03T12:30:22,948 [INFO ] W-9007-my_tc_1.0 TS_METRICS - QueueTime.ms:0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:30:22,948 [INFO ] W-9007-my_tc_1.0 TS_METRICS - WorkerThreadTime.ms:8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-03T12:30:46,502 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956646
2022-04-03T12:30:46,504 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.26673126220703|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956646
2022-04-03T12:30:46,504 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:126.00713348388672|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956646
2022-04-03T12:30:46,504 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956646
2022-04-03T12:30:46,504 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1423.765625|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956646
2022-04-03T12:30:46,505 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2587.25|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956646
2022-04-03T12:30:46,505 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.6|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956646
2022-04-03T12:31:46,506 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956706
2022-04-03T12:31:46,508 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:102.26560592651367|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956706
2022-04-03T12:31:46,509 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:126.00825881958008|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956706
2022-04-03T12:31:46,509 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:55.2|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956706
2022-04-03T12:31:46,509 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1407.46875|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956706
2022-04-03T12:31:46,510 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2605.734375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956706
2022-04-03T12:31:46,510 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:82.8|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648956706
