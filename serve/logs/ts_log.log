2022-04-02T15:16:41,734 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-02T15:16:41,734 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-02T15:16:42,339 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-02T15:16:42,339 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-02T15:16:42,356 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-02T15:16:42,356 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-02T15:16:42,411 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-02T15:16:42,411 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-02T15:16:53,651 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-02T15:16:53,651 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-02T15:16:53,652 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-02T15:16:53,652 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-02T15:16:53,652 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-02T15:16:53,652 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-02T15:16:53,653 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-02T15:16:53,653 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-02T15:16:53,717 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-02T15:16:53,710 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:16:53,714 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:16:53,712 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:16:53,717 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-02T15:16:53,710 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:16:53,710 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:16:53,710 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:16:53,715 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:16:53,708 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:16:53,710 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:16:53,710 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:16:53,708 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:16:53,715 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:16:53,710 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:16:53,712 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:16:53,714 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:16:53,710 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:16:54,180 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-02T15:16:54,180 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-02T15:16:54,182 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-02T15:16:54,182 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-02T15:16:54,190 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-02T15:16:54,190 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-02T15:16:54,191 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-02T15:16:54,191 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-02T15:16:54,197 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-02T15:16:54,197 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-02T15:16:54,987 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:16:55,000 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]96502
2022-04-02T15:16:55,003 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:55,006 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:55,010 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,010 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,024 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:16:55,024 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:16:55,093 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:16:55,111 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215110
2022-04-02T15:16:55,111 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215110
2022-04-02T15:16:55,182 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:55,291 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-02T15:16:55,291 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2022-04-02T15:16:55,313 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:16:55,313 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:16:55,320 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]96507
2022-04-02T15:16:55,320 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]96504
2022-04-02T15:16:55,321 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,321 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,321 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,321 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:55,321 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:55,321 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,322 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:16:55,322 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:16:55,322 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:55,322 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:16:55,322 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:55,322 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:16:55,340 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215340
2022-04-02T15:16:55,338 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:16:55,340 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215340
2022-04-02T15:16:55,320 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:16:55,342 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215341
2022-04-02T15:16:55,342 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215341
2022-04-02T15:16:55,338 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:16:55,343 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:16:55,350 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]96503
2022-04-02T15:16:55,344 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]96501
2022-04-02T15:16:55,352 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:55,352 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:55,359 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,353 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:55,358 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,359 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,358 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,364 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:16:55,357 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:55,364 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:16:55,364 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:16:55,364 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:16:55,361 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:16:55,391 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215391
2022-04-02T15:16:55,390 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:55,390 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:16:55,391 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215391
2022-04-02T15:16:55,394 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:16:55,366 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]96505
2022-04-02T15:16:55,394 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215393
2022-04-02T15:16:55,387 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:16:55,394 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215393
2022-04-02T15:16:55,387 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:55,395 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:55,396 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,396 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]96506
2022-04-02T15:16:55,396 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:55,396 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,397 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:16:55,397 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,397 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:16:55,386 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:16:55,397 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:55,397 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:55,397 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,397 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]96508
2022-04-02T15:16:55,398 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:16:55,398 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,398 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:16:55,398 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:16:55,399 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:16:55,399 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:16:55,398 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:55,537 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215537
2022-04-02T15:16:55,537 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:55,537 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215537
2022-04-02T15:16:55,537 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215537
2022-04-02T15:16:55,536 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:55,537 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:16:55,537 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215537
2022-04-02T15:16:55,539 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215537
2022-04-02T15:16:55,539 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880215537
2022-04-02T15:16:55,535 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:55,539 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:16:55,537 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:16:55,619 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:55,435 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648880215
2022-04-02T15:16:55,699 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:55,699 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:55,698 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:55,708 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:55,714 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:108.82231903076172|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648880215
2022-04-02T15:16:55,717 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:55,719 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:119.45154571533203|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648880215
2022-04-02T15:16:55,719 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:55,721 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:55,720 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:52.3|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648880215
2022-04-02T15:16:55,733 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:55,741 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1810.59375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648880215
2022-04-02T15:16:55,748 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:3260.703125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648880215
2022-04-02T15:16:55,749 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:77.9|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648880215
2022-04-02T15:16:55,754 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:55,749 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:55,754 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:55,754 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:55,754 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:55,755 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:55,755 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:55,755 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:55,755 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:55,756 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:55,756 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:55,756 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:55,756 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:55,756 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:55,757 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:55,757 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:55,757 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:55,757 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:55,757 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:55,757 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:55,757 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:55,758 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:55,758 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:55,757 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:55,758 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:55,758 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:55,760 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:55,760 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:55,761 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:55,759 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:55,762 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:55,762 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:55,763 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:55,763 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:55,763 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:55,763 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:55,763 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:55,763 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:55,763 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:55,763 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:55,763 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:55,764 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:55,764 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:55,764 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:55,761 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:55,764 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:55,764 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:55,784 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:55,782 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:55,797 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:55,788 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:55,805 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:55,807 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:55,805 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:55,805 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:55,810 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:55,811 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:55,806 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:55,806 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:55,826 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:55,834 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:16:55,832 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:55,817 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:55,806 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:55,806 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:55,837 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:55,865 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:55,837 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:55,837 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:16:55,806 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:55,806 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:55,879 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:55,879 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:55,865 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:55,879 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:55,910 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:55,879 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:55,891 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:16:55,891 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:55,979 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:16:55,979 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:16:55,979 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:55,979 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:55,918 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:55,979 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:16:55,979 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:55,979 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:16:55,980 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:16:55,946 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:55,948 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:55,979 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:16:55,979 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:56,034 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:55,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,021 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:56,021 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:56,020 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:16:56,045 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:56,019 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,069 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,069 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:56,069 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:56,058 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:56,069 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:56,019 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:16:56,019 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,070 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:56,070 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:56,058 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,070 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:56,071 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:56,044 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:56,069 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:56,040 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:56,071 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:56,034 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:56,021 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:16:56,070 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:16:56,033 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:56,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,071 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:56,071 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:56,072 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:16:56,071 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,107 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:16:56,080 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:56,033 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:56,135 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:16:56,077 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:56,107 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:16:56,162 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:56,146 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:56,181 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:56,021 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:16:56,154 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:56,146 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:56,225 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:56,225 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:56,226 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,225 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,161 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:16:56,094 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:16:56,090 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,224 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:56,225 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:56,040 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:56,226 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,227 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,226 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,227 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,229 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,229 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,229 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,229 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,229 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,226 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:16:56,226 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:56,229 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,230 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:16:56,227 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:56,230 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:16:56,230 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:56,230 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:56,230 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:56,227 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:56,226 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:16:56,188 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:16:56,230 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,230 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,188 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:16:56,135 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:16:56,227 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:56,244 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,188 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:16:56,077 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:56,243 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,244 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:56,244 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:56,188 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:16:56,288 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:56,288 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:56,226 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:16:56,278 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,243 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:56,288 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:16:56,293 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,288 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:56,288 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:16:56,298 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:56,298 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,298 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,288 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,243 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:56,299 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,298 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:56,299 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:16:56,299 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,299 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,299 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,299 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:56,299 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:16:56,299 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:56,299 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:56,299 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,299 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:56,299 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,299 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,299 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:16:56,299 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,299 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,299 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:16:56,299 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:16:56,299 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:56,299 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:56,300 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:16:56,300 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:16:56,300 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:56,300 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:16:56,300 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:56,300 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:56,300 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,300 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,300 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:56,300 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:56,300 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:56,300 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,300 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,300 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:56,300 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,300 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:56,300 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:56,300 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:56,300 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,300 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,300 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,301 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,300 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:56,300 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:56,300 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,301 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,317 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:16:56,308 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:56,308 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,318 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,308 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:16:56,309 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,309 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:56,317 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:16:56,309 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:16:56,324 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:56,325 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,325 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,325 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:56,324 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,324 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:56,325 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,326 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,326 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:56,326 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,334 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:56,335 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:56,333 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:56,337 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:56,337 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,337 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:56,337 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:56,337 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:56,337 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:16:56,337 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:56,337 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:56,337 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:16:56,336 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,337 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,337 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:56,339 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:56,339 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:56,340 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:16:56,339 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:56,341 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,341 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:56,341 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,341 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,341 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:56,341 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:56,341 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:56,341 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:56,341 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:56,341 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:16:56,341 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:16:56,341 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:16:56,344 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:16:56,344 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:56,344 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:56,343 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:56,344 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:56,355 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:16:56,355 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:56,355 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:16:56,355 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:56,355 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:16:56,361 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:16:56,363 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:56,362 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:16:56,355 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:16:56,355 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:56,364 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:16:56,361 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:16:56,364 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:56,369 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:16:56,366 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:56,367 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:16:56,363 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:16:56,369 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:56,369 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:16:56,369 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:16:56,369 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:16:56,369 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:16:56,369 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:16:56,369 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:16:56,369 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:16:56,369 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:16:56,369 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:16:56,369 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:56,369 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:16:56,369 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,369 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:16:56,369 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:16:56,370 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:16:56,369 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:56,370 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:16:56,370 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:16:56,370 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,370 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,370 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:16:56,370 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:16:56,370 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:16:56,370 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,370 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,370 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,370 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:16:56,370 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,370 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:16:56,370 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,370 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,370 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:16:56,370 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:16:56,370 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,370 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:16:56,370 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:16:56,370 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,370 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,370 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,371 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,371 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,371 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,371 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,371 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,371 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,371 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,371 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:16:56,371 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:16:56,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,371 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:16:56,371 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:16:56,371 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:16:56,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,371 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:16:56,371 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:16:56,371 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:16:56,371 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:16:56,373 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:16:56,373 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:16:56,373 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:16:56,376 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,374 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:56,373 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:16:56,386 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,386 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:56,389 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,389 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,389 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,390 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,390 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:16:56,390 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:16:56,390 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:16:56,390 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:16:56,392 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:16:56,392 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:16:56,394 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:16:56,394 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:16:56,399 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,402 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:16:56,403 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:56,403 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:56,403 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:56,403 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:16:56,404 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:16:56,405 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:16:56,405 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:16:56,090 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:55,916 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:55,891 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:56,069 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:56,292 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:56,226 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:55,889 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:55,916 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:56,069 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:55,891 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:55,889 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:56,090 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:56,292 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:56,465 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,465 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,465 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,465 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,465 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,465 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,465 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,465 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,465 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,466 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,465 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,466 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,466 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,466 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,466 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,466 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,295 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:56,465 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,465 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,465 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,295 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:56,226 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:56,465 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,475 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,474 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,475 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:16:56,476 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,475 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,476 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,474 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:56,475 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:16:56,475 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:16:56,478 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:16:56,478 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,479 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,475 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:16:56,479 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,478 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,478 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:16:56,475 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:16:56,480 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:16:56,480 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:16:56,480 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,480 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:56,480 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:16:56,480 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:16:56,475 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:16:56,480 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:16:56,482 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:16:56,478 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:16:56,480 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:16:56,480 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:16:56,480 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:16:56,478 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:16:56,482 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:16:56,489 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:16:56,489 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:16:56,489 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:16:56,489 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:16:56,489 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:16:56,489 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:16:56,489 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:16:56,489 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:16:56,494 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-02T15:16:56,494 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:16:56,494 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-02T15:16:56,495 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-02T15:16:56,494 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:16:56,494 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-02T15:16:56,494 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-02T15:16:56,494 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-02T15:16:56,495 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-02T15:16:56,494 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-02T15:16:56,494 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:16:56,494 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:16:56,495 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-02T15:16:56,495 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-02T15:16:56,497 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-02T15:16:56,497 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-02T15:16:56,497 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-02T15:16:56,497 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-02T15:16:56,495 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-02T15:16:56,495 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-02T15:16:57,520 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:16:57,520 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:16:57,520 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:16:57,520 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:16:57,520 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:16:57,520 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:16:57,524 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:16:57,524 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:16:57,525 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:16:57,525 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:16:57,525 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:16:57,525 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:16:57,526 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:16:57,526 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:16:57,527 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:16:57,527 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:16:58,800 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:16:58,807 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:16:58,810 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]96513
2022-04-02T15:16:58,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:16:58,810 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:58,810 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:58,810 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]96515
2022-04-02T15:16:58,810 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:58,810 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:58,810 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]96517
2022-04-02T15:16:58,810 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:58,810 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:58,811 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,811 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,811 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,811 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,812 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,812 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,813 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:16:58,813 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:16:58,812 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:16:58,813 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]96514
2022-04-02T15:16:58,813 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:58,813 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:58,814 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,814 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,814 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:16:58,814 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:16:58,814 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:16:58,814 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:16:58,816 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:16:58,816 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:16:58,828 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:16:58,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:16:58,827 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:16:58,855 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]96516
2022-04-02T15:16:58,855 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]96519
2022-04-02T15:16:58,855 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:58,855 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]96518
2022-04-02T15:16:58,855 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,856 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:58,855 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,856 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:58,856 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:58,856 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:58,855 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:16:58,856 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]96520
2022-04-02T15:16:58,857 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:16:58,857 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:58,856 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:16:58,857 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:16:58,857 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:16:58,857 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,857 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,857 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:16:58,857 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:16:58,860 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:16:58,860 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:16:58,860 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,860 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:16:58,860 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:16:58,860 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:16:58,911 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:16:58,920 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:16:58,919 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:16:58,912 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:16:58,918 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:16:58,926 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218926
2022-04-02T15:16:58,926 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218926
2022-04-02T15:16:58,926 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218926
2022-04-02T15:16:58,926 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218926
2022-04-02T15:16:58,926 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218926
2022-04-02T15:16:58,926 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218926
2022-04-02T15:16:58,927 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218927
2022-04-02T15:16:58,927 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218927
2022-04-02T15:16:58,927 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218927
2022-04-02T15:16:58,927 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218927
2022-04-02T15:16:58,933 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:16:58,938 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218938
2022-04-02T15:16:58,938 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218938
2022-04-02T15:16:58,938 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218938
2022-04-02T15:16:58,938 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218938
2022-04-02T15:16:58,941 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:16:58,956 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:16:58,962 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218962
2022-04-02T15:16:58,962 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880218962
2022-04-02T15:16:59,078 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:59,075 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:59,082 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:59,078 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:59,081 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:59,082 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:59,115 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:59,115 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:16:59,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:59,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,371 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:59,378 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:59,381 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:59,381 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:59,381 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,382 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:59,382 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:59,384 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,382 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:59,390 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:59,390 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:59,390 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:59,371 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:59,393 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:59,393 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,384 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,393 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:59,393 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:59,437 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,449 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,407 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,425 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,384 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,382 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:59,384 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,454 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:59,472 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:59,472 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,472 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,472 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:59,472 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,473 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:59,473 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:59,473 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:59,473 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:59,435 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:59,453 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:59,453 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:59,473 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:59,465 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,382 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:59,465 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,475 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,476 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:59,474 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:59,476 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:59,477 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:59,477 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:59,477 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:59,477 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:59,477 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:59,393 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,475 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:59,480 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:59,480 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:59,480 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:59,480 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:59,481 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,480 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:59,442 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,473 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,477 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,477 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,502 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,502 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,503 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,503 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,514 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:16:59,514 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:16:59,514 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:16:59,407 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,449 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,437 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,514 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:16:59,525 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-02T15:16:59,425 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,525 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-02T15:16:59,531 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:59,532 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:16:59,532 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:59,532 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,532 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,532 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:59,533 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:59,533 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,533 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,533 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,533 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,534 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:59,537 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:59,538 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,508 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:16:59,498 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,545 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:16:59,537 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:59,545 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,545 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:16:59,545 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:59,498 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,508 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:16:59,544 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:59,538 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,542 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:59,442 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:16:59,543 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:59,542 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:59,580 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:59,559 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,559 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,577 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,577 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:16:59,562 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:59,562 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:59,561 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:16:59,580 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:59,593 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:16:59,588 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:59,588 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:16:59,588 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:59,473 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,603 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,603 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,603 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,603 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,588 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:59,587 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:59,546 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,582 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,587 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:59,558 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,539 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,628 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:59,546 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,673 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:16:59,543 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,539 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,582 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,678 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:59,558 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,673 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:16:59,677 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:59,543 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,681 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:59,681 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:59,681 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:16:59,681 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:59,681 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:16:59,681 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,681 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:59,681 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,681 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,681 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,681 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,681 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:59,681 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,681 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,583 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,675 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:16:59,684 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:59,681 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:59,683 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:16:59,683 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:59,684 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:59,684 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:59,685 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:59,684 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:16:59,685 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:59,685 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:59,685 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:59,583 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:16:59,683 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:59,685 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:59,685 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:59,685 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:59,685 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:59,685 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:59,669 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:16:59,685 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:59,685 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:59,681 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:59,685 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:59,685 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:59,685 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:59,686 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:59,684 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:59,685 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:59,685 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,686 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,686 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:59,685 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:59,686 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:59,681 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,686 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:59,680 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:16:59,686 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:59,686 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:59,686 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:59,686 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:59,686 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:59,686 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:59,687 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:59,709 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-02T15:16:59,708 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:16:59,708 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:16:59,698 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,698 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,593 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:16:59,713 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,713 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,680 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:16:59,702 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,680 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:16:59,687 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:59,687 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:59,687 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:59,702 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,709 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-02T15:16:59,709 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:16:59,711 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:16:59,687 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:59,713 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:16:59,687 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:59,702 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,713 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:16:59,711 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:16:59,709 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:16:59,731 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:16:59,702 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:16:59,731 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:16:59,735 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-02T15:16:59,735 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-02T15:16:59,733 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:16:59,733 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:16:59,735 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-02T15:16:59,735 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-02T15:16:59,737 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:59,737 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,737 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,738 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:59,738 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:59,738 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:59,738 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:16:59,738 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:16:59,738 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:59,738 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,743 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,745 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,745 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,738 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:59,746 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:59,743 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,745 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,748 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:16:59,745 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:59,748 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:16:59,748 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:59,748 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:59,748 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:59,748 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:16:59,748 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:16:59,748 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:16:59,748 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:16:59,749 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:16:59,749 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:59,745 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:16:59,755 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:59,748 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:16:59,754 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:16:59,767 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:16:59,767 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:16:59,767 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:16:59,767 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:59,767 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:16:59,767 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:16:59,767 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:16:59,767 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:16:59,768 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:16:59,768 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:16:59,767 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:16:59,768 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:16:59,768 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-02T15:16:59,768 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:16:59,768 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-02T15:16:59,768 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:16:59,768 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:16:59,768 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:59,771 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:16:59,706 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:16:59,777 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:16:59,680 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:16:59,780 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:16:59,780 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:16:59,780 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:16:59,781 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:59,781 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:16:59,781 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:59,781 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:16:59,781 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:16:59,781 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:16:59,781 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:16:59,781 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:16:59,781 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:16:59,675 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:16:59,782 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:16:59,782 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:16:59,782 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:16:59,782 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:16:59,781 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:16:59,782 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-02T15:16:59,782 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-02T15:16:59,782 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:16:59,782 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:16:59,781 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:16:59,680 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:16:59,782 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:16:59,782 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:16:59,783 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:16:59,783 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:16:59,784 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:16:59,784 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:16:59,784 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-02T15:16:59,784 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-02T15:16:59,784 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-02T15:16:59,784 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-02T15:16:59,784 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:16:59,785 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:16:59,785 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:16:59,786 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:16:59,786 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:16:59,706 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:16:59,680 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:16:59,669 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:00,536 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:00,536 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:00,688 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:00,688 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:00,735 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:00,735 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:00,739 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:00,739 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:00,834 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:00,834 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:00,835 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:00,835 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:00,835 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:00,835 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:00,835 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:00,835 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:01,376 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:01,380 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]96521
2022-04-02T15:17:01,381 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:01,381 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:01,381 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:01,381 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:01,382 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:01,382 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:01,390 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880221390
2022-04-02T15:17:01,390 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880221390
2022-04-02T15:17:01,459 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:17:01,459 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:02,117 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:02,121 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]96522
2022-04-02T15:17:02,121 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:02,121 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:02,122 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,122 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,122 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:02,122 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:02,124 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222124
2022-04-02T15:17:02,124 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222124
2022-04-02T15:17:02,130 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:17:02,131 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:02,152 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:02,153 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,153 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:02,153 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:02,153 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:02,153 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:02,153 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:02,153 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:02,153 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:02,153 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:02,153 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:02,156 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,156 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,156 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:02,157 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,157 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,157 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:02,157 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:02,158 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:02,159 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:02,159 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:02,159 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:02,159 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:02,159 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:02,159 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:02,159 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:02,159 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:02,159 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:02,159 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:02,160 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:02,160 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:02,160 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:02,161 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:02,162 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:02,163 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:02,164 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:02,164 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:02,158 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,158 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,173 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,173 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,173 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,173 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,173 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:02,173 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:02,173 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:02,176 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:02,176 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:02,173 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:02,183 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:02,183 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:02,184 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-04-02T15:17:02,184 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-04-02T15:17:02,259 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:02,261 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]96526
2022-04-02T15:17:02,261 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:02,261 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:02,261 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,261 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,262 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:02,262 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:02,266 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222265
2022-04-02T15:17:02,263 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:02,267 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:17:02,266 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222265
2022-04-02T15:17:02,266 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:02,269 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:02,269 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]96528
2022-04-02T15:17:02,269 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:02,269 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:02,270 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,270 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,270 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]96523
2022-04-02T15:17:02,270 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:02,270 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:02,270 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:02,270 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:02,271 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,271 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,270 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:02,277 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:02,277 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:02,282 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]96527
2022-04-02T15:17:02,282 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:17:02,283 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:02,283 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:02,283 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222283
2022-04-02T15:17:02,283 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222283
2022-04-02T15:17:02,288 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,288 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,293 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:17:02,294 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222294
2022-04-02T15:17:02,294 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222294
2022-04-02T15:17:02,294 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:02,295 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:02,295 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:02,301 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222301
2022-04-02T15:17:02,301 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222301
2022-04-02T15:17:02,281 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:02,305 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:17:02,301 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:02,306 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]96525
2022-04-02T15:17:02,306 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:02,306 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:02,306 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,306 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,306 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:02,306 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:02,314 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222310
2022-04-02T15:17:02,315 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:17:02,314 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222310
2022-04-02T15:17:02,305 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:02,317 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]96524
2022-04-02T15:17:02,318 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:02,318 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:02,318 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,318 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:02,319 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:02,319 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:02,319 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:02,326 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:02,329 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:17:02,331 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222331
2022-04-02T15:17:02,331 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880222331
2022-04-02T15:17:02,334 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:02,442 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:02,443 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,443 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:02,443 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:02,443 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:02,443 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:02,443 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:02,445 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,443 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:02,446 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:02,445 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,446 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:02,446 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:02,446 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:02,446 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:02,446 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:02,449 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,446 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:02,451 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:02,451 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:02,451 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:02,449 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,451 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:02,451 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:02,451 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,451 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,451 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:02,451 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,453 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,453 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,453 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,452 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:02,453 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,453 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:02,453 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:02,453 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:02,453 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:02,456 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:02,456 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:02,457 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:02,457 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:02,458 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-04-02T15:17:02,458 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-04-02T15:17:02,468 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:02,468 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:02,468 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:02,622 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,622 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,623 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,623 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,623 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:02,623 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,623 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,623 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,624 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,623 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:02,624 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,624 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,624 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,624 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:02,624 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:02,625 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:02,625 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:02,625 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:02,625 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:02,625 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:02,625 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:02,626 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:02,625 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:02,626 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:02,635 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:02,635 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:02,635 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:02,636 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:02,637 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:02,637 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,637 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:02,637 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:02,637 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:02,637 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:02,637 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:02,642 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:02,651 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,656 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-04-02T15:17:02,637 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:02,682 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:02,696 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,693 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,667 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:02,700 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,642 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:02,705 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,651 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,681 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:02,700 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,696 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,682 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:02,705 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,710 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,693 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:02,716 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,716 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:02,716 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:02,716 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:02,716 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:02,716 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:02,716 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:02,717 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,717 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:02,716 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:02,717 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,717 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,717 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,717 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:02,717 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:02,717 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:02,717 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:02,717 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,717 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:02,717 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,656 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-04-02T15:17:02,717 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:02,717 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:02,717 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,717 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:02,718 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:02,717 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:02,718 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:02,718 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:02,718 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:02,718 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:02,718 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:02,718 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:02,710 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,718 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:02,719 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,719 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:02,719 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:02,719 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:02,719 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:02,719 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:02,719 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:02,719 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:02,718 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,718 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,719 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,719 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,719 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,719 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:02,720 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:02,719 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,720 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,719 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,720 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,720 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:02,718 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,718 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,721 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:02,721 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:02,721 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:02,721 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:02,721 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:02,721 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:02,721 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,721 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:02,720 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:02,721 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,721 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,721 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:02,722 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,722 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,718 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,722 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:02,722 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:02,722 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:02,722 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,709 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:02,718 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,722 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:02,723 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,723 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,723 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,723 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,721 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:02,723 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:02,723 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,723 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:02,723 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:02,723 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:02,724 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:02,724 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,724 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,724 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,724 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:02,724 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,724 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,724 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:02,724 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:02,724 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:02,724 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:02,725 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:02,725 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:02,725 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:02,725 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:02,721 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:02,725 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,725 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:02,722 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:02,725 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:02,725 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:02,725 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:02,725 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:02,725 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:02,721 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:02,725 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:02,725 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:02,726 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:02,726 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:02,726 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:02,726 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:02,726 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:02,726 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:02,726 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:02,726 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:02,726 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:02,726 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:02,726 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:02,726 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-04-02T15:17:02,726 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-04-02T15:17:02,726 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,726 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-04-02T15:17:02,726 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:02,726 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:02,726 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-04-02T15:17:02,726 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-04-02T15:17:02,726 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:02,726 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:02,726 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-04-02T15:17:02,727 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:02,726 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:02,726 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:02,726 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:02,726 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:02,722 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:02,745 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:02,725 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:02,741 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:02,743 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:02,748 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:02,726 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:02,741 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:02,750 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:02,743 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:02,749 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:02,726 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:02,748 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:02,750 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:02,726 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:02,760 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:02,763 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:02,760 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:02,745 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:02,748 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:02,763 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:02,725 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:02,750 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:02,765 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-04-02T15:17:02,767 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-04-02T15:17:02,770 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:02,770 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:02,767 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-04-02T15:17:02,765 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-04-02T15:17:02,773 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:02,773 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:02,773 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:04,191 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:04,191 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:04,467 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:04,467 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:04,615 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:04,621 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]96530
2022-04-02T15:17:04,621 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:04,621 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:04,621 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:04,621 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:04,621 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:04,621 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:04,625 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880224625
2022-04-02T15:17:04,625 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:17:04,625 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880224625
2022-04-02T15:17:04,630 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:04,637 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:04,637 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:04,731 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:04,731 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:04,731 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:04,731 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:04,731 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:04,731 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:04,769 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:04,769 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:04,769 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:04,769 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:05,057 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:05,061 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:05,061 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:05,061 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:05,063 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:05,064 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:05,064 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:05,064 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:05,064 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:05,064 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:05,064 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:05,064 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:05,064 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:05,064 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:05,064 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:05,064 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:05,065 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:05,066 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:05,066 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:05,066 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:05,066 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:05,066 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:05,066 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:05,066 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:05,066 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:05,067 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:05,067 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:05,067 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:05,070 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2022-04-02T15:17:05,070 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2022-04-02T15:17:05,066 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:05,843 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:05,843 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]96531
2022-04-02T15:17:05,843 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:05,844 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:05,844 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:05,844 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:05,844 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:05,844 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:05,848 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880225848
2022-04-02T15:17:05,848 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880225848
2022-04-02T15:17:05,865 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:17:05,865 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:06,078 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:06,079 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]96532
2022-04-02T15:17:06,080 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:06,080 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:06,080 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,080 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,080 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:06,080 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:06,082 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226082
2022-04-02T15:17:06,082 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:17:06,082 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226082
2022-04-02T15:17:06,083 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:06,114 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:06,115 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]96533
2022-04-02T15:17:06,115 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:06,115 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,115 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:06,115 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,115 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:06,115 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:06,118 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226117
2022-04-02T15:17:06,118 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226117
2022-04-02T15:17:06,118 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:17:06,119 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:06,119 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:06,120 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]96534
2022-04-02T15:17:06,120 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:06,120 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:06,120 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,120 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,120 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:06,120 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:06,123 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226123
2022-04-02T15:17:06,123 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226123
2022-04-02T15:17:06,123 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:17:06,124 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:06,147 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:06,149 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:06,151 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]96537
2022-04-02T15:17:06,151 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]96535
2022-04-02T15:17:06,152 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:06,152 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,152 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:06,152 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:06,152 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,152 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,152 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:06,152 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,152 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:06,152 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:06,152 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:06,152 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:06,157 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226157
2022-04-02T15:17:06,157 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226157
2022-04-02T15:17:06,157 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226157
2022-04-02T15:17:06,157 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226157
2022-04-02T15:17:06,160 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:17:06,160 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:17:06,162 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:06,162 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:06,180 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:06,183 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]96536
2022-04-02T15:17:06,183 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:06,183 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:06,183 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,183 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:06,183 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:06,183 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:06,186 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:17:06,186 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226186
2022-04-02T15:17:06,186 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880226186
2022-04-02T15:17:06,189 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:06,217 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:06,217 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:06,217 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:06,220 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:06,220 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:06,220 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:06,220 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:06,220 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:06,221 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:06,221 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:06,229 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:06,229 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:06,230 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:06,230 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:06,230 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:06,233 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:06,237 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,233 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:06,238 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:06,237 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,238 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:06,238 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:06,238 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:06,238 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:06,238 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:06,238 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:06,239 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,238 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:06,239 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,244 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:06,245 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:06,245 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:06,239 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,245 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:06,239 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,267 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,267 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,267 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,267 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,245 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:06,270 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:06,270 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:06,270 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:06,272 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:06,272 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:06,272 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:06,272 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:06,270 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:06,274 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:06,291 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:06,291 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:06,312 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-04-02T15:17:06,312 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-04-02T15:17:06,301 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:06,313 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:06,313 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:06,456 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:06,458 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:06,458 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,458 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,458 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:06,458 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:06,458 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:06,458 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:06,458 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,458 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:06,458 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,459 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:06,459 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:06,459 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:06,459 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,459 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,460 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,460 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,459 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:06,460 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:06,460 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:06,461 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:06,461 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:06,461 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:06,461 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:06,461 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:06,461 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-04-02T15:17:06,461 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:06,461 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:06,461 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-04-02T15:17:06,460 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:06,478 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:06,478 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:06,478 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:06,478 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:06,487 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,481 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,481 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,482 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:06,487 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,482 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:06,490 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,490 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,490 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:06,490 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:06,490 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:06,491 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:06,491 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:06,491 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:06,491 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:06,491 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:06,491 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:06,491 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,491 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:06,491 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,491 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:06,491 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:06,491 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:06,491 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:06,490 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,490 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,492 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:06,491 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,492 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,492 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,492 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:06,492 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,492 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,492 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:06,492 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:06,492 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:06,491 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,492 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:06,493 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,493 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:06,493 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,493 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,493 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,493 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:06,493 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:06,493 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:06,494 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:06,494 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:06,494 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:06,494 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:06,493 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:06,494 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:06,494 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:06,494 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:06,494 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:06,494 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:06,493 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:06,494 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:06,493 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:06,494 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:06,494 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:06,494 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:06,494 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:06,494 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:06,495 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2022-04-02T15:17:06,495 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2022-04-02T15:17:06,494 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:06,498 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-04-02T15:17:06,498 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-04-02T15:17:06,509 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:06,511 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,511 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,514 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,514 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,515 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,515 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,515 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,515 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,516 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:06,521 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,521 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,520 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,520 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,521 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:06,522 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:06,522 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,522 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:06,523 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:06,523 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:06,523 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:06,523 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:06,523 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:06,523 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:06,522 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,522 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,522 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,523 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,523 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,523 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,523 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,516 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:06,524 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:06,524 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:06,524 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:06,524 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:06,524 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:06,524 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:06,524 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:06,524 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:06,525 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:06,525 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:06,525 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:06,525 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:06,525 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:06,525 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:06,525 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:06,525 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:06,525 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:06,526 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2022-04-02T15:17:06,526 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-04-02T15:17:06,526 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-04-02T15:17:06,524 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:06,526 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2022-04-02T15:17:06,524 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:06,524 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:06,524 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:06,539 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:06,539 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:06,539 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,539 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:06,542 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:06,542 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:06,543 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,543 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:06,543 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:06,544 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:06,544 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:06,544 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:06,544 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:06,544 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:06,544 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,544 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:06,544 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:06,544 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:06,545 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:06,545 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,545 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:06,545 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,545 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:06,545 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:06,545 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:06,546 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:06,546 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:06,546 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2022-04-02T15:17:06,546 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2022-04-02T15:17:06,546 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:06,546 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:06,547 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:06,547 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:06,547 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:08,075 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:08,075 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:08,488 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:08,489 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]96570
2022-04-02T15:17:08,489 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:08,489 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:08,489 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:08,489 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:08,489 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:08,489 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:08,491 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880228491
2022-04-02T15:17:08,491 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880228491
2022-04-02T15:17:08,492 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:17:08,495 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:08,641 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:08,641 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:08,641 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:08,641 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:08,641 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:08,641 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:08,641 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:08,641 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:08,641 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:08,644 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:08,641 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:08,644 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:08,645 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:08,645 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:08,645 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:08,645 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:08,645 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:08,646 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:08,646 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:08,646 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:08,646 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:08,646 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:08,646 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:08,646 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:08,646 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:08,646 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:08,646 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:08,646 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:08,646 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:08,651 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:08,651 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:08,652 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:08,652 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:08,652 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:08,652 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 5 seconds.
2022-04-02T15:17:08,652 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 5 seconds.
2022-04-02T15:17:08,651 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:08,652 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:08,652 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:08,651 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:09,320 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:09,320 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:09,462 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:09,462 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:09,523 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:09,523 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:09,541 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:09,541 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:09,553 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:09,553 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:09,554 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:09,554 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:09,629 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:09,629 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:10,068 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:10,069 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]96571
2022-04-02T15:17:10,069 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:10,069 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:10,070 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,070 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,070 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:10,070 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:10,073 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230073
2022-04-02T15:17:10,073 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:17:10,073 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230073
2022-04-02T15:17:10,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:10,739 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:10,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]96572
2022-04-02T15:17:10,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:10,740 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:10,741 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,741 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,741 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:10,741 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:10,744 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230744
2022-04-02T15:17:10,744 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230744
2022-04-02T15:17:10,756 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:17:10,756 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:10,865 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:10,866 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:10,866 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:10,866 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:10,866 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:10,866 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:10,866 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:10,866 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:10,873 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:10,873 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:10,872 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:10,874 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:10,874 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:10,874 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:10,875 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:10,875 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:10,875 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:10,875 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:10,875 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:10,875 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:10,875 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:10,875 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:10,875 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:10,877 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:10,877 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:10,877 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:10,877 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:10,877 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:10,877 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:10,877 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:10,877 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:10,877 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:10,877 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:10,878 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:10,877 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:10,878 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:10,878 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:10,879 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:10,879 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:10,879 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:10,879 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:10,879 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:10,879 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:10,879 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:10,879 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:10,879 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:10,879 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-04-02T15:17:10,879 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-04-02T15:17:10,879 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:10,881 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:10,881 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:10,883 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:10,883 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:10,903 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:10,905 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]96575
2022-04-02T15:17:10,905 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:10,906 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:10,906 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,906 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,907 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:10,907 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:10,911 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:17:10,911 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:10,913 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]96576
2022-04-02T15:17:10,913 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:10,913 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:10,913 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:10,913 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]96577
2022-04-02T15:17:10,913 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,913 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230913
2022-04-02T15:17:10,913 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,914 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:10,913 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230913
2022-04-02T15:17:10,914 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:10,914 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:10,914 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,914 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:10,914 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,914 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:10,914 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:10,920 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230920
2022-04-02T15:17:10,920 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230920
2022-04-02T15:17:10,920 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:17:10,920 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230920
2022-04-02T15:17:10,920 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230920
2022-04-02T15:17:10,919 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:10,920 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:10,920 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:17:10,922 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:10,922 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:10,922 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:10,922 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]96573
2022-04-02T15:17:10,922 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]96574
2022-04-02T15:17:10,922 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:10,922 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:10,922 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:10,922 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:10,923 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,923 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,923 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:10,923 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:10,923 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,923 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:10,923 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:10,923 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:10,924 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230924
2022-04-02T15:17:10,924 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230924
2022-04-02T15:17:10,924 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:17:10,924 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:17:10,924 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230924
2022-04-02T15:17:10,924 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880230924
2022-04-02T15:17:10,925 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:10,925 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:11,027 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:11,028 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:11,029 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:11,030 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,032 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:11,032 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:11,032 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,032 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,032 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:11,032 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:11,037 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,037 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,039 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,039 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,039 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,039 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,041 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,041 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,041 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,041 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,042 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:11,042 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:11,043 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:11,043 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:11,043 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-04-02T15:17:11,043 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-04-02T15:17:11,043 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:11,043 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:11,046 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:11,046 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:11,209 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,209 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:11,209 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,210 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,210 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:11,210 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,210 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:11,210 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,210 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:11,210 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:11,210 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:11,210 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:11,210 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,210 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,211 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:11,211 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:11,211 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:11,211 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:11,212 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:11,212 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:11,212 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:11,212 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:11,212 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:11,212 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:11,212 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,212 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:11,212 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:11,212 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:11,213 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:11,213 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:11,213 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:11,210 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,214 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:11,210 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,215 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:11,215 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,215 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,215 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:11,216 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,216 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,216 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:11,216 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:11,216 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:11,216 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:11,216 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:11,216 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,217 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,217 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:11,217 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:11,217 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,217 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,217 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:11,217 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:11,217 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:11,217 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:11,217 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:11,217 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:11,218 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-04-02T15:17:11,218 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-04-02T15:17:11,217 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:11,220 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:11,220 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:11,217 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:11,229 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:11,235 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:11,239 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,239 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,229 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:11,240 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,240 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,240 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,240 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:11,240 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,240 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,240 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:11,241 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,241 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:11,241 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:11,241 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:11,241 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:11,241 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:11,241 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,241 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:11,241 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,241 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:11,241 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,241 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:11,240 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,241 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:11,241 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,242 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:11,242 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,242 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,241 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,240 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,242 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:11,243 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,242 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:11,243 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:11,243 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:11,241 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,243 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:11,243 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:11,243 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:11,243 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:11,243 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:11,243 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:11,243 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:11,243 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,243 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,244 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:11,243 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:11,244 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:11,244 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:11,244 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:11,244 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:11,243 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,244 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:11,244 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:11,244 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:11,245 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:11,244 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:11,245 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:11,244 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:11,245 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:11,245 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:11,245 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:11,245 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:11,245 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,245 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:11,245 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:11,245 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:11,244 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,244 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,245 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:11,245 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,245 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,245 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:11,243 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,245 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,245 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,245 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:11,246 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:11,245 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:11,246 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:11,246 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:11,246 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:11,246 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:11,245 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:11,249 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:11,255 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,255 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,255 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:11,245 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:11,258 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:11,258 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:11,253 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:11,259 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:11,259 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:11,259 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:11,259 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:11,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:11,259 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:11,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:11,260 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:11,255 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,255 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,260 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:11,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:11,260 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:11,256 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,256 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,260 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:11,260 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:11,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:11,260 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:11,261 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:11,261 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,260 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:11,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:11,261 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,262 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:11,263 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:11,263 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:11,263 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:11,263 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:11,262 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:11,263 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:11,262 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:11,263 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:11,263 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:11,263 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:11,255 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,263 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:11,264 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:11,255 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:11,265 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,265 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,265 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,264 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,264 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,265 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,264 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:11,266 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:11,265 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,275 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:11,275 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:11,275 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:11,275 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:11,274 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:11,274 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:11,276 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:11,276 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:11,276 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,276 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:11,276 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:11,276 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:11,276 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:11,276 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:11,276 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:11,276 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,276 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:11,276 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:11,276 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 5 seconds.
2022-04-02T15:17:11,276 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 5 seconds.
2022-04-02T15:17:11,253 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:11,264 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,277 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-04-02T15:17:11,291 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:11,291 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:11,265 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:11,275 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:11,291 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:11,294 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2022-04-02T15:17:11,274 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:11,275 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:11,298 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,276 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:11,298 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:11,294 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2022-04-02T15:17:11,291 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:11,309 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,277 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-04-02T15:17:11,275 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:11,275 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:11,274 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:11,309 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:11,305 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:11,311 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:11,311 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,311 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:11,311 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:11,311 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:11,312 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:11,312 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:11,312 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:11,312 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:11,312 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2022-04-02T15:17:11,312 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2022-04-02T15:17:11,313 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:11,313 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:11,312 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:11,312 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:13,660 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:13,660 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:14,071 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:14,072 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]96603
2022-04-02T15:17:14,073 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:14,073 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:14,073 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:14,073 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:14,073 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:14,073 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:14,075 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:17:14,076 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880234076
2022-04-02T15:17:14,076 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880234076
2022-04-02T15:17:14,085 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:14,228 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:14,228 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:14,228 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:14,228 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:14,228 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:14,228 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:14,228 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:14,228 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:14,228 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:14,228 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:14,229 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:14,229 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:14,229 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:14,230 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:14,229 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:14,229 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:14,233 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:14,233 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:14,234 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:14,234 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:14,234 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:14,234 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:14,234 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:14,234 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:14,234 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:14,234 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:14,234 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 8 seconds.
2022-04-02T15:17:14,234 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 8 seconds.
2022-04-02T15:17:14,234 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:14,234 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:15,889 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:15,889 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:16,047 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:16,047 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:16,224 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:16,224 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:16,278 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:16,278 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:16,278 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:16,278 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:16,278 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:16,278 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:16,316 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:16,316 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:16,556 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:16,557 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]96608
2022-04-02T15:17:16,557 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:16,557 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:16,557 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:16,557 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:16,558 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:16,558 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:16,560 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880236560
2022-04-02T15:17:16,560 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880236560
2022-04-02T15:17:16,561 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:17:16,563 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:17,345 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:17,346 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,346 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,346 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,346 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:17,346 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:17,346 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:17,346 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:17,346 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,346 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,346 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,346 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,346 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,346 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,346 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,347 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:17,346 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,350 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,350 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:17,350 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:17,350 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,350 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:17,350 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,350 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:17,350 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:17,350 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-04-02T15:17:17,367 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:17,369 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]96609
2022-04-02T15:17:17,369 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:17,369 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:17,369 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,369 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,369 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:17,369 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:17,372 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237372
2022-04-02T15:17:17,372 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:17:17,372 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237372
2022-04-02T15:17:17,373 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:17,530 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:17,531 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]96610
2022-04-02T15:17:17,531 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:17,531 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:17,531 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,531 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,531 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:17,531 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:17,532 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237532
2022-04-02T15:17:17,532 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237532
2022-04-02T15:17:17,532 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:17:17,533 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:17,557 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:17,558 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]96611
2022-04-02T15:17:17,558 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:17,558 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,558 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:17,558 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,559 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:17,559 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:17,560 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:17:17,560 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237560
2022-04-02T15:17:17,560 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237560
2022-04-02T15:17:17,562 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:17,564 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:17,564 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]96613
2022-04-02T15:17:17,564 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,564 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:17,564 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,565 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:17,565 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:17,565 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:17,566 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237566
2022-04-02T15:17:17,566 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237566
2022-04-02T15:17:17,566 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:17:17,567 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:17,582 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:17,584 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]96614
2022-04-02T15:17:17,584 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:17,584 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,584 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:17,584 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,585 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:17,585 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:17,585 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:17:17,586 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237586
2022-04-02T15:17:17,586 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237586
2022-04-02T15:17:17,586 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:17,588 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:17,589 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]96612
2022-04-02T15:17:17,589 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:17,589 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:17,589 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,589 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:17,589 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:17,589 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:17,590 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:17:17,590 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237590
2022-04-02T15:17:17,590 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880237590
2022-04-02T15:17:17,592 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:17,644 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:17,645 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,645 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:17,645 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:17,645 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:17,645 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,645 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,645 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:17,645 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,645 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,645 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,645 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,645 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,645 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,646 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,646 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,646 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:17,646 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:17,646 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:17,646 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:17,646 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:17,646 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,646 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,646 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,646 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:17,647 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:17,647 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,647 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:17,647 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,646 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,647 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,647 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:17,647 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:17,647 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:17,647 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:17,648 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:17,648 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:17,648 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:17,648 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:17,648 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:17,648 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:17,648 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:17,648 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:17,648 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,649 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,650 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:17,650 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:17,650 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:17,650 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:17,650 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-04-02T15:17:17,650 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-04-02T15:17:17,651 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:17,651 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:17,652 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,653 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:17,653 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:17,806 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:17,806 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,806 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:17,806 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:17,806 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,807 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,807 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,807 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,807 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,807 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:17,808 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:17,808 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:17,808 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,808 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,808 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,808 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,808 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:17,809 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,809 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,809 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:17,809 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:17,809 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:17,809 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:17,809 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:17,809 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,810 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,809 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:17,810 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:17,810 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:17,810 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-04-02T15:17:17,810 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-04-02T15:17:17,810 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:17,810 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:17,859 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:17,859 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,859 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:17,859 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:17,859 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:17,859 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:17,859 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,859 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,859 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,859 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,859 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,859 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,861 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,861 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,862 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:17,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:17,861 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:17,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:17,861 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:17,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:17,863 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,863 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:17,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,863 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,863 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:17,863 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:17,864 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:17,864 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:17,865 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:17,865 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:17,865 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:17,865 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,865 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,865 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,865 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:17,865 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:17,866 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,864 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:17,866 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:17,866 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 8 seconds.
2022-04-02T15:17:17,866 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 8 seconds.
2022-04-02T15:17:17,866 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:17,866 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:17,868 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:17,868 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,868 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,869 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,869 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:17,869 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,869 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:17,869 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:17,869 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:17,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:17,869 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:17,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:17,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:17,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:17,870 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:17,873 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,873 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:17,873 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,873 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:17,873 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:17,873 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:17,874 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:17,874 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:17,874 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:17,874 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:17,874 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,874 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,874 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,875 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,876 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:17,876 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:17,876 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,876 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,877 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:17,878 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:17,879 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,879 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,879 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:17,879 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,879 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:17,879 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:17,879 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:17,879 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:17,879 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:17,880 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,880 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:17,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:17,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:17,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:17,880 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:17,880 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:17,880 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:17,880 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:17,881 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:17,881 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:17,881 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,881 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:17,881 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:17,881 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,881 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,880 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:17,881 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:17,881 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,881 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:17,881 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,881 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:17,881 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:17,882 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:17,882 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,882 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,881 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,881 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,883 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,883 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:17,883 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:17,883 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,883 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,883 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:17,883 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,883 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,883 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:17,883 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:17,883 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,883 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,883 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:17,884 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:17,884 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:17,884 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:17,884 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:17,884 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:17,884 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:17,884 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:17,884 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:17,884 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2022-04-02T15:17:17,884 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2022-04-02T15:17:17,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:17,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:17,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:17,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:17,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:17,893 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:17,893 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:17,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:17,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:17,893 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,893 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:17,893 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:17,893 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,894 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:17,893 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:17,907 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:17,908 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,907 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:17,908 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:17,908 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,908 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:17,908 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:17,908 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:17,908 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:17,908 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:17,908 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:17,909 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2022-04-02T15:17:17,909 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2022-04-02T15:17:17,909 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:17,909 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:22,243 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:22,243 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:22,669 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:22,681 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]96625
2022-04-02T15:17:22,681 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:22,681 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:22,681 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:22,681 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:22,682 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:22,682 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:22,683 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:17:22,683 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880242683
2022-04-02T15:17:22,683 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880242683
2022-04-02T15:17:22,685 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:22,826 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:22,826 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:22,826 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:22,827 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:22,827 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:22,827 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:22,828 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:22,828 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:22,828 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:22,828 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:22,828 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:22,828 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:22,828 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:22,828 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:22,828 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:22,828 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:22,828 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:22,828 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:22,829 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:22,829 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:22,829 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:22,829 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:22,829 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:22,829 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:22,829 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:22,829 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:22,829 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:22,829 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:22,829 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 13 seconds.
2022-04-02T15:17:22,829 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 13 seconds.
2022-04-02T15:17:22,829 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:22,829 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:23,048 [INFO ] W-9006-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64355 "POST /ping HTTP/1.1" 200 38
2022-04-02T15:17:23,049 [INFO ] W-9006-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:24,827 [INFO ] W-9006-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64356 "POST /ping HTTP/1.1" 200 2
2022-04-02T15:17:24,828 [INFO ] W-9006-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:25,358 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:25,358 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:25,484 [INFO ] W-9004-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64357 "POST /ping HTTP/1.1" 200 1
2022-04-02T15:17:25,487 [INFO ] W-9004-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:25,658 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:25,658 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:25,787 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:25,793 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]96663
2022-04-02T15:17:25,794 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:25,794 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:25,794 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:25,794 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:25,796 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:25,796 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:25,798 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880245798
2022-04-02T15:17:25,798 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:17:25,798 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880245798
2022-04-02T15:17:25,799 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:25,815 [INFO ] W-9003-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64358 "POST /ping HTTP/1.1" 200 1
2022-04-02T15:17:25,817 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:25,817 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:25,817 [INFO ] W-9003-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:25,871 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:25,871 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:25,884 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:25,884 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:25,884 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:25,884 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:26,002 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:26,002 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:26,077 [INFO ] W-9006-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64360 "POST /ping HTTP/1.1" 200 0
2022-04-02T15:17:26,078 [INFO ] W-9006-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:26,221 [INFO ] W-9006-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64361 "POST /ping HTTP/1.1" 200 2
2022-04-02T15:17:26,221 [INFO ] W-9006-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:26,270 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:26,270 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:26,271 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:26,271 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:26,271 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:26,271 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:26,271 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:26,271 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:26,271 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:26,271 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:26,272 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:26,274 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:26,274 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:26,274 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:26,274 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:26,275 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:26,275 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:26,275 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:26,275 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:26,275 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:26,276 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:26,276 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:26,276 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:26,276 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:26,275 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:26,276 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:26,275 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:26,303 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:26,303 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:26,303 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:26,303 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:26,304 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:26,304 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:26,304 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:26,304 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:26,304 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:26,305 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:26,305 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:26,306 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:26,306 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:26,306 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:26,306 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:26,306 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-04-02T15:17:26,306 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-04-02T15:17:26,305 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:26,305 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:26,357 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64362 "POST /ping HTTP/1.1" 200 1
2022-04-02T15:17:26,358 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:26,482 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64363 "POST /ping HTTP/1.1" 200 1
2022-04-02T15:17:26,482 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:26,639 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64364 "POST /ping HTTP/1.1" 200 0
2022-04-02T15:17:26,639 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:26,827 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64365 "POST /ping HTTP/1.1" 200 0
2022-04-02T15:17:26,828 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:26,934 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64366 "POST /ping HTTP/1.1" 200 2
2022-04-02T15:17:26,937 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:27,048 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64367 "POST /ping HTTP/1.1" 200 1
2022-04-02T15:17:27,055 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:27,150 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:27,162 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]96682
2022-04-02T15:17:27,163 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:27,163 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:27,163 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,163 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,164 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:27,164 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:27,166 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247166
2022-04-02T15:17:27,166 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247166
2022-04-02T15:17:27,166 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:17:27,167 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:27,211 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64368 "POST /ping HTTP/1.1" 200 2
2022-04-02T15:17:27,211 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:27,353 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:27,356 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]96684
2022-04-02T15:17:27,356 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:27,356 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:27,357 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,357 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,361 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:27,361 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:27,367 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:17:27,376 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247376
2022-04-02T15:17:27,376 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247376
2022-04-02T15:17:27,378 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:27,404 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64370 "POST /ping HTTP/1.1" 200 1
2022-04-02T15:17:27,405 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:27,449 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:27,451 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]96703
2022-04-02T15:17:27,452 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:27,452 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:27,453 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,453 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,453 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:27,453 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:27,456 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247456
2022-04-02T15:17:27,456 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247456
2022-04-02T15:17:27,463 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:17:27,468 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:27,475 [INFO ] W-9000-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64372 "POST /ping HTTP/1.1" 200 2
2022-04-02T15:17:27,476 [INFO ] W-9000-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:27,511 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:27,516 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]96702
2022-04-02T15:17:27,517 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:27,517 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,517 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:27,517 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,517 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:27,517 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:27,518 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247518
2022-04-02T15:17:27,518 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247518
2022-04-02T15:17:27,518 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:17:27,519 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:27,530 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:27,548 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]96704
2022-04-02T15:17:27,553 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:27,553 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:27,554 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,554 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,554 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:27,554 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:27,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:17:27,560 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247560
2022-04-02T15:17:27,560 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247560
2022-04-02T15:17:27,564 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:27,574 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,574 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,574 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:27,575 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,575 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:27,575 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:27,575 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:27,575 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:27,575 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:27,579 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,579 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,579 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:27,579 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,579 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,579 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:27,583 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:27,583 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:27,583 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:27,583 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:27,583 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:27,583 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:27,583 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,579 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,583 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:27,579 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,585 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,585 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,585 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,598 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:27,598 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:27,598 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:27,598 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:27,585 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,598 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:27,599 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:27,599 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:27,599 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,599 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:27,599 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,600 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:27,601 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:27,601 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:27,601 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:27,601 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:27,601 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:27,602 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:27,601 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,602 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,602 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:27,602 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:27,602 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,603 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,603 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:27,602 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:27,603 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:27,602 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:27,603 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:27,603 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:27,603 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-04-02T15:17:27,603 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-04-02T15:17:27,602 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:27,604 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:27,604 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:27,612 [INFO ] W-9002-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64375 "POST /ping HTTP/1.1" 200 2
2022-04-02T15:17:27,612 [INFO ] W-9002-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:27,643 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:27,647 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]96705
2022-04-02T15:17:27,648 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:27,648 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:27,649 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,649 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:27,649 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:27,649 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:27,655 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:17:27,657 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247657
2022-04-02T15:17:27,657 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880247657
2022-04-02T15:17:27,658 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:27,713 [INFO ] W-9002-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64378 "POST /ping HTTP/1.1" 200 1
2022-04-02T15:17:27,715 [INFO ] W-9002-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:27,754 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,754 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,754 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:27,755 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,755 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,755 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,755 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:27,756 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:27,756 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:27,756 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:27,756 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:27,756 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:27,757 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,757 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,757 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:27,757 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:27,757 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:27,757 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:27,757 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:27,757 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:27,757 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:27,757 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,758 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:27,758 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,758 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,758 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:27,758 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:27,756 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,758 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:27,756 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,762 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:27,762 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:27,762 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:27,762 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:27,762 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:27,762 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:27,762 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:27,762 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:27,762 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:27,763 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:27,763 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:27,763 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,763 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,763 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:27,763 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:27,763 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,763 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,763 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:27,763 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:27,764 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,764 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,765 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,765 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,765 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:27,765 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:27,766 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:27,766 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:27,766 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:27,766 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:27,766 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-04-02T15:17:27,765 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:27,766 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-04-02T15:17:27,765 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:27,828 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:27,828 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,828 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:27,828 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:27,828 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:27,828 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:27,828 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:27,828 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:27,829 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,829 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,829 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:27,830 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:27,830 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,830 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,830 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,831 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,831 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,830 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:27,831 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,831 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,831 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:27,832 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,832 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,832 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:27,832 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:27,832 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:27,832 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:27,832 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:27,832 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:27,832 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2022-04-02T15:17:27,832 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2022-04-02T15:17:27,832 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:27,832 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:27,832 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:27,832 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:27,844 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:27,845 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,845 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:27,845 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:27,845 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:27,845 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:27,845 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:27,845 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:27,845 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,845 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,845 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,845 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:27,845 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,854 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:27,854 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:27,854 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:27,854 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,854 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,855 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:27,855 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:27,855 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:27,855 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,855 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:27,855 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,855 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,855 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,855 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,855 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:27,856 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,856 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:27,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:27,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:27,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:27,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:27,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:27,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:27,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:27,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:27,856 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:27,857 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:27,857 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:27,858 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:27,858 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:27,858 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:27,858 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:27,858 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 13 seconds.
2022-04-02T15:17:27,858 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 13 seconds.
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:27,857 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:27,891 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,891 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,890 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:27,894 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,894 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,894 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,895 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:27,895 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:27,895 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:27,895 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:27,895 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:27,895 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:27,895 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,895 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,895 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:27,895 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,895 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:27,895 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,896 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:27,896 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:27,896 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:27,896 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,896 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,896 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:27,896 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,896 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,896 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:27,896 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,896 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:27,896 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:27,896 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:27,897 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,897 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:27,898 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,897 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:27,899 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-04-02T15:17:27,899 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:27,899 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-04-02T15:17:27,901 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:27,901 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:27,896 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:27,896 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:27,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:27,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:27,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:27,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:27,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:27,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:27,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:27,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:27,943 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:27,943 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,943 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:27,944 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:27,944 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:27,944 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:27,944 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,945 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:27,944 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:27,945 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:27,945 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,945 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:27,945 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:27,945 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:27,945 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,945 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:27,945 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:27,945 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:27,945 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:27,945 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:27,945 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:27,946 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:27,946 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:27,946 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2022-04-02T15:17:27,946 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2022-04-02T15:17:27,945 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:27,945 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:27,946 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:27,946 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:27,945 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:27,946 [INFO ] W-9003-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64379 "POST /ping HTTP/1.1" 200 2
2022-04-02T15:17:27,947 [INFO ] W-9003-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:30,137 [INFO ] W-9003-my_tc_1.0 ACCESS_LOG - /127.0.0.1:64380 "POST /ping HTTP/1.1" 200 2
2022-04-02T15:17:30,138 [INFO ] W-9003-my_tc_1.0 TS_METRICS - Requests2XX.Count:1|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:null
2022-04-02T15:17:35,837 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:35,837 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:17:36,242 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:36,244 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]96913
2022-04-02T15:17:36,245 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:36,245 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:36,245 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:36,245 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:36,245 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:36,245 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:17:36,248 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:17:36,249 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880256249
2022-04-02T15:17:36,249 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880256249
2022-04-02T15:17:36,255 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:36,400 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:36,400 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:36,401 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:36,401 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:36,401 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:36,401 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:36,401 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:36,401 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:36,401 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:36,410 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:36,410 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:36,410 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:36,410 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:36,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:36,411 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:36,411 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:36,411 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:36,411 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:36,411 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:36,411 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:17:36,411 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:36,411 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:17:36,411 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 21 seconds.
2022-04-02T15:17:36,411 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 21 seconds.
2022-04-02T15:17:36,411 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:36,412 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:36,412 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:17:36,412 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:36,412 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:17:39,314 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:39,314 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:17:39,757 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:39,758 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]96914
2022-04-02T15:17:39,758 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:39,758 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:39,758 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:39,758 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:39,758 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:39,758 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:17:39,760 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:17:39,761 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880259761
2022-04-02T15:17:39,761 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880259761
2022-04-02T15:17:39,762 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:39,910 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:39,910 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:39,910 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:39,910 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:39,911 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:39,911 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:39,911 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:39,911 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:39,911 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:39,912 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:39,912 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:39,914 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:39,915 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:39,916 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:39,916 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:39,916 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:39,916 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:39,917 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:39,911 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:39,911 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:39,918 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:39,918 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:39,918 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:39,918 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:39,918 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:39,918 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:17:39,918 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:39,918 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:17:39,918 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-04-02T15:17:39,918 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-04-02T15:17:39,919 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:39,919 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:17:39,919 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:39,919 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:17:40,607 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:40,607 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:17:40,771 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:40,771 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:17:40,835 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:40,835 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:17:40,863 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:40,863 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:17:40,901 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:40,901 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:17:40,950 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:40,950 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:17:41,446 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:41,451 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]96917
2022-04-02T15:17:41,451 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:41,453 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:41,451 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:41,453 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:41,453 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:41,453 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:17:41,457 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:17:41,457 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880261457
2022-04-02T15:17:41,457 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880261457
2022-04-02T15:17:41,458 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:41,958 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:41,958 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:41,958 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:41,958 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:41,958 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:41,958 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:41,958 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:41,959 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:41,959 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:41,959 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:41,959 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:41,959 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:41,959 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:41,959 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:41,960 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:41,960 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:41,960 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:41,960 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:41,960 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:41,960 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:41,960 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:41,960 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:41,960 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:41,959 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:41,959 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:41,961 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:41,961 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:41,961 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:41,961 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:41,961 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:41,961 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:17:41,962 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:41,962 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:41,962 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:41,962 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:17:41,962 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2022-04-02T15:17:41,962 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:41,961 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:17:41,991 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:41,992 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]96920
2022-04-02T15:17:41,992 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:41,992 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:41,992 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:41,992 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:41,994 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:41,994 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:17:41,995 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880261995
2022-04-02T15:17:41,995 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880261995
2022-04-02T15:17:41,995 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:17:41,996 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:42,009 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:42,009 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]96921
2022-04-02T15:17:42,009 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:42,009 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:42,010 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:42,010 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:42,010 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:42,010 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:17:42,012 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880262012
2022-04-02T15:17:42,012 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880262012
2022-04-02T15:17:42,012 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:17:42,014 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:42,031 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:42,032 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]96922
2022-04-02T15:17:42,032 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:42,032 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:42,032 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:42,032 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:42,032 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:42,032 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:17:42,034 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:17:42,035 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880262035
2022-04-02T15:17:42,035 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880262035
2022-04-02T15:17:42,037 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:42,047 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:42,047 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]96924
2022-04-02T15:17:42,047 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:42,047 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:42,047 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:42,047 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:42,048 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:42,048 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:17:42,048 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:17:42,049 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880262049
2022-04-02T15:17:42,049 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880262049
2022-04-02T15:17:42,050 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:42,087 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:42,087 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]96926
2022-04-02T15:17:42,087 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:17:42,087 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:17:42,087 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:42,087 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:17:42,088 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:42,088 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:17:42,088 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880262088
2022-04-02T15:17:42,088 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648880262088
2022-04-02T15:17:42,089 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:17:42,089 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:17:42,313 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:42,313 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:42,315 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:42,316 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:42,316 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:42,316 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:42,316 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:42,316 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:42,316 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:42,316 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:42,316 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:42,316 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:42,313 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:42,317 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:42,317 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:42,318 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:42,317 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:42,318 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:42,318 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:42,318 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:42,318 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:42,318 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:42,318 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:42,318 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:42,318 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:42,318 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:42,319 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:42,319 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:42,319 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:42,319 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:42,319 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:42,319 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:42,318 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:42,319 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:42,319 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:42,319 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:42,319 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:42,320 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:42,320 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:17:42,321 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:42,321 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:17:42,321 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2022-04-02T15:17:42,321 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2022-04-02T15:17:42,321 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:42,321 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:17:42,321 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:42,321 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:17:42,331 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:42,331 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:42,331 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:42,331 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:42,331 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:42,331 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:42,331 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:42,331 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:42,332 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:42,332 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:42,332 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:42,332 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:42,332 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:42,332 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:42,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:42,336 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:42,336 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:42,336 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:42,336 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:42,336 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:42,336 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:42,332 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:42,336 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:42,336 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:42,337 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:42,336 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:17:42,354 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:17:42,354 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:17:42,354 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:42,354 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:42,337 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:42,355 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:42,354 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:42,355 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:42,355 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:42,355 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:17:42,355 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:42,355 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:42,355 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:42,355 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:17:42,355 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:17:42,355 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:42,355 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:17:42,356 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:42,356 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:17:42,356 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2022-04-02T15:17:42,356 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2022-04-02T15:17:42,357 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:42,357 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:42,357 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:42,357 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:42,357 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:42,357 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:42,357 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:42,355 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:42,357 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:42,357 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:42,355 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:17:42,357 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:42,357 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:17:42,357 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:42,358 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:42,358 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:42,358 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:42,358 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:42,358 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:42,358 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:42,358 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:42,359 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:42,359 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:42,359 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:42,359 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:42,359 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:42,359 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:17:42,359 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:42,359 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 21 seconds.
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 21 seconds.
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:42,359 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:17:42,367 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:42,368 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:42,368 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:42,368 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:42,368 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:42,368 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:42,369 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:42,369 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:42,369 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:42,370 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:42,370 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:42,370 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:42,370 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:42,370 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:17:42,371 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:42,371 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:17:42,371 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:17:42,371 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:42,371 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:17:42,402 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:42,402 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:17:42,403 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:42,403 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:17:42,404 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:17:42,404 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:42,404 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:17:42,404 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:17:42,404 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:17:42,404 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:17:42,404 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:17:42,403 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:42,404 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:17:42,404 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:17:42,406 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:17:42,406 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:17:42,406 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:17:42,406 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:17:42,406 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:17:42,406 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/f2b45cd7f87d4630abf20476525b1a3a/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:17:42,406 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:17:42,406 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:17:42,403 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:17:42,407 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:42,407 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:17:42,406 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:42,407 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:42,407 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:17:42,407 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:42,407 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:17:42,407 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:42,407 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2022-04-02T15:17:42,407 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:17:45,446 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-02T15:17:45,446 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-02T15:32:52,316 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-02T15:32:52,316 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2022-04-02T15:32:52,922 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-02T15:32:52,922 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.5.3
TS Home: /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages
Current directory: /Users/seok/Discussion-Korea/serve
Temp directory: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 2048 M
Python executable: /Users/seok/.pyenv/versions/3.9.9/bin/python
Config file: N/A
Inference address: http://127.0.0.1:8080
Management address: http://127.0.0.1:8081
Metrics address: http://127.0.0.1:8082
Model Store: /Users/seok/Discussion-Korea/serve
Initial Models: my_tc=klue-roberta-base.mar
Log dir: /Users/seok/Discussion-Korea/serve/logs
Metrics dir: /Users/seok/Discussion-Korea/serve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Metrics report format: prometheus
Enable metrics API: true
Workflow Store: /Users/seok/Discussion-Korea/serve
Model config: N/A
2022-04-02T15:32:52,933 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-02T15:32:52,933 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2022-04-02T15:32:53,015 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-02T15:32:53,015 [INFO ] main org.pytorch.serve.ModelServer - Loading initial models: klue-roberta-base.mar
2022-04-02T15:33:03,923 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-02T15:33:03,923 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model my_tc
2022-04-02T15:33:03,924 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-02T15:33:03,924 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model my_tc
2022-04-02T15:33:03,925 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-02T15:33:03,925 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model my_tc loaded.
2022-04-02T15:33:03,925 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-02T15:33:03,925 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: my_tc, count: 8
2022-04-02T15:33:03,980 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:03,980 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:03,980 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:03,980 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:03,980 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:03,980 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:03,980 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:03,980 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:03,980 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:03,980 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:03,980 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:03,980 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:03,980 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:03,980 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:03,980 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:03,980 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:03,998 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-02T15:33:03,998 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: KQueueServerSocketChannel.
2022-04-02T15:33:04,952 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-02T15:33:04,952 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://127.0.0.1:8080
2022-04-02T15:33:04,952 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-02T15:33:04,952 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: KQueueServerSocketChannel.
2022-04-02T15:33:04,956 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-02T15:33:04,956 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://127.0.0.1:8081
2022-04-02T15:33:04,957 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-02T15:33:04,957 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: KQueueServerSocketChannel.
2022-04-02T15:33:04,959 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-02T15:33:04,959 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://127.0.0.1:8082
2022-04-02T15:33:05,070 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:05,076 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]97704
2022-04-02T15:33:05,077 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:05,077 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:05,078 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,078 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,098 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:05,098 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:05,150 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:33:05,168 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185165
2022-04-02T15:33:05,168 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185165
2022-04-02T15:33:05,265 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:05,480 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:05,495 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]97705
2022-04-02T15:33:05,496 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,495 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:05,496 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,502 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:05,502 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:05,502 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:05,511 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:33:05,512 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185512
2022-04-02T15:33:05,512 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185512
2022-04-02T15:33:05,511 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:05,511 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:05,514 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]97709
2022-04-02T15:33:05,514 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]97708
2022-04-02T15:33:05,514 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,514 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:05,514 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,514 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,515 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:05,514 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:05,514 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,515 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:05,515 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:05,515 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:05,515 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:05,515 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:05,553 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185553
2022-04-02T15:33:05,552 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185551
2022-04-02T15:33:05,553 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:33:05,546 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:33:05,552 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:05,553 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185553
2022-04-02T15:33:05,552 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185551
2022-04-02T15:33:05,530 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:05,546 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:05,663 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:05,663 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]97707
2022-04-02T15:33:05,664 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]97703
2022-04-02T15:33:05,666 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:05,546 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:05,552 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:05,667 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]97702
2022-04-02T15:33:05,668 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:05,668 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:05,668 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,668 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,668 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,667 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]97706
2022-04-02T15:33:05,667 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:05,668 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:05,668 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,669 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:05,668 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,668 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,669 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:05,669 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,669 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:05,669 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change null -> WORKER_STARTED
2022-04-02T15:33:05,670 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:05,670 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:05,670 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:05,670 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:05,670 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:05,670 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:05,670 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:05,670 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:05,670 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:05,720 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185720
2022-04-02T15:33:05,721 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185721
2022-04-02T15:33:05,721 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185721
2022-04-02T15:33:05,717 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:33:05,724 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185724
2022-04-02T15:33:05,717 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:33:05,720 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185720
2022-04-02T15:33:05,759 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185758
2022-04-02T15:33:05,724 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185724
2022-04-02T15:33:05,753 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:05,759 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881185758
2022-04-02T15:33:05,717 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:33:05,718 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:05,760 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:33:05,986 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:05,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:05,994 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:05,997 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:05,998 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:05,998 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:05,983 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:05,995 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:05,995 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:05,995 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,001 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:05,994 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:05,988 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:05,958 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:05,902 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:05,963 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:05,983 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:05,988 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:05,753 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:05,963 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:05,902 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:06,069 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,037 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:06,062 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,079 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,065 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,035 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:05,958 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:06,079 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,072 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:06,069 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,040 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:06,062 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,097 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:06,090 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:06,098 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:06,065 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,039 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:06,097 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:06,099 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:06,099 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:06,099 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:06,154 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:06,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,124 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:06,123 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,118 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:06,142 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:06,163 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,162 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,163 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,149 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:06,162 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:06,142 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:06,149 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:06,164 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,163 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,165 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,255 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,259 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,252 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:06,257 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,252 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:06,262 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,262 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,262 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:06,263 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,263 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:06,263 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,263 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:06,263 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,263 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:06,263 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,264 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,264 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,252 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:06,258 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:06,264 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,253 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:06,253 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:06,258 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:06,252 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:06,304 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:06,253 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:06,253 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:06,299 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:06,300 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:06,342 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,337 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,342 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,342 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,300 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:06,342 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,340 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,342 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:06,342 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,340 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,337 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:06,343 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:06,343 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:06,300 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:06,343 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:06,300 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:06,343 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:06,339 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:06,343 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:06,340 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,343 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:06,347 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,345 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:06,348 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:06,344 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:06,404 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:06,404 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:06,405 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:06,405 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:06,405 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,405 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:06,398 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:06,398 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:06,402 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:06,403 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:06,405 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:06,405 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,405 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,405 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,405 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,405 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,405 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:06,405 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:06,417 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:06,403 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:06,398 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:06,402 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:06,416 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:06,398 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:06,416 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:06,416 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,417 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:06,416 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:06,417 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:06,416 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,453 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:06,457 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:06,453 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,469 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:06,452 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:06,459 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,457 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:06,458 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:06,494 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:06,494 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,494 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:06,494 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:06,494 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,494 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:06,457 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,495 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:06,496 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,496 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,496 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,496 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,503 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,496 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,495 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,501 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,503 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,503 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:06,501 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:06,503 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:06,503 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,503 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:06,497 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,503 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:06,503 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,503 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:06,503 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,503 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,504 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,504 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,504 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:06,504 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:06,504 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,504 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:06,505 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:06,505 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:06,506 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:06,506 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:06,504 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:06,506 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:06,505 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:06,506 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,507 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:06,507 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:06,507 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:06,508 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:06,506 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:06,507 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:06,505 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:06,507 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:06,519 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,532 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:06,538 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:06,506 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:06,534 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:06,533 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:06,532 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,544 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:06,545 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,545 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,544 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:06,552 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:06,553 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:06,555 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:06,548 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:06,551 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:06,555 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:06,555 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:06,555 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:06,555 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,556 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:06,556 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:06,556 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,556 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:06,556 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:06,550 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:06,556 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:06,556 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:06,556 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,556 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:06,556 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,556 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,556 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:06,556 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,556 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:06,556 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,556 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,556 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,556 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:06,556 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:06,557 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:06,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:06,557 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:06,557 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:06,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:06,557 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:06,557 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:06,557 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:06,545 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,556 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:06,545 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:06,549 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:06,563 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:06,563 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:06,564 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:06,566 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:06,564 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:06,565 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:06,575 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,580 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:06,580 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:06,580 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:06,580 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:06,581 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:06,583 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:06,583 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:06,583 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:06,583 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:06,580 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:06,583 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:06,583 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:06,583 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:06,583 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:06,583 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:06,583 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:06,583 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:06,583 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:06,583 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:06,583 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:06,583 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:06,583 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:06,584 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:06,584 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:06,584 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,584 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,584 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,584 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,584 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,584 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,584 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,584 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:06,580 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:06,584 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:06,585 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:06,585 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:06,585 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:06,583 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:06,585 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:06,585 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,585 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:06,585 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:06,585 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:06,585 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:06,585 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,585 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:06,585 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:06,586 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,585 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:06,585 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:06,585 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,585 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,599 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:06,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:06,599 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,599 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:06,601 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:06,601 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,601 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:06,597 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:06,613 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:06,614 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,614 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:06,612 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,612 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:06,612 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,612 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:06,612 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:06,621 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:06,621 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:06,622 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,621 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,622 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,621 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:06,622 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,622 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:06,622 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:06,622 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,622 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:06,622 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:06,622 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:06,622 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,622 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,622 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:06,622 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:06,622 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,622 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:06,622 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,622 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,622 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,622 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:06,622 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:06,622 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,622 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,623 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:06,622 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,622 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:06,623 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:06,622 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:06,623 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,623 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:06,623 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:06,623 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:06,623 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,628 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,630 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,630 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:06,630 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:06,630 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:06,623 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,631 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,627 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,635 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:06,635 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:06,635 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:06,635 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:06,635 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:06,635 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:06,637 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:06,637 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:06,645 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,645 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:06,647 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,648 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:06,652 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,652 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,652 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,653 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:06,666 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,666 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,665 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,665 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:06,671 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,671 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:06,676 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:06,676 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:06,677 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:06,106 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,343 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,099 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,097 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,343 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,677 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:06,343 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,677 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:06,677 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:06,678 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:06,679 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:06,681 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:06,681 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:06,681 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:06,681 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:06,681 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:06,681 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:06,682 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:06,342 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,097 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,682 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:06,342 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,097 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,343 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,097 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,106 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,099 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,343 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,343 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515) [?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:264) [?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:06,695 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,695 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,695 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,695 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,695 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,695 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,696 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,696 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,696 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,696 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,695 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,698 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,695 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,697 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,698 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,698 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,698 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,701 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,701 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,702 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,702 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,697 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,702 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,702 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:06,702 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,702 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,702 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:06,702 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,702 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:06,702 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,702 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:06,702 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:06,702 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,702 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,703 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,703 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:06,703 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:06,703 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:06,703 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:06,703 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:06,703 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:06,703 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:06,703 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:06,703 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:06,713 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:06,713 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:06,713 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-02T15:33:06,713 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:06,713 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:06,713 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-02T15:33:06,714 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-02T15:33:06,714 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-02T15:33:06,715 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:06,715 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:06,715 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:06,715 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:06,715 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-02T15:33:06,715 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-02T15:33:06,715 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:06,715 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:06,716 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-02T15:33:06,716 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-02T15:33:06,716 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:06,716 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:06,716 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:06,716 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:06,716 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-02T15:33:06,716 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:06,716 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-02T15:33:06,716 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:06,716 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:06,716 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:06,716 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:06,716 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:06,723 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-02T15:33:06,722 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-02T15:33:06,722 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-02T15:33:06,723 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-02T15:33:06,722 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-02T15:33:06,722 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-02T15:33:06,790 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648881186
2022-04-02T15:33:06,794 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:108.78559875488281|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648881186
2022-04-02T15:33:06,794 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:119.48826599121094|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648881186
2022-04-02T15:33:06,794 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:52.3|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648881186
2022-04-02T15:33:06,794 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:1931.484375|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648881186
2022-04-02T15:33:06,799 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:2583.578125|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648881186
2022-04-02T15:33:06,800 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:76.4|#Level:Host|#hostname:MacBook-Air-2.local,timestamp:1648881186
2022-04-02T15:33:07,729 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:07,729 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:07,729 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:07,729 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:07,729 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:07,729 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:07,733 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:07,735 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:07,733 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:07,735 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:07,736 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:07,737 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:07,736 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:07,737 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:07,737 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:07,737 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:08,772 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:08,776 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]97716
2022-04-02T15:33:08,776 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:08,776 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:08,776 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,776 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,777 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:08,777 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:08,776 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:08,779 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]97719
2022-04-02T15:33:08,779 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:08,779 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:08,779 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,779 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,779 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:08,779 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:08,790 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:33:08,790 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:33:08,791 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:08,792 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]97714
2022-04-02T15:33:08,792 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:08,793 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:08,793 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,793 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,793 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:08,793 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:08,793 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:08,793 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]97718
2022-04-02T15:33:08,793 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:08,793 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:08,794 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,794 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,794 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:08,794 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:08,795 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881188795
2022-04-02T15:33:08,795 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881188795
2022-04-02T15:33:08,795 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881188795
2022-04-02T15:33:08,795 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881188795
2022-04-02T15:33:08,844 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881188840
2022-04-02T15:33:08,845 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:33:08,844 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881188840
2022-04-02T15:33:08,916 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:08,917 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:08,841 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:08,843 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:08,841 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:08,930 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]97713
2022-04-02T15:33:08,930 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]97712
2022-04-02T15:33:08,936 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]97715
2022-04-02T15:33:08,939 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:08,939 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:08,950 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,962 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:08,962 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:09,007 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:08,940 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:08,950 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:09,023 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:09,014 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:08,940 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:09,021 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]97717
2022-04-02T15:33:09,007 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:09,014 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:09,023 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:09,027 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:09,027 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:09,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:09,031 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:09,033 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:33:09,034 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:09,034 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:09,034 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:09,034 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:09,035 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:09,035 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:09,051 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881189050
2022-04-02T15:33:09,051 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881189050
2022-04-02T15:33:09,067 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:33:09,068 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:33:09,073 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:33:09,074 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881189073
2022-04-02T15:33:09,074 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881189073
2022-04-02T15:33:09,074 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881189074
2022-04-02T15:33:09,074 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881189074
2022-04-02T15:33:09,074 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:09,075 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881189075
2022-04-02T15:33:09,075 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881189075
2022-04-02T15:33:09,210 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,231 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881189230
2022-04-02T15:33:09,211 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,198 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:09,211 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,210 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,190 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:09,202 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:09,185 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:09,231 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881189230
2022-04-02T15:33:09,190 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:09,190 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:33:09,190 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:09,242 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,242 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,244 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,244 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,245 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:09,268 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:09,268 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:09,268 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:09,268 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,268 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,268 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,268 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,268 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:09,244 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:09,244 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,270 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:09,271 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:09,271 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,271 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:09,271 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:09,271 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:09,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:09,244 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,272 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:09,271 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,321 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:09,322 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:09,333 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,334 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,334 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,334 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:09,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:09,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:09,336 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:09,266 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,272 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,339 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:09,341 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:09,339 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:09,266 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,272 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,359 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,359 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,359 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,358 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:09,359 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,365 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,365 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,365 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,365 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,364 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:09,366 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:09,371 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:09,371 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:09,371 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:09,371 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:09,371 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:09,371 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:09,371 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:09,371 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:09,375 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:09,383 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:09,384 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-02T15:33:09,384 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 1 seconds.
2022-04-02T15:33:09,384 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-02T15:33:09,384 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 1 seconds.
2022-04-02T15:33:09,375 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:09,383 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:09,369 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:09,369 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:09,416 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:09,419 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,419 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:09,420 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:09,420 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:09,420 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:09,420 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,420 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,420 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,369 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:09,369 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:09,420 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,425 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,425 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,430 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:09,431 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:09,431 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:09,431 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,431 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:09,431 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:09,431 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:09,432 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,432 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:09,432 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,432 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,432 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,432 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,432 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:09,432 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:09,432 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:09,432 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:09,432 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:09,432 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:09,433 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:09,433 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:09,433 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:09,433 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:09,433 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:09,433 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:09,433 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,433 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,433 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,434 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,435 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:09,436 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,436 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,437 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,437 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:09,432 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,437 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:09,432 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,437 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,437 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,438 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,438 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,438 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:09,438 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:09,438 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:09,438 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:09,439 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:09,439 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:09,440 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-02T15:33:09,440 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 1 seconds.
2022-04-02T15:33:09,438 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:09,438 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:09,499 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:09,499 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:09,502 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,503 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:09,503 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,504 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:09,505 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:09,505 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:09,505 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:09,505 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:09,505 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:09,506 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,506 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,526 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,506 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:09,535 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,536 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,536 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,536 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,537 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:09,506 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,537 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:09,528 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,537 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:09,539 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,539 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,539 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:09,539 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:09,539 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:09,539 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,540 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:09,540 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,540 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,540 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:09,526 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,541 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,541 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,539 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,541 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,541 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,541 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,526 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:09,543 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,543 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:09,543 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:09,543 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:09,543 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:09,543 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,542 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:09,543 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,545 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,546 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,547 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:09,547 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:09,547 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:09,547 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,541 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,545 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:09,506 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,505 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,551 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,552 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,552 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,551 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,555 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,555 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,547 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:09,555 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,555 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,555 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:09,549 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:09,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:09,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:09,548 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:09,561 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,559 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:09,556 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:09,566 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,567 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:09,567 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,567 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,567 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:09,567 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:09,567 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:09,567 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:09,557 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,567 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:09,567 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:09,567 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:09,567 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:09,568 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,568 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:09,568 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,568 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:09,568 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:09,510 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:09,568 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:09,568 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,568 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:09,568 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:09,568 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:09,568 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,528 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:09,568 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:09,570 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,569 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:09,568 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,570 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:09,570 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:09,570 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:09,570 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:09,570 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:09,570 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:09,570 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:09,570 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:09,561 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,570 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:09,572 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:09,572 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:09,572 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:09,572 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:09,572 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,572 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,572 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,570 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,573 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,573 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,575 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,575 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,567 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:09,574 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,576 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:09,576 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:09,576 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:09,577 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,577 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,578 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,580 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,576 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:09,580 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,570 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,590 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:09,590 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,590 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:09,577 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,590 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:09,578 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,590 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,590 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,577 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,591 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,590 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,591 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:09,591 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:09,591 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:09,591 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:09,591 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:09,591 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:09,591 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:09,591 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:09,592 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:09,591 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:09,594 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,592 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:09,591 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:09,570 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:09,591 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:09,591 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:09,620 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:09,619 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:09,620 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:09,619 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:09,620 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:09,620 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:09,620 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-02T15:33:09,620 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,620 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 1 seconds.
2022-04-02T15:33:09,620 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,621 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,621 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:09,591 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:09,621 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:09,591 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:09,621 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,621 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:09,621 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:09,621 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,621 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-02T15:33:09,621 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,621 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 1 seconds.
2022-04-02T15:33:09,621 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:09,576 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:09,591 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:09,621 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,621 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:09,621 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:09,621 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:09,621 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,621 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:09,591 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:09,621 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,622 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:09,622 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:09,622 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,622 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-02T15:33:09,622 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:09,591 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:09,622 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 1 seconds.
2022-04-02T15:33:09,622 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:09,622 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:09,622 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:09,622 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:09,622 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:09,622 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-02T15:33:09,622 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:09,622 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 1 seconds.
2022-04-02T15:33:09,622 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:09,661 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:09,662 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,663 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:09,663 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:09,663 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:09,663 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:09,663 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,663 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,663 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,663 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,664 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:09,664 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:09,664 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:09,661 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,661 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:09,664 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,667 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:09,667 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:09,667 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,667 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:09,667 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:09,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:09,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:09,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:09,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:09,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:09,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:09,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:09,669 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:09,669 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:09,669 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:09,669 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:09,669 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:09,669 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:09,669 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:09,670 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:09,670 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:09,670 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:09,668 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,670 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,668 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:09,671 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,671 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:09,671 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,671 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:09,671 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:09,671 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:09,671 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:09,671 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:09,671 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:09,671 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,671 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:09,672 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:09,672 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:09,672 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:09,672 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:09,672 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:09,685 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:09,685 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:09,685 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-02T15:33:09,685 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 1 seconds.
2022-04-02T15:33:09,672 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:10,385 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:10,385 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:10,387 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:10,387 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:10,445 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:10,445 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:10,649 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:10,649 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:10,649 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:10,649 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:10,649 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:10,649 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:10,650 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:10,650 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:10,691 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:10,691 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:11,364 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:11,368 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]97721
2022-04-02T15:33:11,368 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:11,368 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:11,368 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:11,368 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:11,369 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:11,369 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:11,378 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881191377
2022-04-02T15:33:11,378 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881191377
2022-04-02T15:33:11,410 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:33:11,412 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:11,535 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:11,537 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]97722
2022-04-02T15:33:11,537 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:11,537 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:11,538 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:11,538 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:11,538 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:11,538 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:11,539 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881191539
2022-04-02T15:33:11,539 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881191539
2022-04-02T15:33:11,544 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:33:11,544 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:11,758 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:11,759 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]97723
2022-04-02T15:33:11,772 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:11,772 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:11,772 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:11,772 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:11,772 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:11,772 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:11,775 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881191775
2022-04-02T15:33:11,775 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881191775
2022-04-02T15:33:11,780 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:33:11,780 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:12,063 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:12,063 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,063 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:12,063 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:12,063 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:12,063 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:12,063 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:12,063 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:12,074 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,074 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,076 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:12,076 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:12,077 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:12,077 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:12,077 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:12,077 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:12,084 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,077 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:12,084 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,084 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:12,086 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:12,086 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:12,086 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:12,086 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:12,086 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,086 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:12,086 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:12,085 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,085 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,087 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,086 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:12,087 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,090 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,090 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,087 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:12,098 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:12,098 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:12,098 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:12,099 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:12,099 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:12,099 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:12,099 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:12,097 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:12,099 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:12,118 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:12,099 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:12,097 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:12,130 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:12,140 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:12,141 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:12,142 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:12,142 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,142 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:12,142 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:12,142 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:12,142 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-04-02T15:33:12,142 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 2 seconds.
2022-04-02T15:33:12,142 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:12,142 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:12,142 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:12,142 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:12,143 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:12,143 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:12,143 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:12,143 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:12,143 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:12,143 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:12,146 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,146 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,146 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:12,152 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:12,152 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,152 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,152 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:12,152 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]97728
2022-04-02T15:33:12,153 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:12,153 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:12,153 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:12,153 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:12,153 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:12,154 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:12,154 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:12,154 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:12,154 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:12,154 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:12,155 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:12,153 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,154 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:12,153 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,165 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:12,168 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,155 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:12,167 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,168 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,168 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]97724
2022-04-02T15:33:12,168 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:12,168 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:12,168 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:12,169 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,169 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:12,169 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:12,169 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:12,169 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,169 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:12,174 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:12,178 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:12,178 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:12,178 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:12,178 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:12,178 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:12,173 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:33:12,179 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:12,179 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:12,179 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:12,179 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:12,179 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:12,179 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:12,179 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:12,179 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:12,179 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:12,179 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:12,179 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:12,179 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:12,191 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-04-02T15:33:12,173 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881192171
2022-04-02T15:33:12,173 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881192171
2022-04-02T15:33:12,194 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881192193
2022-04-02T15:33:12,194 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881192193
2022-04-02T15:33:12,195 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:33:12,179 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:12,191 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 2 seconds.
2022-04-02T15:33:12,179 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:12,177 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:12,198 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]97726
2022-04-02T15:33:12,198 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:12,198 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:12,198 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:12,198 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:12,205 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:12,205 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:12,206 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:12,206 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:12,208 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:33:12,208 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881192207
2022-04-02T15:33:12,208 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881192207
2022-04-02T15:33:12,213 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:12,223 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:12,230 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:12,231 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]97725
2022-04-02T15:33:12,231 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]97727
2022-04-02T15:33:12,231 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:12,231 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:12,231 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:12,231 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:12,231 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:12,231 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:12,231 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:12,232 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:12,232 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:12,232 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:12,232 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:12,232 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:12,235 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881192235
2022-04-02T15:33:12,235 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881192235
2022-04-02T15:33:12,242 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,242 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:12,235 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881192235
2022-04-02T15:33:12,235 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881192235
2022-04-02T15:33:12,255 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,234 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:33:12,255 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:12,234 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:33:12,256 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:12,256 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:12,256 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:12,256 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:12,256 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:12,256 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:12,257 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:12,257 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:12,257 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:12,242 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,259 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,258 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:12,257 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:12,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:12,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:12,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:12,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:12,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:12,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:12,260 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:12,259 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,259 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:12,270 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,270 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,271 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,271 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,272 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,272 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,272 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:12,272 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:12,272 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:12,272 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:12,273 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-04-02T15:33:12,273 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 2 seconds.
2022-04-02T15:33:12,273 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,274 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:12,274 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:12,272 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:12,272 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:12,483 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:12,484 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,484 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,484 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,484 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,484 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,484 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,485 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:12,485 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,489 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,485 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,497 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,493 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,489 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:12,493 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,497 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,499 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:12,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:12,500 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:12,500 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:12,500 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:12,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,500 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:12,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:12,500 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:12,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:12,500 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:12,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:12,500 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:12,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:12,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:12,500 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:12,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:12,500 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:12,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:12,500 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,500 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,500 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:12,501 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,500 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:12,489 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,501 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,501 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,501 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,501 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,501 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,501 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,501 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:12,501 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,503 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,503 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,503 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,502 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:12,502 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:12,502 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,502 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,503 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:12,503 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,503 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,503 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,503 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:12,503 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:12,503 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:12,503 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:12,504 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:12,505 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:12,507 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:12,503 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:12,504 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:12,504 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:12,507 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:12,503 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:12,505 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:12,505 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:12,506 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:12,505 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:12,506 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:12,505 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:12,505 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:12,545 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,545 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:12,545 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,540 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:12,546 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:12,545 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,546 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:12,545 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:12,540 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:12,545 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:12,553 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,553 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,553 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,553 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:12,554 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,554 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,553 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,553 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:12,555 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,555 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,555 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,555 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:12,556 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:12,556 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,556 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:12,556 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,556 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:12,556 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:12,558 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,558 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:12,559 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-04-02T15:33:12,559 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 2 seconds.
2022-04-02T15:33:12,560 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:12,560 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:12,560 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-04-02T15:33:12,560 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 2 seconds.
2022-04-02T15:33:12,560 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:12,560 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:12,567 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:12,567 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:12,567 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-04-02T15:33:12,567 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-04-02T15:33:12,567 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 2 seconds.
2022-04-02T15:33:12,567 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 2 seconds.
2022-04-02T15:33:12,564 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:12,564 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:12,573 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:12,573 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:12,573 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,579 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:12,579 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:12,579 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:12,579 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:12,579 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:12,579 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:12,579 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:12,579 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:12,580 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:12,580 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:12,580 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:12,580 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:12,581 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:12,581 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:12,581 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:12,581 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:12,586 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:12,588 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:12,588 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:12,571 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:12,567 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:12,592 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-04-02T15:33:12,592 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 2 seconds.
2022-04-02T15:33:12,567 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:12,571 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:14,149 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:14,149 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:14,183 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:14,183 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:14,275 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:14,275 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:14,548 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:14,548 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:14,549 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:14,549 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:14,567 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:14,567 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:14,567 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:14,567 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:14,587 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:14,587 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:14,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:14,973 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]97729
2022-04-02T15:33:14,973 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:14,973 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:14,973 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:14,973 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:14,974 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:14,974 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:14,978 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:33:14,978 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881194978
2022-04-02T15:33:14,978 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881194978
2022-04-02T15:33:14,981 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:15,413 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:15,414 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]97730
2022-04-02T15:33:15,414 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:15,414 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:15,414 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,414 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,415 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:15,415 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:15,417 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195417
2022-04-02T15:33:15,417 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195417
2022-04-02T15:33:15,427 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:33:15,427 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:15,766 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:15,769 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:15,769 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:15,771 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:15,771 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:15,771 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:15,771 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:15,771 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:15,771 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:15,771 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:15,771 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:15,771 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:15,771 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:15,771 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:15,772 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:15,772 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:15,772 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:15,772 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:15,772 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:15,772 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:15,773 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:15,773 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:15,773 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:15,773 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:15,774 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:15,774 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:15,774 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:15,773 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:15,776 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2022-04-02T15:33:15,776 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 3 seconds.
2022-04-02T15:33:15,791 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:15,792 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]97731
2022-04-02T15:33:15,792 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:15,792 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:15,792 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,792 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,793 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:15,793 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:15,795 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195795
2022-04-02T15:33:15,795 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195795
2022-04-02T15:33:15,796 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:33:15,797 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:15,858 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:15,856 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:15,858 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:15,860 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:15,860 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:15,860 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:15,861 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:15,861 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:15,861 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:15,861 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:15,861 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:15,861 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:15,861 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:15,861 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:15,861 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:15,861 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:15,861 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:15,864 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:15,864 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:15,864 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:15,864 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:15,864 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:15,864 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:15,864 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:15,864 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:15,864 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:15,864 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:15,865 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:15,865 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:15,865 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:15,865 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 3 seconds.
2022-04-02T15:33:15,865 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:15,905 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:15,912 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]97734
2022-04-02T15:33:15,912 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:15,912 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:15,912 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,912 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,913 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:15,913 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:15,914 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:15,917 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195915
2022-04-02T15:33:15,917 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195915
2022-04-02T15:33:15,917 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:33:15,918 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]97735
2022-04-02T15:33:15,918 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:15,918 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:15,918 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:15,918 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,918 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,918 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]97733
2022-04-02T15:33:15,919 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:15,919 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,919 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:15,919 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:15,919 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,919 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:15,919 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:15,919 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:15,920 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:15,923 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:33:15,923 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195923
2022-04-02T15:33:15,923 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195923
2022-04-02T15:33:15,923 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:33:15,924 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195924
2022-04-02T15:33:15,924 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195924
2022-04-02T15:33:15,925 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:15,925 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:15,922 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:15,929 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:15,931 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]97732
2022-04-02T15:33:15,931 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:15,931 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,931 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,932 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:15,932 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:15,935 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195934
2022-04-02T15:33:15,931 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:15,935 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195934
2022-04-02T15:33:15,931 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]97736
2022-04-02T15:33:15,939 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:15,939 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:15,939 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,939 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:33:15,939 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:15,939 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:15,939 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:15,940 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:15,941 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195941
2022-04-02T15:33:15,941 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881195941
2022-04-02T15:33:15,941 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:33:15,942 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:16,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:16,071 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,071 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,072 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,072 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,072 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:16,073 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:16,073 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:16,073 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:16,073 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:16,073 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:16,073 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:16,073 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:16,073 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:16,073 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,074 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:16,073 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,094 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,094 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,094 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,094 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,094 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:16,094 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:16,095 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:16,095 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:16,095 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2022-04-02T15:33:16,095 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 3 seconds.
2022-04-02T15:33:16,095 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:16,095 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:16,096 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:16,096 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:16,096 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:16,234 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:16,238 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:16,238 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,238 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,241 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:16,241 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:16,241 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:16,241 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:16,241 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:16,241 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:16,241 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:16,242 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:16,242 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:16,242 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:16,242 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:16,242 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:16,242 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:16,242 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:16,242 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,256 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,252 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,242 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,259 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,258 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:16,260 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:16,261 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:16,252 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,261 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:16,261 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:16,260 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:16,242 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:16,260 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:16,246 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:16,269 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,270 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,259 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,270 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,272 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,270 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:16,272 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,279 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,278 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:16,256 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,279 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,286 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:16,270 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,270 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:16,286 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,270 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:16,286 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:16,286 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:16,281 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:16,289 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,289 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,272 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:16,271 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:16,269 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,270 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:16,299 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:16,299 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:16,286 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,299 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:16,299 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:16,299 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:16,299 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:16,299 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:16,299 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:16,298 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,298 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,300 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:16,300 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:16,300 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,300 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,299 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,300 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:16,299 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:16,300 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:16,299 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,300 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,300 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:16,300 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,300 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,300 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:16,300 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,300 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,300 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,300 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:16,301 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:16,301 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:16,301 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:16,300 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:16,286 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:16,298 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,298 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,320 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:16,319 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:16,320 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:16,319 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:16,319 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:16,326 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:16,330 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,335 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:16,335 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:16,330 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,336 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:16,336 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:16,330 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:16,331 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:16,327 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,327 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:16,331 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:16,327 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:16,330 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:16,337 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:16,336 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:16,336 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:16,339 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:16,331 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-04-02T15:33:16,331 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 3 seconds.
2022-04-02T15:33:16,341 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:16,341 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:16,341 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-04-02T15:33:16,341 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 3 seconds.
2022-04-02T15:33:16,341 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:16,341 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:16,337 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:16,336 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,336 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,339 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:16,338 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2022-04-02T15:33:16,338 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 3 seconds.
2022-04-02T15:33:16,344 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:16,344 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:16,344 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:16,344 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:16,344 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-04-02T15:33:16,344 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 3 seconds.
2022-04-02T15:33:16,339 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,339 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:16,345 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,343 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:16,345 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:16,345 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:16,345 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:16,345 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:16,345 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:16,345 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,345 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:16,345 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:16,345 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:16,345 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:16,345 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:16,345 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:16,345 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:16,346 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:16,346 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:16,346 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:16,346 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:16,346 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:16,346 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:16,346 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:16,346 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:16,346 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:16,346 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:16,346 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:16,346 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-04-02T15:33:16,346 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 3 seconds.
2022-04-02T15:33:18,781 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:18,781 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:18,872 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:18,872 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:19,100 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:19,100 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:19,331 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:19,331 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]97737
2022-04-02T15:33:19,331 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:19,331 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:19,332 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:19,332 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:19,332 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:19,332 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:19,335 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:19,335 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:19,336 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881199336
2022-04-02T15:33:19,336 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881199336
2022-04-02T15:33:19,336 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:33:19,336 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:19,336 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:19,337 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:19,341 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:19,341 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:19,345 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:19,345 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:19,347 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:19,347 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:19,719 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:19,720 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]97739
2022-04-02T15:33:19,720 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:19,720 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:19,720 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:19,720 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:19,720 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:19,720 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:19,723 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881199723
2022-04-02T15:33:19,723 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881199723
2022-04-02T15:33:19,725 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:33:19,725 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:20,263 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:20,263 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,263 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:20,267 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,267 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:20,267 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,268 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:20,268 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:20,268 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:20,268 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:20,268 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,268 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:20,269 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:20,269 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:20,269 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:20,269 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:20,269 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:20,269 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:20,269 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:20,269 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:20,269 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:20,270 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,270 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:20,270 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:20,270 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 5 seconds.
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 5 seconds.
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:20,270 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:20,540 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:20,541 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]97740
2022-04-02T15:33:20,541 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:20,541 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:20,544 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,544 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,546 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:20,546 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:20,549 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200549
2022-04-02T15:33:20,549 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200549
2022-04-02T15:33:20,549 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:33:20,550 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:20,551 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:20,551 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,551 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:20,551 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:20,551 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:20,551 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:20,556 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,556 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,557 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:20,557 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:20,557 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,557 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,557 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:20,557 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:20,557 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:20,557 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:20,558 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:20,558 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:20,558 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:20,558 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:20,558 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:20,558 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:20,558 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:20,559 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:20,559 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:20,559 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:20,559 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:20,559 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:20,559 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:20,559 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:20,559 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2022-04-02T15:33:20,559 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 5 seconds.
2022-04-02T15:33:20,559 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:20,559 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:20,631 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:20,632 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]97744
2022-04-02T15:33:20,632 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:20,632 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:20,632 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,632 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,633 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:20,633 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:20,635 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200635
2022-04-02T15:33:20,635 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200635
2022-04-02T15:33:20,635 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:33:20,636 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:20,637 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:20,638 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]97742
2022-04-02T15:33:20,638 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:20,638 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:20,638 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,638 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,642 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:20,642 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:20,647 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200647
2022-04-02T15:33:20,647 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:33:20,647 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200647
2022-04-02T15:33:20,648 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:20,656 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:20,657 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]97743
2022-04-02T15:33:20,657 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:20,657 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:20,658 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,658 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,658 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:20,658 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:20,659 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:33:20,659 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200659
2022-04-02T15:33:20,659 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200659
2022-04-02T15:33:20,660 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:20,661 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:20,662 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]97745
2022-04-02T15:33:20,662 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:20,662 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,662 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:20,662 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,662 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:20,662 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:20,663 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:33:20,664 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200664
2022-04-02T15:33:20,664 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200664
2022-04-02T15:33:20,665 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:20,668 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:20,669 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]97741
2022-04-02T15:33:20,669 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:20,669 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:20,669 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,669 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:20,670 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:20,670 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:20,670 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200670
2022-04-02T15:33:20,670 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881200670
2022-04-02T15:33:20,670 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:33:20,671 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:20,818 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:20,819 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,819 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:20,819 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:20,819 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:20,819 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:20,819 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:20,819 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:20,819 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,819 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:20,820 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:20,820 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:20,821 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:20,822 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:20,823 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,823 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:20,823 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:20,823 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:20,823 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,823 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:20,823 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:20,823 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:20,836 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,836 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,840 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,840 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,840 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,840 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,841 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:20,841 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:20,841 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:20,841 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:20,842 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:20,842 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:20,842 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:20,842 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:20,842 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2022-04-02T15:33:20,842 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 5 seconds.
2022-04-02T15:33:20,842 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:20,842 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:20,850 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:20,850 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:20,938 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:20,938 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,938 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:20,938 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:20,938 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:20,938 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:20,939 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:20,939 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:20,943 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,943 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,944 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,944 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:20,944 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,944 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:20,945 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:20,944 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,945 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:20,945 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:20,945 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:20,945 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:20,945 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:20,945 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:20,945 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:20,945 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:20,946 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,946 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:20,946 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:20,946 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:20,947 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:20,945 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,945 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,947 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:20,947 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:20,947 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:20,947 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:20,947 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:20,947 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:20,947 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:20,947 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:20,948 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:20,948 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:20,948 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:20,948 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:20,948 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:20,948 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:20,948 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,948 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:20,948 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:20,949 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:20,949 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,949 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:20,949 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:20,948 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:20,948 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:20,949 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:20,949 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:20,949 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:20,949 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-04-02T15:33:20,949 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 5 seconds.
2022-04-02T15:33:20,957 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:20,957 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:20,948 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:20,948 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:20,967 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,967 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,968 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:20,968 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,968 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:20,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:20,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:20,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:20,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:20,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:20,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:20,968 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,975 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,975 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,968 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,972 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:20,971 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:20,980 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:20,980 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:20,980 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:20,980 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:20,981 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:20,981 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,981 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,982 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:20,981 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,982 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:20,982 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:20,992 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:20,997 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,998 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:20,998 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:20,998 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:20,997 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:20,998 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:20,999 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,999 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:20,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:20,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:20,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:20,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:20,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:20,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:20,999 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:21,000 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:21,000 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:21,000 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:21,000 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:20,982 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:20,982 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:21,000 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,999 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,982 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:21,000 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:20,982 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:21,001 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-04-02T15:33:21,000 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:20,999 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:21,000 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:21,017 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:21,001 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 5 seconds.
2022-04-02T15:33:21,003 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:20,982 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:21,001 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:21,022 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:21,023 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:21,023 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:21,021 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:21,021 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:21,023 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:21,023 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:21,024 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:21,024 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:21,024 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:21,024 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:21,024 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:21,024 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:21,024 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:21,024 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:21,025 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:21,024 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:21,025 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:21,025 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:21,025 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:21,025 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:21,025 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:21,025 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:21,025 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:21,025 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:21,025 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:21,025 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:21,025 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:21,025 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:21,025 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:21,025 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:21,025 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:21,025 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:21,026 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:21,025 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:21,026 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:21,026 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:21,026 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:21,026 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:21,026 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:21,026 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:21,026 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:21,026 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:21,026 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:21,026 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:21,026 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:21,026 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:21,026 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:21,026 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:21,027 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:21,027 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:21,027 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:21,027 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:21,026 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:21,027 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:21,027 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:21,027 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:21,027 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:21,027 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:21,027 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:21,027 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:21,027 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:21,027 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:21,027 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:21,027 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:21,028 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:21,027 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:21,027 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:21,026 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:21,027 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:21,027 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:21,028 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:21,045 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:21,045 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:21,045 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:21,045 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:21,046 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:21,046 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:21,046 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:21,046 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:21,046 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:21,046 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:21,027 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:21,046 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:21,046 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:21,046 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:21,027 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:21,046 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:21,027 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:21,046 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:21,046 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:21,047 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-04-02T15:33:21,047 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 5 seconds.
2022-04-02T15:33:21,047 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:21,047 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:21,047 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:21,047 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-04-02T15:33:21,047 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 5 seconds.
2022-04-02T15:33:21,047 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:21,047 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:21,047 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:21,048 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 5 seconds.
2022-04-02T15:33:21,048 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 5 seconds.
2022-04-02T15:33:21,027 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:21,026 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:21,027 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:25,280 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:25,280 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:25,574 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:25,574 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:25,708 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:25,717 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]97746
2022-04-02T15:33:25,717 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:25,717 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:25,717 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:25,717 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:25,717 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:25,717 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:25,719 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:33:25,719 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881205719
2022-04-02T15:33:25,719 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881205719
2022-04-02T15:33:25,722 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:25,848 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:25,848 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:25,950 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:25,950 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:25,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:25,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:25,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:25,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:25,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:25,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:25,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:25,972 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:25,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:25,972 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:25,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:25,972 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:25,973 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:25,973 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:25,973 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:25,973 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:25,973 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:25,973 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:25,974 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:25,975 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:25,976 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:25,976 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:25,976 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:25,976 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:25,976 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:25,976 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:25,976 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:25,973 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:25,973 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:25,977 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:25,977 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:25,978 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:25,978 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:25,978 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:25,978 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:25,978 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:25,978 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:25,978 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:25,978 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:25,979 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 8 seconds.
2022-04-02T15:33:25,979 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 8 seconds.
2022-04-02T15:33:25,978 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:25,978 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:26,004 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:26,004 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:26,051 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:26,051 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:26,051 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:26,051 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:26,051 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:26,051 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:26,528 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:26,529 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]97747
2022-04-02T15:33:26,529 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:26,529 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:26,529 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:26,529 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:26,530 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:26,530 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:26,531 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881206531
2022-04-02T15:33:26,531 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881206531
2022-04-02T15:33:26,544 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:33:26,544 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:27,189 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:27,189 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,189 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:27,189 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:27,189 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,189 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:27,189 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,189 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:27,189 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:27,189 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:27,189 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:27,189 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:27,190 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,190 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:27,190 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:27,191 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,191 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:27,191 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:27,191 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:27,191 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:27,192 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:27,192 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:27,192 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:27,192 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:27,192 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:27,192 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:27,192 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2022-04-02T15:33:27,192 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 8 seconds.
2022-04-02T15:33:27,192 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:27,192 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:27,240 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:27,241 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]97748
2022-04-02T15:33:27,241 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:27,241 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:27,241 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,241 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,241 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:27,241 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:27,242 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207242
2022-04-02T15:33:27,242 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:33:27,242 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207242
2022-04-02T15:33:27,243 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:27,246 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:27,248 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]97749
2022-04-02T15:33:27,248 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:27,248 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,248 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,248 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:27,248 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:27,248 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:27,249 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207249
2022-04-02T15:33:27,249 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:33:27,249 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207249
2022-04-02T15:33:27,251 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:27,287 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:27,287 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]97750
2022-04-02T15:33:27,287 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:27,287 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:27,287 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,287 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,287 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:27,287 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:27,290 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:33:27,290 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207290
2022-04-02T15:33:27,290 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207290
2022-04-02T15:33:27,291 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:27,295 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:27,296 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]97753
2022-04-02T15:33:27,296 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:27,296 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:27,296 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,296 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,296 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:27,296 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:27,298 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207298
2022-04-02T15:33:27,298 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207298
2022-04-02T15:33:27,298 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:33:27,298 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:27,298 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]97751
2022-04-02T15:33:27,298 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:27,299 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:27,299 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,299 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,299 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:27,299 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:27,299 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:27,300 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207300
2022-04-02T15:33:27,300 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207300
2022-04-02T15:33:27,300 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:33:27,301 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:27,325 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:27,329 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]97752
2022-04-02T15:33:27,329 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,329 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:27,329 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:27,329 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:27,329 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:27,329 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:27,331 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207331
2022-04-02T15:33:27,331 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881207331
2022-04-02T15:33:27,330 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:33:27,337 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:27,532 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,532 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:27,532 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:27,532 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,533 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:27,533 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:27,533 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,533 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,533 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:27,533 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,533 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:27,534 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:27,534 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:27,534 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:27,534 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:27,532 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,533 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,534 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,534 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,535 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,536 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,535 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,536 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,536 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,533 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,536 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:27,537 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:27,537 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:27,537 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:27,537 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:27,538 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:27,538 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:27,538 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:27,538 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:27,536 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,540 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,540 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,541 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,541 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,541 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,541 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:27,541 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:27,541 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,537 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:27,543 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:27,541 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:27,543 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:27,543 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:27,543 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2022-04-02T15:33:27,543 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 8 seconds.
2022-04-02T15:33:27,541 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:27,543 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:27,543 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:27,542 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:27,543 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:27,544 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-04-02T15:33:27,544 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 8 seconds.
2022-04-02T15:33:27,544 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:27,544 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:27,544 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:27,545 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:27,545 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:27,545 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:27,545 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:27,545 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:27,597 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:27,597 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,597 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:27,597 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:27,597 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:27,597 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:27,597 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:27,597 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:27,597 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,597 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,597 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:27,598 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:27,598 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,598 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,598 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,598 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,598 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,598 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,598 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:27,598 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,598 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:27,598 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,598 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:27,598 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:27,599 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:27,599 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:27,599 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:27,599 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:27,600 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-04-02T15:33:27,600 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 8 seconds.
2022-04-02T15:33:27,599 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:27,600 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:27,600 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:27,609 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:27,610 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,610 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:27,610 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:27,610 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,610 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:27,610 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,610 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,610 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,610 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:27,610 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,610 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:27,610 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,610 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:27,610 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:27,610 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,610 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,610 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:27,610 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:27,610 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,610 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:27,610 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:27,610 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:27,611 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:27,611 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:27,611 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:27,610 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,610 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,611 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:27,611 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:27,610 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,611 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:27,610 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,611 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,611 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,611 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:27,611 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:27,611 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,611 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:27,611 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,611 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,611 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:27,611 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:27,611 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,611 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,611 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:27,611 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,611 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:27,612 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:27,612 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:27,611 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:27,612 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:27,612 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:27,612 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:27,612 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:27,612 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:27,612 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:27,612 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:27,612 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:27,612 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:27,612 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:27,612 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:27,612 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:27,612 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:27,612 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:27,612 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:27,612 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:27,612 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:27,612 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,612 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,613 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:27,613 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:27,612 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:27,613 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:27,612 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:27,613 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:27,613 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-04-02T15:33:27,613 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:27,613 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:27,613 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:27,613 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 8 seconds.
2022-04-02T15:33:27,613 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 8 seconds.
2022-04-02T15:33:27,613 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 8 seconds.
2022-04-02T15:33:27,613 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:27,613 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:27,613 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:27,641 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:27,641 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,641 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:27,641 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:27,641 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:27,641 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:27,641 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:27,641 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:27,641 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,641 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:27,641 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:27,641 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:27,641 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,641 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:27,642 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,642 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:27,642 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:27,644 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:27,644 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,644 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:27,644 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:27,644 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:27,644 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,644 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:27,644 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:27,644 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:27,644 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:27,644 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:27,645 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:27,645 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:27,644 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:27,645 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:27,645 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:27,645 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:27,645 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:27,644 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:27,645 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:27,645 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-04-02T15:33:27,645 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 8 seconds.
2022-04-02T15:33:27,645 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:27,645 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:33,985 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:33,985 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:34,406 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:34,414 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]97755
2022-04-02T15:33:34,415 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:34,415 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:34,415 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:34,415 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:34,416 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:34,416 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:34,418 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:33:34,420 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881214420
2022-04-02T15:33:34,420 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881214420
2022-04-02T15:33:34,429 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:34,571 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:34,571 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:34,571 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:34,571 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:34,571 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:34,572 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:34,571 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:34,571 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:34,573 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:34,573 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:34,573 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:34,573 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:34,573 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:34,574 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:34,574 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:34,574 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:34,574 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:34,574 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:34,574 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:34,574 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 13 seconds.
2022-04-02T15:33:34,574 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 13 seconds.
2022-04-02T15:33:34,574 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:34,574 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:35,200 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:35,200 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:35,554 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:35,554 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:35,554 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:35,554 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:35,605 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:35,605 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:35,616 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:35,616 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:35,616 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:35,616 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:35,633 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:35,638 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]97756
2022-04-02T15:33:35,638 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:35,638 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:35,638 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:35,638 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:35,639 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:35,639 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:35,641 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:33:35,641 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881215641
2022-04-02T15:33:35,641 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881215641
2022-04-02T15:33:35,643 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:35,651 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:35,651 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:36,155 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:36,155 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,156 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,156 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:36,156 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:36,156 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:36,156 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:36,156 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,156 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,157 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:36,158 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,158 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:36,158 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,158 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:36,158 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:36,158 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:36,158 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:36,158 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 13 seconds.
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:36,158 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:36,636 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:36,637 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]97757
2022-04-02T15:33:36,637 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:36,637 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:36,638 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,638 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,638 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:36,638 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:36,643 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216643
2022-04-02T15:33:36,643 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:33:36,643 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216643
2022-04-02T15:33:36,643 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:36,648 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:36,649 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]97758
2022-04-02T15:33:36,649 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:36,649 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:36,649 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,649 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,649 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:36,649 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:36,651 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216651
2022-04-02T15:33:36,651 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216651
2022-04-02T15:33:36,651 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:33:36,652 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:36,667 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:36,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]97759
2022-04-02T15:33:36,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:36,668 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:36,668 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,668 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,668 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:36,668 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:36,669 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216669
2022-04-02T15:33:36,669 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216669
2022-04-02T15:33:36,669 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:33:36,671 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:36,684 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:36,685 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]97760
2022-04-02T15:33:36,685 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:36,685 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:36,685 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,685 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,685 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:36,685 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:36,686 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:36,686 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]97762
2022-04-02T15:33:36,686 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:33:36,687 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:36,687 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216687
2022-04-02T15:33:36,687 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216687
2022-04-02T15:33:36,687 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,687 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:36,687 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,687 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:36,687 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:36,687 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:36,687 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:33:36,687 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]97761
2022-04-02T15:33:36,688 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:36,688 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216688
2022-04-02T15:33:36,688 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216688
2022-04-02T15:33:36,688 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:36,688 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,688 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:36,688 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:36,688 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:36,688 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:36,689 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:36,689 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216689
2022-04-02T15:33:36,689 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:33:36,689 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881216689
2022-04-02T15:33:36,690 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:36,932 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,932 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:36,932 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:36,933 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:36,933 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,933 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:36,933 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:36,933 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:36,934 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:36,934 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:36,934 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,935 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,935 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,935 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,935 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,935 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:36,935 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:36,935 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:36,935 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:36,936 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:36,936 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:36,936 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:36,936 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:36,936 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-04-02T15:33:36,936 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 13 seconds.
2022-04-02T15:33:36,936 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:36,936 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:36,954 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:36,955 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,955 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,955 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,955 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,955 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,955 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,958 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,958 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,958 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,958 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,958 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:36,958 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:36,958 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:36,958 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:36,958 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2022-04-02T15:33:36,958 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 13 seconds.
2022-04-02T15:33:36,958 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,959 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:36,959 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:36,959 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:36,959 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,960 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,958 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:36,959 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:36,958 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:36,968 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:36,960 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,968 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:36,968 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:36,968 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:36,968 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,968 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,968 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:36,968 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,968 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,968 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,969 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,969 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,969 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,969 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:36,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:36,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:36,970 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:36,970 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:36,970 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:36,970 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:36,970 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-04-02T15:33:36,970 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 13 seconds.
2022-04-02T15:33:36,970 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:36,970 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:36,970 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:36,969 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:36,993 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:36,993 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,993 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:36,993 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:36,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:36,994 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,994 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:36,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:36,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:36,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,994 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,994 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:36,994 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,994 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:36,994 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:36,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:36,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:36,994 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:36,994 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:36,994 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:36,994 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:36,995 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:36,995 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,995 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:36,995 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:36,995 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,995 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,995 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,994 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,994 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:36,995 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,995 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,995 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,995 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,995 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,996 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,996 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,996 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,996 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:36,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:36,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:36,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:36,995 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:36,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:36,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:36,996 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,996 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:36,996 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:36,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:36,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:36,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:36,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:36,996 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:36,996 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:36,997 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:36,997 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:36,997 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:36,997 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-04-02T15:33:36,996 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:36,997 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:36,996 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,997 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,997 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:36,997 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:36,997 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 13 seconds.
2022-04-02T15:33:36,997 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:36,996 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:36,997 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:36,997 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:36,997 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 13 seconds.
2022-04-02T15:33:36,997 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 13 seconds.
2022-04-02T15:33:36,997 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,997 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:36,997 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:36,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:36,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:36,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:36,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:36,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:36,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:36,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:36,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:36,998 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:36,999 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,999 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:36,999 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:36,999 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:36,999 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:37,000 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:37,001 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:37,001 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:37,001 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:36,999 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:36,999 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:37,002 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:37,002 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:37,002 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:37,002 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:37,002 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:37,002 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:37,002 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:37,002 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:37,002 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:37,002 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:37,002 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:37,002 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:37,002 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-04-02T15:33:37,002 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 13 seconds.
2022-04-02T15:33:47,582 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:47,582 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:33:47,993 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:47,997 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]97764
2022-04-02T15:33:47,997 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:47,997 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:47,997 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:47,997 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:47,997 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:47,997 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:33:47,999 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:33:47,999 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881227999
2022-04-02T15:33:47,999 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881227999
2022-04-02T15:33:48,009 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:48,146 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:48,146 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:48,147 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:48,147 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:48,147 [INFO ] KQueueEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:48,148 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:48,148 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:48,148 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:48,149 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:48,149 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:48,149 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:48,149 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:48,149 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:48,149 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:48,150 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:48,150 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:48,150 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:48,150 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:48,151 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:48,151 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:48,151 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:48,151 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:48,151 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:48,151 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:48,151 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:48,148 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:48,148 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:48,166 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:48,166 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:48,169 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:48,169 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:48,170 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:48,170 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:33:48,170 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:48,170 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:33:48,171 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 21 seconds.
2022-04-02T15:33:48,171 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 21 seconds.
2022-04-02T15:33:48,170 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:48,170 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:33:48,170 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:48,170 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:33:49,167 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:49,167 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:33:49,591 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:49,594 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]97766
2022-04-02T15:33:49,594 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:49,594 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:49,594 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:49,594 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:49,595 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:49,595 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:33:49,596 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:33:49,596 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881229596
2022-04-02T15:33:49,596 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881229596
2022-04-02T15:33:49,599 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:49,742 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:49,742 [INFO ] KQueueEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:49,742 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:49,743 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:49,743 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:49,743 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:49,743 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:49,743 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:49,743 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:49,743 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:49,743 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:49,743 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:49,743 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:49,743 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:49,743 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:49,744 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:49,744 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:49,744 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:49,744 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:49,743 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:49,743 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:49,746 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:49,746 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:49,746 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:49,747 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:49,747 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:49,747 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:49,747 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:33:49,747 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:33:49,762 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:49,762 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:49,762 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:33:49,762 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:49,762 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:49,762 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:33:49,762 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2022-04-02T15:33:49,762 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 21 seconds.
2022-04-02T15:33:49,942 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:49,942 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:33:49,962 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:49,962 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:33:49,971 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:49,971 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:33:50,002 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:50,002 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:50,002 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:50,002 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:33:50,002 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:33:50,002 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:33:50,820 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:50,820 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]97767
2022-04-02T15:33:50,821 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:50,821 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:50,822 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,822 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,822 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:50,822 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:33:50,823 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:33:50,826 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230825
2022-04-02T15:33:50,826 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230825
2022-04-02T15:33:50,829 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:50,877 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:50,878 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]97768
2022-04-02T15:33:50,878 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:50,878 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:50,878 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,878 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,879 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:50,879 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:33:50,880 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:50,880 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230880
2022-04-02T15:33:50,880 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230880
2022-04-02T15:33:50,880 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:33:50,880 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]97769
2022-04-02T15:33:50,880 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:50,880 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,880 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:50,880 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,880 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:50,880 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:33:50,881 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:50,881 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:33:50,881 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230881
2022-04-02T15:33:50,881 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230881
2022-04-02T15:33:50,882 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:50,884 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:50,884 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]97772
2022-04-02T15:33:50,884 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:50,885 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:50,885 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,885 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,885 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:50,885 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:33:50,887 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230887
2022-04-02T15:33:50,887 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230887
2022-04-02T15:33:50,888 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:33:50,889 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:50,897 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:50,900 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]97770
2022-04-02T15:33:50,900 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:50,900 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:50,900 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,900 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,900 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:50,900 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:33:50,905 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:33:50,906 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230906
2022-04-02T15:33:50,906 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230906
2022-04-02T15:33:50,909 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:50,925 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:50,925 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]97771
2022-04-02T15:33:50,925 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:33:50,925 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:33:50,925 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,925 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:33:50,926 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:50,926 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:33:50,929 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:33:50,931 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230931
2022-04-02T15:33:50,931 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881230931
2022-04-02T15:33:50,934 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:33:51,002 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:51,003 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,003 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:51,003 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:51,003 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:51,003 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:51,003 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,003 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,003 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,003 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,003 [INFO ] KQueueEventLoopGroup-5-11 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,003 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:51,004 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,004 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:51,004 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,004 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,004 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:51,005 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,005 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:51,005 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:51,005 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:51,006 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:51,005 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:51,006 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:33:51,006 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:51,006 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 21 seconds.
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:51,006 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:33:51,069 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:51,069 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,069 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,069 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:51,069 [INFO ] KQueueEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,069 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:51,069 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:51,069 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:51,069 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,069 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,069 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,069 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,069 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:51,069 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:51,070 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:51,070 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:51,070 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,070 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:51,070 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:51,071 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:51,071 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:51,071 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:51,071 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:33:51,071 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:51,071 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:33:51,071 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:51,071 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:51,071 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:51,071 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:33:51,071 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2022-04-02T15:33:51,071 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:33:51,071 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 21 seconds.
2022-04-02T15:33:51,074 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,075 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,075 [INFO ] KQueueEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,075 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,075 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:51,075 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,076 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,077 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,077 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:51,077 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:51,077 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,077 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,077 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:51,075 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,075 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,078 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,078 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,077 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:51,078 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,078 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,078 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:51,078 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:51,078 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:33:51,078 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:51,078 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:33:51,078 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:33:51,078 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:51,078 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:33:51,078 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-04-02T15:33:51,078 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 21 seconds.
2022-04-02T15:33:51,086 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:51,086 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,086 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:51,086 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:51,086 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:51,086 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:51,086 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,087 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,087 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,087 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,087 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:51,087 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:51,087 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:51,087 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:51,087 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:51,088 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:51,088 [INFO ] KQueueEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:51,088 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,088 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:51,088 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:51,088 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,088 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:51,089 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:51,089 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,089 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,090 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,090 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,090 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:51,090 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:33:51,090 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:51,090 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:33:51,090 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:51,090 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:51,090 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:33:51,090 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:33:51,091 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2022-04-02T15:33:51,091 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 21 seconds.
2022-04-02T15:33:51,095 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:51,095 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,095 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:51,095 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:51,095 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:51,095 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:51,095 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,095 [INFO ] KQueueEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,095 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,096 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,096 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:51,096 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:51,097 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:51,096 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,096 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,100 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,100 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,100 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,100 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,102 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:51,102 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:33:51,102 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:51,102 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:33:51,102 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:51,102 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:33:51,103 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 21 seconds.
2022-04-02T15:33:51,103 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 21 seconds.
2022-04-02T15:33:51,103 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:51,103 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:33:51,127 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:33:51,128 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:33:51,128 [INFO ] KQueueEventLoopGroup-5-16 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:33:51,128 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:33:51,128 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:33:51,128 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:33:51,129 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:33:51,129 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:33:51,129 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:33:51,128 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,129 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:33:51,130 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:33:51,130 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:33:51,130 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:33:51,130 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:33:51,130 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,130 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,130 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:33:51,128 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:33:51,130 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,130 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:33:51,130 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:33:51,130 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:33:51,131 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,131 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:33:51,131 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:33:51,131 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:33:51,131 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:33:51,132 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:51,132 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:33:51,132 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:51,132 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:33:51,132 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2022-04-02T15:33:51,132 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 21 seconds.
2022-04-02T15:33:51,132 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:51,132 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:33:51,133 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:33:51,133 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:34:09,180 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:34:09,180 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006]
2022-04-02T15:34:09,582 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:34:09,584 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - [PID]97775
2022-04-02T15:34:09,584 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:34:09,584 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:34:09,585 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:09,585 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:09,585 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:34:09,585 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006
2022-04-02T15:34:09,588 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9006.
2022-04-02T15:34:09,588 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881249588
2022-04-02T15:34:09,588 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881249588
2022-04-02T15:34:09,591 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:34:09,741 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:34:09,742 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:09,742 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:34:09,742 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:34:09,742 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:34:09,742 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:34:09,742 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:09,742 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:09,742 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:09,742 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:09,742 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:09,742 [INFO ] KQueueEventLoopGroup-5-1 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:09,743 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:34:09,743 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:09,743 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:09,743 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:34:09,743 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:34:09,743 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:09,743 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:34:09,743 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:34:09,743 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:34:09,743 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:09,743 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:34:09,743 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:34:09,743 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:09,744 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:34:09,745 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:09,745 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:09,745 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:09,745 [DEBUG] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:34:09,745 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:34:09,745 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stderr
2022-04-02T15:34:09,745 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:34:09,745 [WARN ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9006-my_tc_1.0-stdout
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 34 seconds.
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9006 in 34 seconds.
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stdout
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:34:09,745 [INFO ] W-9006-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-my_tc_1.0-stderr
2022-04-02T15:34:10,772 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:34:10,772 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004]
2022-04-02T15:34:11,179 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:34:11,183 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - [PID]97776
2022-04-02T15:34:11,183 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:34:11,183 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:34:11,184 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:11,184 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:11,184 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:34:11,184 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004
2022-04-02T15:34:11,185 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9004.
2022-04-02T15:34:11,185 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881251185
2022-04-02T15:34:11,185 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881251185
2022-04-02T15:34:11,188 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:11,333 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:11,333 [INFO ] KQueueEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9004 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:34:11,333 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:11,334 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:34:11,334 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:34:11,334 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:11,334 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:11,334 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:11,334 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:11,334 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:11,334 [DEBUG] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:11,334 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:11,335 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:34:11,335 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stderr
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:34:11,335 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stdout
2022-04-02T15:34:11,335 [WARN ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9004-my_tc_1.0-stdout
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9004-my_tc_1.0-stderr
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2022-04-02T15:34:11,335 [INFO ] W-9004-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9004 in 34 seconds.
2022-04-02T15:34:12,013 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:34:12,013 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002]
2022-04-02T15:34:12,075 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:34:12,075 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005]
2022-04-02T15:34:12,078 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:34:12,078 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000]
2022-04-02T15:34:12,093 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:34:12,093 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001]
2022-04-02T15:34:12,103 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:34:12,103 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007]
2022-04-02T15:34:12,137 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:34:12,137 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/seok/.pyenv/versions/3.9.9/bin/python, /Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py, --sock-type, unix, --sock-name, /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003]
2022-04-02T15:34:12,998 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:34:13,000 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - [PID]97778
2022-04-02T15:34:13,001 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:34:13,001 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:34:13,001 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,001 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,001 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:34:13,001 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002
2022-04-02T15:34:13,002 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9002.
2022-04-02T15:34:13,003 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253003
2022-04-02T15:34:13,003 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253003
2022-04-02T15:34:13,003 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:34:13,086 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:34:13,086 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - [PID]97779
2022-04-02T15:34:13,086 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:34:13,086 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:34:13,087 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,087 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,087 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:34:13,087 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005
2022-04-02T15:34:13,089 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9005.
2022-04-02T15:34:13,090 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253090
2022-04-02T15:34:13,090 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253090
2022-04-02T15:34:13,092 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:34:13,104 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:34:13,104 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - [PID]97781
2022-04-02T15:34:13,104 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:34:13,104 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:34:13,104 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,104 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,104 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:34:13,104 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001
2022-04-02T15:34:13,107 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9001.
2022-04-02T15:34:13,108 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253108
2022-04-02T15:34:13,108 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253108
2022-04-02T15:34:13,109 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:34:13,141 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:34:13,144 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - [PID]97782
2022-04-02T15:34:13,144 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:34:13,144 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - [PID]97780
2022-04-02T15:34:13,144 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:34:13,144 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:34:13,144 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:34:13,145 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,145 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,144 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:34:13,145 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,145 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:34:13,145 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007
2022-04-02T15:34:13,145 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,146 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:34:13,146 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000
2022-04-02T15:34:13,147 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9007.
2022-04-02T15:34:13,147 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253147
2022-04-02T15:34:13,147 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253147
2022-04-02T15:34:13,147 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253147
2022-04-02T15:34:13,147 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253147
2022-04-02T15:34:13,147 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9000.
2022-04-02T15:34:13,150 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:34:13,150 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:34:13,186 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Listening on port: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:34:13,193 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - [PID]97783
2022-04-02T15:34:13,193 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,193 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STOPPED -> WORKER_STARTED
2022-04-02T15:34:13,193 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Torch worker started.
2022-04-02T15:34:13,193 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Python runtime: 3.9.9
2022-04-02T15:34:13,193 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:34:13,193 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003
2022-04-02T15:34:13,194 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Connection accepted: /var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T//.ts.sock.9003.
2022-04-02T15:34:13,195 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253195
2022-04-02T15:34:13,195 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req. to backend at: 1648881253195
2022-04-02T15:34:13,196 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - model_name: my_tc, batchSize: 1
2022-04-02T15:34:13,279 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,279 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:34:13,286 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,286 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:34:13,286 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:34:13,286 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:34:13,286 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:34:13,286 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:13,286 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:13,306 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,306 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,306 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:34:13,306 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:34:13,307 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:34:13,307 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:13,307 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:34:13,333 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:34:13,333 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:34:13,333 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,334 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:34:13,334 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,334 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,334 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:34:13,334 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:34:13,279 [INFO ] KQueueEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,344 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:34:13,344 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:34:13,344 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:34:13,344 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:34:13,345 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:34:13,345 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:34:13,345 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:34:13,345 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:34:13,345 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:34:13,345 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:34:13,345 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:13,345 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:13,345 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,345 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,345 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,346 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,346 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:34:13,346 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:13,346 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,346 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,346 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:34:13,346 [INFO ] W-9002-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'ts.torch_handler.RobertaModel_handler'
2022-04-02T15:34:13,345 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,345 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,350 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,350 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,351 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,351 [DEBUG] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,352 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:34:13,352 [INFO ] W-9002-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stdout
2022-04-02T15:34:13,353 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:34:13,353 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stderr
2022-04-02T15:34:13,353 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:34:13,353 [WARN ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9002-my_tc_1.0-stdout
2022-04-02T15:34:13,354 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2022-04-02T15:34:13,354 [INFO ] W-9002-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9002 in 34 seconds.
2022-04-02T15:34:13,354 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:34:13,354 [INFO ] W-9002-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-my_tc_1.0-stderr
2022-04-02T15:34:13,489 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:34:13,489 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,489 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:34:13,489 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:34:13,489 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:34:13,489 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:34:13,489 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:13,489 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:13,489 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,489 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,489 [INFO ] KQueueEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,489 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,490 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:34:13,490 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,492 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,490 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,492 [INFO ] KQueueEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,492 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:34:13,501 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,501 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,490 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:34:13,501 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,501 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:34:13,501 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:34:13,501 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:13,501 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:34:13,501 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:34:13,501 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:34:13,501 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:34:13,502 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:34:13,502 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:34:13,502 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,502 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:13,502 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:13,502 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,502 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,502 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:34:13,502 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:34:13,502 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,502 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:34:13,503 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:34:13,503 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:13,503 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,503 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:34:13,503 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:34:13,503 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:34:13,503 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,501 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,501 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,503 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:34:13,501 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,528 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,501 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,528 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,528 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,503 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:34:13,528 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:34:13,528 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:34:13,528 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:34:13,528 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:34:13,528 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,528 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,528 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,546 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,546 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,528 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:34:13,546 [INFO ] KQueueEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9007 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,546 [INFO ] KQueueEventLoopGroup-5-7 org.pytorch.serve.wlm.WorkerThread - 9000 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,545 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:34:13,550 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,550 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:34:13,550 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:34:13,550 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:34:13,550 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,545 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:34:13,550 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,550 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,550 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,550 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:34:13,528 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,551 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:34:13,551 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:13,551 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:13,551 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,551 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,528 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:34:13,551 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:34:13,550 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,551 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:34:13,551 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:34:13,550 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,550 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:34:13,551 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:13,550 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,551 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:34:13,551 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,528 [DEBUG] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,551 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:34:13,551 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:34:13,552 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:34:13,552 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:34:13,552 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:13,552 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:34:13,552 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:13,550 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,552 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:34:13,552 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:34:13,552 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,552 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,551 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:34:13,552 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:34:13,552 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:34:13,552 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:34:13,552 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:34:13,552 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:34:13,552 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:34:13,550 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,552 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:34:13,552 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:34:13,553 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:13,553 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:34:13,553 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,553 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,551 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:34:13,553 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,553 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,553 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,553 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,553 [DEBUG] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,553 [DEBUG] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,551 [DEBUG] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,553 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:34:13,552 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:34:13,553 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:34:13,554 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:34:13,554 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,554 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:34:13,554 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:34:13,554 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:34:13,554 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:34:13,554 [INFO ] W-9007-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stderr
2022-04-02T15:34:13,555 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,552 [INFO ] W-9001-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stderr
2022-04-02T15:34:13,554 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stderr
2022-04-02T15:34:13,554 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:13,554 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:34:13,552 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stderr
2022-04-02T15:34:13,555 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:34:13,555 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:13,554 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:34:13,555 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,554 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stderr
2022-04-02T15:34:13,555 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:34:13,555 [WARN ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9007-my_tc_1.0-stdout
2022-04-02T15:34:13,554 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:34:13,555 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,554 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:34:13,556 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 34 seconds.
2022-04-02T15:34:13,556 [INFO ] W-9007-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9007 in 34 seconds.
2022-04-02T15:34:13,554 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:34:13,554 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stderr
2022-04-02T15:34:13,556 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:34:13,555 [WARN ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9001-my_tc_1.0-stdout
2022-04-02T15:34:13,554 [INFO ] W-9005-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stderr
2022-04-02T15:34:13,556 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2022-04-02T15:34:13,554 [INFO ] W-9000-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stderr
2022-04-02T15:34:13,556 [INFO ] W-9001-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:13,555 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:34:13,556 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:34:13,556 [INFO ] W-9001-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-my_tc_1.0-stdout
2022-04-02T15:34:13,555 [INFO ] W-9007-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,556 [INFO ] W-9001-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9001 in 34 seconds.
2022-04-02T15:34:13,555 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:34:13,556 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:34:13,555 [WARN ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9005-my_tc_1.0-stdout
2022-04-02T15:34:13,556 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,556 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2022-04-02T15:34:13,556 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:34:13,556 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:34:13,557 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,556 [WARN ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9000-my_tc_1.0-stdout
2022-04-02T15:34:13,556 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:34:13,557 [INFO ] W-9000-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,556 [INFO ] W-9005-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9005 in 34 seconds.
2022-04-02T15:34:13,557 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:34:13,556 [INFO ] W-9005-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:34:13,557 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-04-02T15:34:13,557 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:34:13,557 [INFO ] W-9005-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-my_tc_1.0-stdout
2022-04-02T15:34:13,557 [INFO ] W-9000-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9000 in 34 seconds.
2022-04-02T15:34:13,557 [INFO ] W-9000-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9000-my_tc_1.0-stdout
2022-04-02T15:34:13,556 [INFO ] W-9007-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9007-my_tc_1.0-stdout
2022-04-02T15:34:13,576 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Backend worker process died.
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 83, in load
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module, function_name = self._load_handler_file(handler)
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 123, in _load_handler_file
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name)
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
2022-04-02T15:34:13,577 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,577 [INFO ] KQueueEventLoopGroup-5-8 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_STARTED
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap_external>", line 850, in exec_module
2022-04-02T15:34:13,577 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:13,577 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_STARTED
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/private/var/folders/c7/kl67jhc17clcs0z170qm90bw0000gn/T/models/78823125fba8491c9de7e64d9555cd7c/RobertaModel_handler.py", line 9, in <module>
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     from base_handler import BaseHandler
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - ModuleNotFoundError: No module named 'base_handler'
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - During handling of the above exception, another exception occurred:
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - 
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG - Traceback (most recent call last):
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 189, in <module>
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     worker.run_server()
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 161, in run_server
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     self.handle_connection(cl_socket)
2022-04-02T15:34:13,577 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 123, in handle_connection
2022-04-02T15:34:13,577 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service, result, code = self.load_model(msg)
2022-04-02T15:34:13,577 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died.
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2056) ~[?:?]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2133) ~[?:?]
	at java.util.concurrent.ArrayBlockingQueue.poll(ArrayBlockingQueue.java:432) ~[?:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:189) [model-server.jar:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128) [?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628) [?:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_service_worker.py", line 95, in load_model
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     service = model_loader.load(model_name, model_dir, handler, gpu,
2022-04-02T15:34:13,578 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 85, in load
2022-04-02T15:34:13,578 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.BatchAggregator - Load model failed: my_tc, error: Worker died.
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = self._load_default_handler(handler)
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/site-packages/ts/model_loader.py", line 128, in _load_default_handler
2022-04-02T15:34:13,578 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     module = importlib.import_module(module_name, 'ts.torch_handler')
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "/Users/seok/.pyenv/versions/3.9.9/lib/python3.9/importlib/__init__.py", line 127, in import_module
2022-04-02T15:34:13,578 [DEBUG] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-my_tc_1.0 State change WORKER_STARTED -> WORKER_STOPPED
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -     return _bootstrap._gcd_import(name[level:], package, level)
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 972, in _find_and_load_unlocked
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
2022-04-02T15:34:13,578 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:34:13,578 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stderr
2022-04-02T15:34:13,578 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
2022-04-02T15:34:13,578 [WARN ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - terminateIOStreams() threadName=W-9003-my_tc_1.0-stdout
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stdout MODEL_LOG -   File "<frozen importlib._bootstrap>", line 984, in _find_and_load_unlocked
2022-04-02T15:34:13,578 [INFO ] W-9003-my_tc_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stderr
2022-04-02T15:34:13,579 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:34:13,579 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2022-04-02T15:34:13,579 [INFO ] W-9003-my_tc_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-my_tc_1.0-stdout
2022-04-02T15:34:13,579 [INFO ] W-9003-my_tc_1.0 org.pytorch.serve.wlm.WorkerThread - Retry worker: 9003 in 34 seconds.
2022-04-02T15:34:42,812 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-02T15:34:42,812 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Inference model server stopped.
2022-04-02T15:34:42,818 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-04-02T15:34:42,818 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
2022-04-02T15:34:42,818 [INFO ] KQueueEventLoopGroup-2-1 org.pytorch.serve.ModelServer - Metrics model server stopped.
2022-04-02T15:34:42,818 [INFO ] KQueueEventLoopGroup-2-2 org.pytorch.serve.ModelServer - Management model server stopped.
